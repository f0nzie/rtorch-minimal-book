<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 rTorch vs PyTorch | A Minimal rTorch Book</title>
  <meta name="description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  <meta name="generator" content="bookdown 0.21.4 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 rTorch vs PyTorch | A Minimal rTorch Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 rTorch vs PyTorch | A Minimal rTorch Book" />
  
  <meta name="twitter:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2020-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pytorch-and-numpy.html"/>
<link rel="next" href="converting-tensors.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.16/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
      // R show code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('show');
      });
      // Python show code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      // Bash show code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      
  });
  $("#rmd-hide-all-code").click(function() {
      // close the dropdown menu when an option is clicked
      $("#allCodeButton").dropdown("toggle");
      // Hide R code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Python code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Bash code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('hide');
      });
  });


  // index for unique code element ids
  var r_currentIndex  = 1;   // for R code
  var py_currentIndex = 1;   // for Python code
  var sh_currentIndex  = 1;   // for shell code

  // select Python chunks
  var pyCodeBlocks = $('pre.python');
  pyCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse py-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'pycode-643E0F36' + py_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#ebfaeb');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Python code' : 'Python code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#009900');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Python code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Python code');
    });  
   });
  
  

  // select Bash shell chunks
  var shCodeBlocks = $('pre.bash');
  shCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse sh-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'shcode-643E0F36' + sh_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#A0A0A0');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Bash code' : 'Bash code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#cc7a00');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Bash code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Bash code');
    });  
   });  


  // select all R code blocks
  // var rCodeBlocks = $('pre.sourceCode, pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  // adding pre.sourceCode confuses the Python button
  var rCodeBlocks = $('pre.r, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + r_currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#e6faff'); // change color of chunk background

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide R code' : 'R code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);
    
    // change the background color of the button        
    showCodeButton.css('background-color','#0000ff');
    
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('R code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide R code');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  // show code by default. Use "show" === "hide" to hide
  window.initializeCodeFolding("show" === "show");
});
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The rTorch Minimal Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> Start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#get-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Get the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#getting-help"><i class="fa fa-check"></i><b>1.4</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html"><i class="fa fa-check"></i><b>2</b> PyTorch and NumPy</a><ul>
<li class="chapter" data-level="2.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#pytorch-modules-in-rtorch"><i class="fa fa-check"></i><b>2.1</b> PyTorch modules in <code>rTorch</code></a><ul>
<li class="chapter" data-level="2.1.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#torchvision"><i class="fa fa-check"></i><b>2.1.1</b> torchvision</a></li>
<li class="chapter" data-level="2.1.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#numpy"><i class="fa fa-check"></i><b>2.1.2</b> numpy</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#common-array-operations"><i class="fa fa-check"></i><b>2.2</b> Common array operations</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#create-an-array"><i class="fa fa-check"></i>Create an array</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#reshape-an-array"><i class="fa fa-check"></i>Reshape an array</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#generate-a-random-array-in-numpy"><i class="fa fa-check"></i>Generate a random array in NumPy</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#common-tensor-operations"><i class="fa fa-check"></i><b>2.3</b> Common tensor operations</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#generate-random-tensors"><i class="fa fa-check"></i>Generate random tensors</a></li>
<li><a href="pytorch-and-numpy.html#numpy-array-to-pytorch-tensor"><code>numpy</code> array to PyTorch tensor</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#python-built-in-functions"><i class="fa fa-check"></i><b>2.4</b> Python built-in functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html"><i class="fa fa-check"></i><b>3</b> rTorch vs PyTorch</a><ul>
<li class="chapter" data-level="3.1" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#whats-different"><i class="fa fa-check"></i><b>3.1</b> What’s different</a></li>
<li class="chapter" data-level="3.2" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>3.2</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="3.3" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#call-functions-from-torch"><i class="fa fa-check"></i><b>3.3</b> Call functions from <code>torch</code></a></li>
<li class="chapter" data-level="3.4" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#python-objects"><i class="fa fa-check"></i><b>3.4</b> Python objects</a></li>
<li class="chapter" data-level="3.5" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#iterating-through-datasets"><i class="fa fa-check"></i><b>3.5</b> Iterating through datasets</a><ul>
<li class="chapter" data-level="3.5.1" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#enumeration"><i class="fa fa-check"></i><b>3.5.1</b> Enumeration</a></li>
<li class="chapter" data-level="3.5.2" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#enumerate-and-iterate"><i class="fa fa-check"></i><b>3.5.2</b> <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="3.5.3" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#for-loop-for-iteration"><i class="fa fa-check"></i><b>3.5.3</b> <code>for-loop</code> for iteration</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#zero-gradient"><i class="fa fa-check"></i><b>3.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="3.6.1" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#code-version-in-python"><i class="fa fa-check"></i><b>3.6.1</b> Code version in Python</a></li>
<li class="chapter" data-level="3.6.2" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#code-version-in-r"><i class="fa fa-check"></i><b>3.6.2</b> Code version in R</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#r-generic-functions"><i class="fa fa-check"></i><b>3.7</b> R generic functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="converting-tensors.html"><a href="converting-tensors.html"><i class="fa fa-check"></i><b>4</b> Converting tensors</a><ul>
<li class="chapter" data-level="4.1" data-path="converting-tensors.html"><a href="converting-tensors.html#tensor-to-numpy-array"><i class="fa fa-check"></i><b>4.1</b> Tensor to <code>numpy</code> array</a></li>
<li class="chapter" data-level="4.2" data-path="converting-tensors.html"><a href="converting-tensors.html#numpy-array-to-tensor"><i class="fa fa-check"></i><b>4.2</b> <code>numpy</code> array to tensor</a><ul>
<li class="chapter" data-level="4.2.1" data-path="converting-tensors.html"><a href="converting-tensors.html#numpy-array-to-r"><i class="fa fa-check"></i><b>4.2.1</b> <code>numpy</code> array to <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="converting-tensors.html"><a href="converting-tensors.html#r-objects-to-numpy-objects"><i class="fa fa-check"></i><b>4.3</b> R objects to <code>numpy</code> objects</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="5" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>5</b> Tensors</a><ul>
<li class="chapter" data-level="5.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>5.1</b> Tensor data types</a><ul>
<li class="chapter" data-level="5.1.1" data-path="tensors.html"><a href="tensors.html#major-tensor-types"><i class="fa fa-check"></i><b>5.1.1</b> Major tensor types</a></li>
<li class="chapter" data-level="5.1.2" data-path="tensors.html"><a href="tensors.html#example-a-4d-tensor"><i class="fa fa-check"></i><b>5.1.2</b> Example: A 4D tensor</a></li>
<li class="chapter" data-level="5.1.3" data-path="tensors.html"><a href="tensors.html#example-a-3d-tensor"><i class="fa fa-check"></i><b>5.1.3</b> Example: A 3D tensor</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>5.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="5.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>5.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="5.2.2" data-path="tensors.html"><a href="tensors.html#add-tensor-elements"><i class="fa fa-check"></i><b>5.2.2</b> Add tensor elements</a></li>
<li class="chapter" data-level="5.2.3" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>5.2.3</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>5.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="5.3.1" data-path="tensors.html"><a href="tensors.html#python-tuples-and-r-vectors"><i class="fa fa-check"></i><b>5.3.1</b> Python tuples and R vectors</a></li>
<li class="chapter" data-level="5.3.2" data-path="tensors.html"><a href="tensors.html#a-numpy-array-from-r-vectors"><i class="fa fa-check"></i><b>5.3.2</b> A numpy array from R vectors</a></li>
<li class="chapter" data-level="5.3.3" data-path="tensors.html"><a href="tensors.html#numpy-arrays-to-tensors"><i class="fa fa-check"></i><b>5.3.3</b> numpy arrays to tensors</a></li>
<li class="chapter" data-level="5.3.4" data-path="tensors.html"><a href="tensors.html#create-and-fill-a-tensor"><i class="fa fa-check"></i><b>5.3.4</b> Create and fill a tensor</a></li>
<li class="chapter" data-level="5.3.5" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>5.3.5</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>5.4</b> Create tensors</a><ul>
<li class="chapter" data-level="5.4.1" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>5.4.1</b> Tensor fill</a></li>
<li class="chapter" data-level="5.4.2" data-path="tensors.html"><a href="tensors.html#tensor-with-a-range-of-values"><i class="fa fa-check"></i><b>5.4.2</b> Tensor with a range of values</a></li>
<li class="chapter" data-level="5.4.3" data-path="tensors.html"><a href="tensors.html#linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>5.4.3</b> Linear or log scale Tensor</a></li>
<li class="chapter" data-level="5.4.4" data-path="tensors.html"><a href="tensors.html#in-place-out-of-place-fill"><i class="fa fa-check"></i><b>5.4.4</b> In-place / Out-of-place fill</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>5.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="5.5.1" data-path="tensors.html"><a href="tensors.html#exercise"><i class="fa fa-check"></i><b>5.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>5.6</b> Concatenate tensors</a><ul>
<li class="chapter" data-level="5.6.1" data-path="tensors.html"><a href="tensors.html#concatenate-by-rows"><i class="fa fa-check"></i><b>5.6.1</b> Concatenate by rows</a></li>
<li class="chapter" data-level="5.6.2" data-path="tensors.html"><a href="tensors.html#concatenate-by-columns"><i class="fa fa-check"></i><b>5.6.2</b> Concatenate by columns</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>5.7</b> Reshape tensors</a><ul>
<li class="chapter" data-level="5.7.1" data-path="tensors.html"><a href="tensors.html#with-chunk"><i class="fa fa-check"></i><b>5.7.1</b> With <code>chunk()</code>:</a></li>
<li class="chapter" data-level="5.7.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>5.7.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>5.8</b> Special tensors</a><ul>
<li class="chapter" data-level="5.8.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>5.8.1</b> Identity matrix</a></li>
<li class="chapter" data-level="5.8.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>5.8.2</b> Ones</a></li>
<li class="chapter" data-level="5.8.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>5.8.3</b> Zeros</a></li>
<li class="chapter" data-level="5.8.4" data-path="tensors.html"><a href="tensors.html#diagonal-operations"><i class="fa fa-check"></i><b>5.8.4</b> Diagonal operations</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>5.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="5.9.1" data-path="tensors.html"><a href="tensors.html#indices-to-tensor-elements"><i class="fa fa-check"></i><b>5.9.1</b> Indices to tensor elements</a></li>
<li class="chapter" data-level="5.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>5.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>5.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="5.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>5.10.1</b> Cross product</a></li>
<li class="chapter" data-level="5.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>5.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>5.11</b> Logical operations</a><ul>
<li class="chapter" data-level="5.11.1" data-path="tensors.html"><a href="tensors.html#extract-a-unique-logical-result"><i class="fa fa-check"></i><b>5.11.1</b> Extract a unique logical result</a></li>
<li class="chapter" data-level="5.11.2" data-path="tensors.html"><a href="tensors.html#greater-than-gt"><i class="fa fa-check"></i><b>5.11.2</b> Greater than (<code>gt</code>)</a></li>
<li class="chapter" data-level="5.11.3" data-path="tensors.html"><a href="tensors.html#less-than-or-equal-le"><i class="fa fa-check"></i><b>5.11.3</b> Less than or equal (<code>le</code>)</a></li>
<li class="chapter" data-level="5.11.4" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>5.11.4</b> Logical NOT (<code>!</code>)</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>5.12</b> Distributions</a><ul>
<li class="chapter" data-level="5.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>5.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="5.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>5.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="5.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>5.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>5.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>6</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="6.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>6.1</b> Scalars</a></li>
<li class="chapter" data-level="6.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>6.2</b> Vectors</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linearalgebra.html"><a href="linearalgebra.html#vector-to-matrix"><i class="fa fa-check"></i><b>6.2.1</b> Vector to matrix</a></li>
<li class="chapter" data-level="6.2.2" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-to-tensor"><i class="fa fa-check"></i><b>6.2.2</b> Matrix to tensor</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>6.3</b> Matrices</a></li>
<li class="chapter" data-level="6.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>6.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="6.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>6.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="6.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>6.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="6.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>6.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="6.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>6.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="6.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>6.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="6.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>6.10</b> Dot product</a><ul>
<li class="chapter" data-level="6.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#d-array-using-python"><i class="fa fa-check"></i><b>6.10.1</b> 2D array using Python</a></li>
<li class="chapter" data-level="6.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#d-array-using-r"><i class="fa fa-check"></i><b>6.10.2</b> 2D array using R</a></li>
<li class="chapter" data-level="6.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#mm-and-matmul-functions"><i class="fa fa-check"></i><b>6.10.3</b> <code>mm</code> and <code>matmul</code> functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html"><i class="fa fa-check"></i><b>7</b> Creating PyTorch classes</a><ul>
<li class="chapter" data-level="7.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#build-a-pytorch-model-class"><i class="fa fa-check"></i><b>7.1</b> Build a PyTorch model class</a><ul>
<li class="chapter" data-level="7.1.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-1-one-layer-nn"><i class="fa fa-check"></i><b>7.1.1</b> Example 1: One layer NN</a></li>
<li class="chapter" data-level="7.1.2" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>7.1.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="8" data-path="example-1-a-classification-problem.html"><a href="example-1-a-classification-problem.html"><i class="fa fa-check"></i><b>8</b> Example 1: A classification problem</a><ul>
<li class="chapter" data-level="8.1" data-path="example-1-a-classification-problem.html"><a href="example-1-a-classification-problem.html#code-in-python"><i class="fa fa-check"></i><b>8.1</b> Code in Python</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>9</b> Example 2: MNIST handwritten digits</a><ul>
<li class="chapter" data-level="9.1" data-path="mnistdigits.html"><a href="mnistdigits.html#code-in-r"><i class="fa fa-check"></i><b>9.1</b> Code in R</a><ul>
<li class="chapter" data-level="9.1.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>9.1.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="9.1.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>9.1.2</b> Read datasets</a></li>
<li class="chapter" data-level="9.1.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>9.1.3</b> Define the model</a></li>
<li class="chapter" data-level="9.1.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>9.1.4</b> Training</a></li>
<li class="chapter" data-level="9.1.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>9.1.5</b> Prediction</a></li>
<li class="chapter" data-level="9.1.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>9.1.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="mnistdigits.html"><a href="mnistdigits.html#code-in-python-1"><i class="fa fa-check"></i><b>9.2</b> Code in Python</a></li>
</ul></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="10" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>10</b> Linear Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="linear-regression.html"><a href="linear-regression.html#introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="linear-regression.html"><a href="linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>10.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="10.3" data-path="linear-regression.html"><a href="linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>10.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="10.4" data-path="linear-regression.html"><a href="linear-regression.html#numpy-array-to-tensor-1"><i class="fa fa-check"></i><b>10.4</b> <code>numpy</code> array to tensor</a></li>
<li class="chapter" data-level="10.5" data-path="linear-regression.html"><a href="linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>10.5</b> Creating the network model</a></li>
<li class="chapter" data-level="10.6" data-path="linear-regression.html"><a href="linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>10.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="10.7" data-path="linear-regression.html"><a href="linear-regression.html#training-1"><i class="fa fa-check"></i><b>10.7</b> Training</a></li>
<li class="chapter" data-level="10.8" data-path="linear-regression.html"><a href="linear-regression.html#results"><i class="fa fa-check"></i><b>10.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>11</b> Linear Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#rainfall-prediction"><i class="fa fa-check"></i><b>11.1</b> Rainfall prediction</a></li>
<li class="chapter" data-level="11.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#training-data"><i class="fa fa-check"></i><b>11.2</b> Training data</a></li>
<li class="chapter" data-level="11.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>11.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="11.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#build-the-model"><i class="fa fa-check"></i><b>11.4</b> Build the model</a></li>
<li class="chapter" data-level="11.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-predictions"><i class="fa fa-check"></i><b>11.5</b> Generate predictions</a></li>
<li class="chapter" data-level="11.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#loss-function"><i class="fa fa-check"></i><b>11.6</b> Loss Function</a></li>
<li class="chapter" data-level="11.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#step-by-step-process"><i class="fa fa-check"></i><b>11.7</b> Step by step process</a><ul>
<li class="chapter" data-level="11.7.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#compute-the-losses"><i class="fa fa-check"></i><b>11.7.1</b> Compute the losses</a></li>
<li class="chapter" data-level="11.7.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#compute-gradients"><i class="fa fa-check"></i><b>11.7.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="11.7.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#reset-the-gradients"><i class="fa fa-check"></i><b>11.7.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#all-together"><i class="fa fa-check"></i><b>11.8</b> All together</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="12" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>12</b> Neural Networks</a><ul>
<li class="chapter" data-level="12.1" data-path="neural-networks.html"><a href="neural-networks.html#rtorch-and-pytorch"><i class="fa fa-check"></i><b>12.1</b> rTorch and PyTorch</a></li>
<li class="chapter" data-level="12.2" data-path="neural-networks.html"><a href="neural-networks.html#a-neural-network-with-numpy"><i class="fa fa-check"></i><b>12.2</b> A neural network with <code>numpy</code></a></li>
<li class="chapter" data-level="12.3" data-path="neural-networks.html"><a href="neural-networks.html#a-neural-network-with-r-base"><i class="fa fa-check"></i><b>12.3</b> A neural network with <code>r-base</code></a></li>
<li class="chapter" data-level="12.4" data-path="neural-networks.html"><a href="neural-networks.html#a-pytorch-neural-network"><i class="fa fa-check"></i><b>12.4</b> A <code>PyTorch</code> neural network</a></li>
<li class="chapter" data-level="12.5" data-path="neural-networks.html"><a href="neural-networks.html#a-neural-network-in-rtorch"><i class="fa fa-check"></i><b>12.5</b> A neural network in <code>rTorch</code></a><ul>
<li class="chapter" data-level="12.5.1" data-path="neural-networks.html"><a href="neural-networks.html#load-the-libraries"><i class="fa fa-check"></i><b>12.5.1</b> Load the libraries</a></li>
<li class="chapter" data-level="12.5.2" data-path="neural-networks.html"><a href="neural-networks.html#dataset"><i class="fa fa-check"></i><b>12.5.2</b> Dataset</a></li>
<li class="chapter" data-level="12.5.3" data-path="neural-networks.html"><a href="neural-networks.html#initialize-the-weights"><i class="fa fa-check"></i><b>12.5.3</b> Initialize the weights</a></li>
<li class="chapter" data-level="12.5.4" data-path="neural-networks.html"><a href="neural-networks.html#iterate-through-the-dataset"><i class="fa fa-check"></i><b>12.5.4</b> Iterate through the dataset</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="neural-networks.html"><a href="neural-networks.html#full-neural-network-in-rtorch"><i class="fa fa-check"></i><b>12.6</b> Full Neural Network in rTorch</a></li>
<li class="chapter" data-level="12.7" data-path="neural-networks.html"><a href="neural-networks.html#exercise-2"><i class="fa fa-check"></i><b>12.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html"><i class="fa fa-check"></i><b>13</b> A neural network step-by-step</a><ul>
<li class="chapter" data-level="13.1" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#introduction-1"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#select-device"><i class="fa fa-check"></i><b>13.2</b> Select device</a></li>
<li class="chapter" data-level="13.3" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#create-the-dataset"><i class="fa fa-check"></i><b>13.3</b> Create the dataset</a></li>
<li class="chapter" data-level="13.4" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#define-the-model-1"><i class="fa fa-check"></i><b>13.4</b> Define the model</a></li>
<li class="chapter" data-level="13.5" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#the-loss-function"><i class="fa fa-check"></i><b>13.5</b> The Loss function</a></li>
<li class="chapter" data-level="13.6" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#iterate-through-the-dataset-1"><i class="fa fa-check"></i><b>13.6</b> Iterate through the dataset</a></li>
<li class="chapter" data-level="13.7" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#using-r-generics"><i class="fa fa-check"></i><b>13.7</b> Using R generics</a><ul>
<li class="chapter" data-level="13.7.1" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#simplify-tensor-operations"><i class="fa fa-check"></i><b>13.7.1</b> Simplify tensor operations</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#an-elegant-neural-network"><i class="fa fa-check"></i><b>13.8</b> An elegant neural network</a></li>
<li class="chapter" data-level="13.9" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#a-browseable-dataframe"><i class="fa fa-check"></i><b>13.9</b> A browseable dataframe</a></li>
<li class="chapter" data-level="13.10" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#plot-the-loss-at-each-iteration"><i class="fa fa-check"></i><b>13.10</b> Plot the loss at each iteration</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="14" data-path="working-with-a-dataframe.html"><a href="working-with-a-dataframe.html"><i class="fa fa-check"></i><b>14</b> Working with a data●frame</a><ul>
<li class="chapter" data-level="14.1" data-path="working-with-a-dataframe.html"><a href="working-with-a-dataframe.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>14.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="14.2" data-path="working-with-a-dataframe.html"><a href="working-with-a-dataframe.html#load-dataset"><i class="fa fa-check"></i><b>14.2</b> Load dataset</a></li>
<li class="chapter" data-level="14.3" data-path="working-with-a-dataframe.html"><a href="working-with-a-dataframe.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>14.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="14.3.1" data-path="working-with-a-dataframe.html"><a href="working-with-a-dataframe.html#using-data.frame"><i class="fa fa-check"></i><b>14.3.1</b> Using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="working-with-datatable.html"><a href="working-with-datatable.html"><i class="fa fa-check"></i><b>15</b> Working with data●table</a><ul>
<li class="chapter" data-level="15.1" data-path="working-with-datatable.html"><a href="working-with-datatable.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>15.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="15.2" data-path="working-with-datatable.html"><a href="working-with-datatable.html#load-dataset-1"><i class="fa fa-check"></i><b>15.2</b> Load dataset</a></li>
<li class="chapter" data-level="15.3" data-path="working-with-datatable.html"><a href="working-with-datatable.html#datasets-without-normalization"><i class="fa fa-check"></i><b>15.3</b> Datasets without normalization</a></li>
<li class="chapter" data-level="15.4" data-path="working-with-datatable.html"><a href="working-with-datatable.html#using-data.table"><i class="fa fa-check"></i><b>15.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#sigmoid"><i class="fa fa-check"></i><b>B.1</b> Sigmoid</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#relu"><i class="fa fa-check"></i><b>B.2</b> ReLU</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#tanh"><i class="fa fa-check"></i><b>B.3</b> tanh</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#softmax"><i class="fa fa-check"></i><b>B.4</b> Softmax</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Activation functions in Python</a><ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li><a href="appendixB.html#visualization-with-matplotlib">Visualization with <code>matplotlib</code></a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-code-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax code in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/f0nzie/rtorch-minimal-book" target="blank">Book source code</a></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="rtorch-vs-pytorch" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> rTorch vs PyTorch</h1>
<p><em>Last update: Sun Oct 25 13:00:41 2020 -0500 (265c0b3c1)</em></p>
<div id="whats-different" class="section level2">
<h2><span class="header-section-number">3.1</span> What’s different</h2>
<p>This chapter will explain the main differences between <code>PyTorch</code> and <code>rTorch</code>. Most of the things work directly in <code>PyTorch</code> but we need to be aware of some minor differences when working with rTorch. Here is a review of existing methods.</p>
<p>Let’s start by loading <code>rTorch</code>:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" title="1"><span class="kw">library</span>(rTorch)</a></code></pre></div>
</div>
<div id="calling-objects-from-pytorch" class="section level2">
<h2><span class="header-section-number">3.2</span> Calling objects from PyTorch</h2>
<p>We use the dollar sign or <code>$</code> to call a class, function or method from the <code>rTorch</code> modules. In this case, from the <code>torch</code> module:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" title="1">torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>#&gt; tensor([1., 2., 3.])</code></pre>
<p>In Python, what we do is using the <strong>dot</strong> to separate the sub-members of an object:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb63-1" title="1"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb63-2" title="2">torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</a></code></pre></div>
<pre><code>#&gt; tensor([1, 2, 3])</code></pre>
</div>
<div id="call-functions-from-torch" class="section level2">
<h2><span class="header-section-number">3.3</span> Call functions from <code>torch</code></h2>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" title="1"><span class="kw">library</span>(rTorch)</a>
<a class="sourceLine" id="cb65-2" title="2"><span class="co"># these are the equivalents of the Python import module</span></a>
<a class="sourceLine" id="cb65-3" title="3">nn          &lt;-<span class="st"> </span>torch<span class="op">$</span>nn</a>
<a class="sourceLine" id="cb65-4" title="4">transforms  &lt;-<span class="st"> </span>torchvision<span class="op">$</span>transforms</a>
<a class="sourceLine" id="cb65-5" title="5">dsets       &lt;-<span class="st"> </span>torchvision<span class="op">$</span>datasets</a>
<a class="sourceLine" id="cb65-6" title="6"></a>
<a class="sourceLine" id="cb65-7" title="7">torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</a></code></pre></div>
<pre><code>#&gt; tensor([1., 2., 3.])</code></pre>
<p>The code above is equivalent to writing this code in Python:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb67-1" title="1"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb67-2" title="2"><span class="im">import</span> torch.nn <span class="im">as</span> nn</a>
<a class="sourceLine" id="cb67-3" title="3"><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</a>
<a class="sourceLine" id="cb67-4" title="4"><span class="im">import</span> torchvision.datasets <span class="im">as</span> dsets</a>
<a class="sourceLine" id="cb67-5" title="5"></a>
<a class="sourceLine" id="cb67-6" title="6">torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</a></code></pre></div>
<pre><code>#&gt; tensor([1, 2, 3])</code></pre>
<p>Then we can proceed to extract classes, methods and functions from the <code>nn</code>, <code>transforms</code>, and <code>dsets</code> objects. In this example we use the module <code>torchvision$datasets</code> and the function <code>transforms$ToTensor()</code>. For example, the <code>train_dataset</code> of MNIST:`</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1">local_folder &lt;-<span class="st"> &#39;./datasets/mnist_digits&#39;</span></a>
<a class="sourceLine" id="cb69-2" title="2">train_dataset =<span class="st"> </span>torchvision<span class="op">$</span>datasets<span class="op">$</span><span class="kw">MNIST</span>(<span class="dt">root =</span> local_folder, </a>
<a class="sourceLine" id="cb69-3" title="3">                                           <span class="dt">train =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb69-4" title="4">                                           <span class="dt">transform =</span> transforms<span class="op">$</span><span class="kw">ToTensor</span>(),</a>
<a class="sourceLine" id="cb69-5" title="5">                                           <span class="dt">download =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb69-6" title="6">train_dataset</a></code></pre></div>
<pre><code>#&gt; Dataset MNIST
#&gt;     Number of datapoints: 60000
#&gt;     Root location: ./datasets/mnist_digits
#&gt;     Split: Train
#&gt;     StandardTransform
#&gt; Transform: ToTensor()</code></pre>
</div>
<div id="python-objects" class="section level2">
<h2><span class="header-section-number">3.4</span> Python objects</h2>
<p>Sometimes we are interested in knowing the internal components of a class. In that case, we use the <code>reticulate</code> function <code>py_list_attributes()</code>.</p>
<p>In this example, we want to show the attributes of <code>train_dataset</code>:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1">reticulate<span class="op">::</span><span class="kw">py_list_attributes</span>(train_dataset)</a></code></pre></div>
<pre><code>#&gt;  [1] &quot;__add__&quot;                &quot;__class__&quot;              &quot;__delattr__&quot;           
#&gt;  [4] &quot;__dict__&quot;               &quot;__dir__&quot;                &quot;__doc__&quot;               
#&gt;  [7] &quot;__eq__&quot;                 &quot;__format__&quot;             &quot;__ge__&quot;                
#&gt; [10] &quot;__getattribute__&quot;       &quot;__getitem__&quot;            &quot;__gt__&quot;                
#&gt; [13] &quot;__hash__&quot;               &quot;__init__&quot;               &quot;__init_subclass__&quot;     
#&gt; [16] &quot;__le__&quot;                 &quot;__len__&quot;                &quot;__lt__&quot;                
#&gt; [19] &quot;__module__&quot;             &quot;__ne__&quot;                 &quot;__new__&quot;               
#&gt; [22] &quot;__reduce__&quot;             &quot;__reduce_ex__&quot;          &quot;__repr__&quot;              
#&gt; [25] &quot;__setattr__&quot;            &quot;__sizeof__&quot;             &quot;__str__&quot;               
#&gt; [28] &quot;__subclasshook__&quot;       &quot;__weakref__&quot;            &quot;_check_exists&quot;         
#&gt; [31] &quot;_format_transform_repr&quot; &quot;_repr_indent&quot;           &quot;class_to_idx&quot;          
#&gt; [34] &quot;classes&quot;                &quot;data&quot;                   &quot;download&quot;              
#&gt; [37] &quot;extra_repr&quot;             &quot;processed_folder&quot;       &quot;raw_folder&quot;            
#&gt; [40] &quot;resources&quot;              &quot;root&quot;                   &quot;target_transform&quot;      
#&gt; [43] &quot;targets&quot;                &quot;test_data&quot;              &quot;test_file&quot;             
#&gt; [46] &quot;test_labels&quot;            &quot;train&quot;                  &quot;train_data&quot;            
#&gt; [49] &quot;train_labels&quot;           &quot;training_file&quot;          &quot;transform&quot;             
#&gt; [52] &quot;transforms&quot;</code></pre>
<p>Knowing the internal methods of a class could be useful when we want to refer to a specific property of such class. For example, from the list above, we know that the object <code>train_dataset</code> has an attribute <code>__len__</code>. We can call it like this:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1">train_dataset<span class="op">$</span><span class="st">`</span><span class="dt">__len__</span><span class="st">`</span>()</a></code></pre></div>
<pre><code>#&gt; [1] 60000</code></pre>
</div>
<div id="iterating-through-datasets" class="section level2">
<h2><span class="header-section-number">3.5</span> Iterating through datasets</h2>
<div id="enumeration" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Enumeration</h3>
<p>Given the following training dataset <code>x_train</code>, we want to find the number of elements of the tensor. We start by entering a <code>numpy</code> array, which then will convert to a tensor with the PyTorch function <code>from_numpy()</code>:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1">x_train_r &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="kw">c</span>(<span class="fl">3.3</span>, <span class="fl">4.4</span>, <span class="fl">5.5</span>, <span class="fl">6.71</span>, <span class="fl">6.93</span>, <span class="fl">4.168</span>, </a>
<a class="sourceLine" id="cb75-2" title="2">                  <span class="fl">9.779</span>, <span class="fl">6.182</span>, <span class="fl">7.59</span>, <span class="fl">2.167</span>, <span class="fl">7.042</span>,</a>
<a class="sourceLine" id="cb75-3" title="3">                  <span class="fl">10.791</span>, <span class="fl">5.313</span>, <span class="fl">7.997</span>, <span class="fl">3.1</span>), <span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb75-4" title="4"></a>
<a class="sourceLine" id="cb75-5" title="5">x_train_np &lt;-<span class="st"> </span><span class="kw">r_to_py</span>(x_train_r)</a>
<a class="sourceLine" id="cb75-6" title="6">x_train_   &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(x_train_np)          <span class="co"># convert to tensor</span></a>
<a class="sourceLine" id="cb75-7" title="7">x_train    &lt;-<span class="st"> </span>x_train_<span class="op">$</span><span class="kw">type</span>(torch<span class="op">$</span>FloatTensor)      <span class="co"># make it a a FloatTensor</span></a>
<a class="sourceLine" id="cb75-8" title="8"><span class="kw">print</span>(x_train<span class="op">$</span>dtype)</a>
<a class="sourceLine" id="cb75-9" title="9"><span class="kw">print</span>(x_train)</a></code></pre></div>
<pre><code>#&gt; torch.float32
#&gt; tensor([[ 3.3000],
#&gt;         [ 4.4000],
#&gt;         [ 5.5000],
#&gt;         [ 6.7100],
#&gt;         [ 6.9300],
#&gt;         [ 4.1680],
#&gt;         [ 9.7790],
#&gt;         [ 6.1820],
#&gt;         [ 7.5900],
#&gt;         [ 2.1670],
#&gt;         [ 7.0420],
#&gt;         [10.7910],
#&gt;         [ 5.3130],
#&gt;         [ 7.9970],
#&gt;         [ 3.1000]])</code></pre>
<p><code>length</code> is similar to <code>nelement</code> for number of elements:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" title="1"><span class="kw">length</span>(x_train)</a>
<a class="sourceLine" id="cb77-2" title="2">x_train<span class="op">$</span><span class="kw">nelement</span>()    <span class="co"># number of elements in the tensor</span></a></code></pre></div>
<pre><code>#&gt; [1] 15
#&gt; [1] 15</code></pre>
</div>
<div id="enumerate-and-iterate" class="section level3">
<h3><span class="header-section-number">3.5.2</span> <code>enumerate</code> and <code>iterate</code></h3>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" title="1">py =<span class="st"> </span><span class="kw">import_builtins</span>()</a>
<a class="sourceLine" id="cb79-2" title="2"></a>
<a class="sourceLine" id="cb79-3" title="3">enum_x_train =<span class="st"> </span>py<span class="op">$</span><span class="kw">enumerate</span>(x_train)</a>
<a class="sourceLine" id="cb79-4" title="4">enum_x_train</a>
<a class="sourceLine" id="cb79-5" title="5"></a>
<a class="sourceLine" id="cb79-6" title="6">py<span class="op">$</span><span class="kw">len</span>(x_train)</a></code></pre></div>
<pre><code>#&gt; &lt;enumerate&gt;
#&gt; [1] 15</code></pre>
<p>If we directly use <code>iterate</code> over the <code>enum_x_train</code> object, we get an R list with the index and the value of the <code>1D</code> tensor:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" title="1">xit =<span class="st"> </span><span class="kw">iterate</span>(enum_x_train, <span class="dt">simplify =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb81-2" title="2">xit</a></code></pre></div>
<pre><code>#&gt; [[1]]
#&gt; [[1]][[1]]
#&gt; [1] 0
#&gt; 
#&gt; [[1]][[2]]
#&gt; tensor([3.3000])
#&gt; 
#&gt; 
#&gt; [[2]]
#&gt; [[2]][[1]]
#&gt; [1] 1
#&gt; 
#&gt; [[2]][[2]]
#&gt; tensor([4.4000])
#&gt; 
#&gt; 
#&gt; [[3]]
#&gt; [[3]][[1]]
#&gt; [1] 2
#&gt; 
#&gt; [[3]][[2]]
#&gt; tensor([5.5000])
#&gt; 
#&gt; 
#&gt; [[4]]
#&gt; [[4]][[1]]
#&gt; [1] 3
#&gt; 
#&gt; [[4]][[2]]
#&gt; tensor([6.7100])
#&gt; 
#&gt; 
#&gt; [[5]]
#&gt; [[5]][[1]]
#&gt; [1] 4
#&gt; 
#&gt; [[5]][[2]]
#&gt; tensor([6.9300])
#&gt; 
#&gt; 
#&gt; [[6]]
#&gt; [[6]][[1]]
#&gt; [1] 5
#&gt; 
#&gt; [[6]][[2]]
#&gt; tensor([4.1680])
#&gt; 
#&gt; 
#&gt; [[7]]
#&gt; [[7]][[1]]
#&gt; [1] 6
#&gt; 
#&gt; [[7]][[2]]
#&gt; tensor([9.7790])
#&gt; 
#&gt; 
#&gt; [[8]]
#&gt; [[8]][[1]]
#&gt; [1] 7
#&gt; 
#&gt; [[8]][[2]]
#&gt; tensor([6.1820])
#&gt; 
#&gt; 
#&gt; [[9]]
#&gt; [[9]][[1]]
#&gt; [1] 8
#&gt; 
#&gt; [[9]][[2]]
#&gt; tensor([7.5900])
#&gt; 
#&gt; 
#&gt; [[10]]
#&gt; [[10]][[1]]
#&gt; [1] 9
#&gt; 
#&gt; [[10]][[2]]
#&gt; tensor([2.1670])
#&gt; 
#&gt; 
#&gt; [[11]]
#&gt; [[11]][[1]]
#&gt; [1] 10
#&gt; 
#&gt; [[11]][[2]]
#&gt; tensor([7.0420])
#&gt; 
#&gt; 
#&gt; [[12]]
#&gt; [[12]][[1]]
#&gt; [1] 11
#&gt; 
#&gt; [[12]][[2]]
#&gt; tensor([10.7910])
#&gt; 
#&gt; 
#&gt; [[13]]
#&gt; [[13]][[1]]
#&gt; [1] 12
#&gt; 
#&gt; [[13]][[2]]
#&gt; tensor([5.3130])
#&gt; 
#&gt; 
#&gt; [[14]]
#&gt; [[14]][[1]]
#&gt; [1] 13
#&gt; 
#&gt; [[14]][[2]]
#&gt; tensor([7.9970])
#&gt; 
#&gt; 
#&gt; [[15]]
#&gt; [[15]][[1]]
#&gt; [1] 14
#&gt; 
#&gt; [[15]][[2]]
#&gt; tensor([3.1000])</code></pre>
</div>
<div id="for-loop-for-iteration" class="section level3">
<h3><span class="header-section-number">3.5.3</span> <code>for-loop</code> for iteration</h3>
<p>Another way of iterating through a dataset that you will see a lot in the PyTorch tutorials is a <code>loop</code> through the length of the dataset. In this case, <code>x_train</code>. We are using <code>cat()</code> for the index (an integer), and <code>print()</code> for the tensor, since <code>cat</code> doesn’t know how to deal with tensors:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" title="1"><span class="co"># reset the iterator</span></a>
<a class="sourceLine" id="cb83-2" title="2">enum_x_train =<span class="st"> </span>py<span class="op">$</span><span class="kw">enumerate</span>(x_train)</a>
<a class="sourceLine" id="cb83-3" title="3"></a>
<a class="sourceLine" id="cb83-4" title="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>py<span class="op">$</span><span class="kw">len</span>(x_train)) {</a>
<a class="sourceLine" id="cb83-5" title="5">    obj &lt;-<span class="st"> </span><span class="kw">iter_next</span>(enum_x_train)    <span class="co"># next item</span></a>
<a class="sourceLine" id="cb83-6" title="6">    <span class="kw">cat</span>(obj[[<span class="dv">1</span>]], <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)     <span class="co"># 1st part or index</span></a>
<a class="sourceLine" id="cb83-7" title="7">    <span class="kw">print</span>(obj[[<span class="dv">2</span>]])         <span class="co"># 2nd part or tensor</span></a>
<a class="sourceLine" id="cb83-8" title="8">}</a></code></pre></div>
<pre><code>#&gt; 0    tensor([3.3000])
#&gt; 1    tensor([4.4000])
#&gt; 2    tensor([5.5000])
#&gt; 3    tensor([6.7100])
#&gt; 4    tensor([6.9300])
#&gt; 5    tensor([4.1680])
#&gt; 6    tensor([9.7790])
#&gt; 7    tensor([6.1820])
#&gt; 8    tensor([7.5900])
#&gt; 9    tensor([2.1670])
#&gt; 10   tensor([7.0420])
#&gt; 11   tensor([10.7910])
#&gt; 12   tensor([5.3130])
#&gt; 13   tensor([7.9970])
#&gt; 14   tensor([3.1000])</code></pre>
<p>Similarly, if we want the scalar values but not as tensor, then we will need to use <code>item()</code>.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" title="1"><span class="co"># reset the iterator</span></a>
<a class="sourceLine" id="cb85-2" title="2">enum_x_train =<span class="st"> </span>py<span class="op">$</span><span class="kw">enumerate</span>(x_train)</a>
<a class="sourceLine" id="cb85-3" title="3"></a>
<a class="sourceLine" id="cb85-4" title="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>py<span class="op">$</span><span class="kw">len</span>(x_train)) {</a>
<a class="sourceLine" id="cb85-5" title="5">    obj &lt;-<span class="st"> </span><span class="kw">iter_next</span>(enum_x_train)    <span class="co"># next item</span></a>
<a class="sourceLine" id="cb85-6" title="6">    <span class="kw">cat</span>(obj[[<span class="dv">1</span>]], <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)               <span class="co"># 1st part or index</span></a>
<a class="sourceLine" id="cb85-7" title="7">    <span class="kw">print</span>(obj[[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">item</span>())            <span class="co"># 2nd part or tensor</span></a>
<a class="sourceLine" id="cb85-8" title="8">}</a></code></pre></div>
<pre><code>#&gt; 0    [1] 3.3
#&gt; 1    [1] 4.4
#&gt; 2    [1] 5.5
#&gt; 3    [1] 6.71
#&gt; 4    [1] 6.93
#&gt; 5    [1] 4.17
#&gt; 6    [1] 9.78
#&gt; 7    [1] 6.18
#&gt; 8    [1] 7.59
#&gt; 9    [1] 2.17
#&gt; 10   [1] 7.04
#&gt; 11   [1] 10.8
#&gt; 12   [1] 5.31
#&gt; 13   [1] 8
#&gt; 14   [1] 3.1</code></pre>
<blockquote>
<p>We will find very frequently this kind of iterators when we read a dataset read by <code>torchvision</code>. There are several different ways to iterate through these objects as you will find.</p>
</blockquote>
</div>
</div>
<div id="zero-gradient" class="section level2">
<h2><span class="header-section-number">3.6</span> Zero gradient</h2>
<p>The zero gradient was one of the most difficult to implement in R if we don’t pay attention to the content of the objects carrying the <strong>weights</strong> and <strong>biases</strong>. This happens when the algorithm written in <strong>PyTorch</strong> is not immediately translatable to <strong>rTorch</strong>. This can be appreciated in this example.</p>
<blockquote>
<p>We are using the same seed in the PyTorch and rTorch versions, so, we could compare the results.</p>
</blockquote>
<div id="code-version-in-python" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Code version in Python</h3>
<div class="sourceCode" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb87-1" title="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb87-2" title="2"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb87-3" title="3"></a>
<a class="sourceLine" id="cb87-4" title="4">torch.manual_seed(<span class="dv">0</span>)  <span class="co"># reproducible</span></a>
<a class="sourceLine" id="cb87-5" title="5"></a>
<a class="sourceLine" id="cb87-6" title="6"><span class="co"># Input (temp, rainfall, humidity)</span></a></code></pre></div>
<pre><code>#&gt; &lt;torch._C.Generator object at 0x7f42c604e250&gt;</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb89-1" title="1">inputs <span class="op">=</span> np.array([[<span class="dv">73</span>, <span class="dv">67</span>, <span class="dv">43</span>],</a>
<a class="sourceLine" id="cb89-2" title="2">                   [<span class="dv">91</span>, <span class="dv">88</span>, <span class="dv">64</span>],</a>
<a class="sourceLine" id="cb89-3" title="3">                   [<span class="dv">87</span>, <span class="dv">134</span>, <span class="dv">58</span>],</a>
<a class="sourceLine" id="cb89-4" title="4">                   [<span class="dv">102</span>, <span class="dv">43</span>, <span class="dv">37</span>],</a>
<a class="sourceLine" id="cb89-5" title="5">                   [<span class="dv">69</span>, <span class="dv">96</span>, <span class="dv">70</span>]], dtype<span class="op">=</span><span class="st">&#39;float32&#39;</span>)</a>
<a class="sourceLine" id="cb89-6" title="6"></a>
<a class="sourceLine" id="cb89-7" title="7"><span class="co"># Targets (apples, oranges)</span></a>
<a class="sourceLine" id="cb89-8" title="8">targets <span class="op">=</span> np.array([[<span class="dv">56</span>, <span class="dv">70</span>],</a>
<a class="sourceLine" id="cb89-9" title="9">                    [<span class="dv">81</span>, <span class="dv">101</span>],</a>
<a class="sourceLine" id="cb89-10" title="10">                    [<span class="dv">119</span>, <span class="dv">133</span>],</a>
<a class="sourceLine" id="cb89-11" title="11">                    [<span class="dv">22</span>, <span class="dv">37</span>],</a>
<a class="sourceLine" id="cb89-12" title="12">                    [<span class="dv">103</span>, <span class="dv">119</span>]], dtype<span class="op">=</span><span class="st">&#39;float32&#39;</span>)</a>
<a class="sourceLine" id="cb89-13" title="13">                    </a>
<a class="sourceLine" id="cb89-14" title="14"></a>
<a class="sourceLine" id="cb89-15" title="15"><span class="co"># Convert inputs and targets to tensors</span></a>
<a class="sourceLine" id="cb89-16" title="16">inputs  <span class="op">=</span> torch.from_numpy(inputs)</a>
<a class="sourceLine" id="cb89-17" title="17">targets <span class="op">=</span> torch.from_numpy(targets)</a>
<a class="sourceLine" id="cb89-18" title="18"></a>
<a class="sourceLine" id="cb89-19" title="19"><span class="co"># random weights and biases</span></a>
<a class="sourceLine" id="cb89-20" title="20">w <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb89-21" title="21">b <span class="op">=</span> torch.randn(<span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb89-22" title="22"></a>
<a class="sourceLine" id="cb89-23" title="23"><span class="co"># function for the model</span></a>
<a class="sourceLine" id="cb89-24" title="24"><span class="kw">def</span> model(x):</a>
<a class="sourceLine" id="cb89-25" title="25">  wt <span class="op">=</span> w.t()</a>
<a class="sourceLine" id="cb89-26" title="26">  mm <span class="op">=</span> x <span class="op">@</span> w.t()</a>
<a class="sourceLine" id="cb89-27" title="27">  <span class="cf">return</span> x <span class="op">@</span> w.t() <span class="op">+</span> b       <span class="co"># @ represents matrix multiplication in PyTorch</span></a>
<a class="sourceLine" id="cb89-28" title="28"></a>
<a class="sourceLine" id="cb89-29" title="29"><span class="co"># MSE loss function</span></a>
<a class="sourceLine" id="cb89-30" title="30"><span class="kw">def</span> mse(t1, t2):</a>
<a class="sourceLine" id="cb89-31" title="31">  diff <span class="op">=</span> t1 <span class="op">-</span> t2</a>
<a class="sourceLine" id="cb89-32" title="32">  <span class="cf">return</span> torch.<span class="bu">sum</span>(diff <span class="op">*</span> diff) <span class="op">/</span> diff.numel()</a>
<a class="sourceLine" id="cb89-33" title="33"></a>
<a class="sourceLine" id="cb89-34" title="34"><span class="co"># Running all together</span></a>
<a class="sourceLine" id="cb89-35" title="35"><span class="co"># Train for 100 epochs</span></a>
<a class="sourceLine" id="cb89-36" title="36"><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</a>
<a class="sourceLine" id="cb89-37" title="37">  preds <span class="op">=</span> model(inputs)</a>
<a class="sourceLine" id="cb89-38" title="38">  loss <span class="op">=</span> mse(preds, targets)</a>
<a class="sourceLine" id="cb89-39" title="39">  loss.backward()</a>
<a class="sourceLine" id="cb89-40" title="40">  <span class="cf">with</span> torch.no_grad():</a>
<a class="sourceLine" id="cb89-41" title="41">    w <span class="op">-=</span> w.grad <span class="op">*</span> <span class="fl">0.00001</span></a>
<a class="sourceLine" id="cb89-42" title="42">    b <span class="op">-=</span> b.grad <span class="op">*</span> <span class="fl">0.00001</span></a>
<a class="sourceLine" id="cb89-43" title="43">    w_gz <span class="op">=</span> w.grad.zero_()</a>
<a class="sourceLine" id="cb89-44" title="44">    b_gz <span class="op">=</span> b.grad.zero_()</a>
<a class="sourceLine" id="cb89-45" title="45">    </a>
<a class="sourceLine" id="cb89-46" title="46"><span class="co"># Calculate loss</span></a>
<a class="sourceLine" id="cb89-47" title="47">preds <span class="op">=</span> model(inputs)</a>
<a class="sourceLine" id="cb89-48" title="48">loss <span class="op">=</span> mse(preds, targets)</a>
<a class="sourceLine" id="cb89-49" title="49"><span class="bu">print</span>(<span class="st">&quot;Loss: &quot;</span>, loss)    </a>
<a class="sourceLine" id="cb89-50" title="50"></a>
<a class="sourceLine" id="cb89-51" title="51"><span class="co"># predictions</span></a></code></pre></div>
<pre><code>#&gt; Loss:  tensor(1270.1233, grad_fn=&lt;DivBackward0&gt;)</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb91-1" title="1"><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Predictions:&quot;</span>)</a></code></pre></div>
<pre><code>#&gt; 
#&gt; Predictions:</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb93-1" title="1">preds</a>
<a class="sourceLine" id="cb93-2" title="2"></a>
<a class="sourceLine" id="cb93-3" title="3"><span class="co"># Targets</span></a></code></pre></div>
<pre><code>#&gt; tensor([[ 69.3122,  80.2639],
#&gt;         [ 73.7528,  97.2381],
#&gt;         [118.3933, 124.7628],
#&gt;         [ 89.6111,  93.0286],
#&gt;         [ 47.3014,  80.6467]], grad_fn=&lt;AddBackward0&gt;)</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb95-1" title="1"><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Targets:&quot;</span>)</a></code></pre></div>
<pre><code>#&gt; 
#&gt; Targets:</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb97-1" title="1">targets</a></code></pre></div>
<pre><code>#&gt; tensor([[ 56.,  70.],
#&gt;         [ 81., 101.],
#&gt;         [119., 133.],
#&gt;         [ 22.,  37.],
#&gt;         [103., 119.]])</code></pre>
</div>
<div id="code-version-in-r" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Code version in R</h3>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1"><span class="kw">library</span>(rTorch)</a>
<a class="sourceLine" id="cb99-2" title="2"></a>
<a class="sourceLine" id="cb99-3" title="3">torch<span class="op">$</span><span class="kw">manual_seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb99-4" title="4"></a>
<a class="sourceLine" id="cb99-5" title="5">device =<span class="st"> </span>torch<span class="op">$</span><span class="kw">device</span>(<span class="st">&#39;cpu&#39;</span>)</a>
<a class="sourceLine" id="cb99-6" title="6"><span class="co"># Input (temp, rainfall, humidity)</span></a>
<a class="sourceLine" id="cb99-7" title="7">inputs =<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">73</span>, <span class="dv">67</span>, <span class="dv">43</span>),</a>
<a class="sourceLine" id="cb99-8" title="8">                   <span class="kw">list</span>(<span class="dv">91</span>, <span class="dv">88</span>, <span class="dv">64</span>),</a>
<a class="sourceLine" id="cb99-9" title="9">                   <span class="kw">list</span>(<span class="dv">87</span>, <span class="dv">134</span>, <span class="dv">58</span>),</a>
<a class="sourceLine" id="cb99-10" title="10">                   <span class="kw">list</span>(<span class="dv">102</span>, <span class="dv">43</span>, <span class="dv">37</span>),</a>
<a class="sourceLine" id="cb99-11" title="11">                   <span class="kw">list</span>(<span class="dv">69</span>, <span class="dv">96</span>, <span class="dv">70</span>)), <span class="dt">dtype=</span><span class="st">&#39;float32&#39;</span>)</a>
<a class="sourceLine" id="cb99-12" title="12"></a>
<a class="sourceLine" id="cb99-13" title="13"><span class="co"># Targets (apples, oranges)</span></a>
<a class="sourceLine" id="cb99-14" title="14">targets =<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">56</span>, <span class="dv">70</span>), </a>
<a class="sourceLine" id="cb99-15" title="15">                    <span class="kw">list</span>(<span class="dv">81</span>, <span class="dv">101</span>),</a>
<a class="sourceLine" id="cb99-16" title="16">                    <span class="kw">list</span>(<span class="dv">119</span>, <span class="dv">133</span>),</a>
<a class="sourceLine" id="cb99-17" title="17">                    <span class="kw">list</span>(<span class="dv">22</span>, <span class="dv">37</span>), </a>
<a class="sourceLine" id="cb99-18" title="18">                    <span class="kw">list</span>(<span class="dv">103</span>, <span class="dv">119</span>)), <span class="dt">dtype=</span><span class="st">&#39;float32&#39;</span>)</a>
<a class="sourceLine" id="cb99-19" title="19"></a>
<a class="sourceLine" id="cb99-20" title="20"></a>
<a class="sourceLine" id="cb99-21" title="21"><span class="co"># Convert inputs and targets to tensors</span></a>
<a class="sourceLine" id="cb99-22" title="22">inputs =<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(inputs)</a>
<a class="sourceLine" id="cb99-23" title="23">targets =<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(targets)</a>
<a class="sourceLine" id="cb99-24" title="24"></a>
<a class="sourceLine" id="cb99-25" title="25"><span class="co"># random numbers for weights and biases. Then convert to double()</span></a>
<a class="sourceLine" id="cb99-26" title="26">torch<span class="op">$</span><span class="kw">set_default_dtype</span>(torch<span class="op">$</span>float64)</a>
<a class="sourceLine" id="cb99-27" title="27"></a>
<a class="sourceLine" id="cb99-28" title="28">w =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L, <span class="dt">requires_grad=</span><span class="ot">TRUE</span>) <span class="co">#$double()</span></a>
<a class="sourceLine" id="cb99-29" title="29">b =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, <span class="dt">requires_grad=</span><span class="ot">TRUE</span>) <span class="co">#$double()</span></a>
<a class="sourceLine" id="cb99-30" title="30"></a>
<a class="sourceLine" id="cb99-31" title="31">model &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb99-32" title="32">  wt &lt;-<span class="st"> </span>w<span class="op">$</span><span class="kw">t</span>()</a>
<a class="sourceLine" id="cb99-33" title="33">  <span class="kw">return</span>(torch<span class="op">$</span><span class="kw">add</span>(torch<span class="op">$</span><span class="kw">mm</span>(x, wt), b))</a>
<a class="sourceLine" id="cb99-34" title="34">}</a>
<a class="sourceLine" id="cb99-35" title="35"></a>
<a class="sourceLine" id="cb99-36" title="36"><span class="co"># MSE loss</span></a>
<a class="sourceLine" id="cb99-37" title="37">mse =<span class="st"> </span><span class="cf">function</span>(t1, t2) {</a>
<a class="sourceLine" id="cb99-38" title="38">  diff &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(t1, t2)</a>
<a class="sourceLine" id="cb99-39" title="39">  mul &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sum</span>(torch<span class="op">$</span><span class="kw">mul</span>(diff, diff))</a>
<a class="sourceLine" id="cb99-40" title="40">  <span class="kw">return</span>(torch<span class="op">$</span><span class="kw">div</span>(mul, diff<span class="op">$</span><span class="kw">numel</span>()))</a>
<a class="sourceLine" id="cb99-41" title="41">}</a>
<a class="sourceLine" id="cb99-42" title="42"></a>
<a class="sourceLine" id="cb99-43" title="43"><span class="co"># Running all together</span></a>
<a class="sourceLine" id="cb99-44" title="44"><span class="co"># Adjust weights and reset gradients</span></a>
<a class="sourceLine" id="cb99-45" title="45"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>) {</a>
<a class="sourceLine" id="cb99-46" title="46">  preds =<span class="st"> </span><span class="kw">model</span>(inputs)</a>
<a class="sourceLine" id="cb99-47" title="47">  loss =<span class="st"> </span><span class="kw">mse</span>(preds, targets)</a>
<a class="sourceLine" id="cb99-48" title="48">  loss<span class="op">$</span><span class="kw">backward</span>()</a>
<a class="sourceLine" id="cb99-49" title="49">  <span class="kw">with</span>(torch<span class="op">$</span><span class="kw">no_grad</span>(), {</a>
<a class="sourceLine" id="cb99-50" title="50">    w<span class="op">$</span>data &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(w<span class="op">$</span>data, torch<span class="op">$</span><span class="kw">mul</span>(w<span class="op">$</span>grad, torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="fl">1e-5</span>)))</a>
<a class="sourceLine" id="cb99-51" title="51">    b<span class="op">$</span>data &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(b<span class="op">$</span>data, torch<span class="op">$</span><span class="kw">mul</span>(b<span class="op">$</span>grad, torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="fl">1e-5</span>)))</a>
<a class="sourceLine" id="cb99-52" title="52">    </a>
<a class="sourceLine" id="cb99-53" title="53">    w<span class="op">$</span>grad<span class="op">$</span><span class="kw">zero_</span>()</a>
<a class="sourceLine" id="cb99-54" title="54">    b<span class="op">$</span>grad<span class="op">$</span><span class="kw">zero_</span>()</a>
<a class="sourceLine" id="cb99-55" title="55">  })</a>
<a class="sourceLine" id="cb99-56" title="56">}</a>
<a class="sourceLine" id="cb99-57" title="57"></a>
<a class="sourceLine" id="cb99-58" title="58"><span class="co"># Calculate loss</span></a>
<a class="sourceLine" id="cb99-59" title="59">preds =<span class="st"> </span><span class="kw">model</span>(inputs)</a>
<a class="sourceLine" id="cb99-60" title="60">loss =<span class="st"> </span><span class="kw">mse</span>(preds, targets)</a>
<a class="sourceLine" id="cb99-61" title="61"><span class="kw">cat</span>(<span class="st">&quot;Loss: &quot;</span>); <span class="kw">print</span>(loss)</a>
<a class="sourceLine" id="cb99-62" title="62"></a>
<a class="sourceLine" id="cb99-63" title="63"><span class="co"># predictions</span></a>
<a class="sourceLine" id="cb99-64" title="64"><span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Predictions:</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb99-65" title="65">preds</a>
<a class="sourceLine" id="cb99-66" title="66"></a>
<a class="sourceLine" id="cb99-67" title="67"><span class="co"># Targets</span></a>
<a class="sourceLine" id="cb99-68" title="68"><span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Targets:</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb99-69" title="69">targets</a></code></pre></div>
<pre><code>#&gt; &lt;torch._C.Generator&gt;
#&gt; Loss: tensor(1270.1237, grad_fn=&lt;DivBackward0&gt;)
#&gt; 
#&gt; Predictions:
#&gt; tensor([[ 69.3122,  80.2639],
#&gt;         [ 73.7528,  97.2381],
#&gt;         [118.3933, 124.7628],
#&gt;         [ 89.6111,  93.0286],
#&gt;         [ 47.3013,  80.6467]], grad_fn=&lt;AddBackward0&gt;)
#&gt; 
#&gt; Targets:
#&gt; tensor([[ 56.,  70.],
#&gt;         [ 81., 101.],
#&gt;         [119., 133.],
#&gt;         [ 22.,  37.],
#&gt;         [103., 119.]])</code></pre>
<p>Notice that while we are in Python, the tensor operation, gradient (<span class="math inline">\(\nabla\)</span>) of the weights <span class="math inline">\(w\)</span> times the <strong>Learning Rate</strong> <span class="math inline">\(\alpha\)</span>, is:</p>
<p><span class="math display">\[w = -w + \nabla w \; \alpha\]</span></p>
<p>In Python, it is a very straight forwward and clean code:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb101-1" title="1">w <span class="op">-=</span> w.grad <span class="op">*</span> <span class="fl">1e-5</span></a></code></pre></div>
<p>In R, without generics, it shows a little bit more convoluted:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1">w<span class="op">$</span>data &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(w<span class="op">$</span>data, torch<span class="op">$</span><span class="kw">mul</span>(w<span class="op">$</span>grad, torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="fl">1e-5</span>)))</a></code></pre></div>
</div>
</div>
<div id="r-generic-functions" class="section level2">
<h2><span class="header-section-number">3.7</span> R generic functions</h2>
<p>Which why we simplified these common operations using the R generic function. When we use the generic methods from <strong>rTorch</strong> the operation looks much neater.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" title="1">w<span class="op">$</span>data &lt;-<span class="st"> </span>w<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>w<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span><span class="fl">1e-5</span></a></code></pre></div>
<p>The following two expressions are equivalent, with the first being the long version natural way of doing it in <strong>PyTorch</strong>. The second is using the generics in R for subtraction, multiplication and scalar conversion.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1">param<span class="op">$</span>data &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(param<span class="op">$</span>data,</a>
<a class="sourceLine" id="cb104-2" title="2">                        torch<span class="op">$</span><span class="kw">mul</span>(param<span class="op">$</span>grad<span class="op">$</span><span class="kw">float</span>(),</a>
<a class="sourceLine" id="cb104-3" title="3">                          torch<span class="op">$</span><span class="kw">scalar_tensor</span>(learning_rate)))</a>
<a class="sourceLine" id="cb104-4" title="4"><span class="er">}</span></a></code></pre></div>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" title="1">param<span class="op">$</span>data &lt;-<span class="st"> </span>param<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>param<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span>learning_rate</a></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pytorch-and-numpy.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="converting-tensors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/f0nzie/rtorch-minimal-book/edit/main/0103-rtorch_pytorch_whats_different.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

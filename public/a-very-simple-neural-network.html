<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 A very simple neural network | A Minimal rTorch Book</title>
  <meta name="description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 A very simple neural network | A Minimal rTorch Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 A very simple neural network | A Minimal rTorch Book" />
  
  <meta name="twitter:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2020-10-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.15/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
      // R show code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('show');
      });
      // Python show code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      // Bash show code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      
  });
  $("#rmd-hide-all-code").click(function() {
      // close the dropdown menu when an option is clicked
      $("#allCodeButton").dropdown("toggle");
      // Hide R code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Python code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Bash code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('hide');
      });
  });


  // index for unique code element ids
  var r_currentIndex  = 1;   // for R code
  var py_currentIndex = 1;   // for Python code
  var sh_currentIndex  = 1;   // for shell code

  // select Python chunks
  var pyCodeBlocks = $('pre.python');
  pyCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse py-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'pycode-643E0F36' + py_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#ebfaeb');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Python code' : 'Python code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#009900');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Python code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Python code');
    });  
   });
  
  

  // select Bash shell chunks
  var shCodeBlocks = $('pre.bash');
  shCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse sh-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'shcode-643E0F36' + sh_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#A0A0A0');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Bash code' : 'Bash code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#cc7a00');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Bash code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Bash code');
    });  
   });  


  // select all R code blocks
  // var rCodeBlocks = $('pre.sourceCode, pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  // adding pre.sourceCode confuses the Python button
  var rCodeBlocks = $('pre.r, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + r_currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#e6faff'); // change color of chunk background

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide R code' : 'R code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);
    
    // change the background color of the button        
    showCodeButton.css('background-color','#0000ff');
    
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('R code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide R code');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  // show code by default. Use "show" === "hide" to hide
  window.initializeCodeFolding("show" === "show");
});
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The rTorch Minimal Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#callable-pytorch-modules"><i class="fa fa-check"></i><b>1.4</b> Callable PyTorch modules</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.4.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.4.2</b> <code>np</code>: the <code>numpy</code> module</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#create-an-array"><i class="fa fa-check"></i>Create an array</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#reshape-an-array"><i class="fa fa-check"></i>Reshape an array</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#generate-a-random-array"><i class="fa fa-check"></i>Generate a random array</a></li>
<li><a href="intro.html#convert-a-numpy-array-to-a-pytorch-tensor">Convert a <code>numpy</code> array to a PyTorch tensor</a></li>
</ul></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.4.3</b> Python built-in functions</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#length-of-a-dataset"><i class="fa fa-check"></i>Length of a dataset</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#iterators"><i class="fa fa-check"></i>Iterators</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#types-and-instances"><i class="fa fa-check"></i>Types and instances</a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html"><i class="fa fa-check"></i><b>2</b> PyTorch and NumPy</a><ul>
<li class="chapter" data-level="2.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#callable-pytorch-modules-from-rtorch"><i class="fa fa-check"></i><b>2.1</b> Callable PyTorch modules from rTorch</a><ul>
<li class="chapter" data-level="2.1.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#the-torchvision-module-1"><i class="fa fa-check"></i><b>2.1.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="2.1.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#the-numpy-module"><i class="fa fa-check"></i><b>2.1.2</b> The <code>numpy</code> module</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#create-an-array-1"><i class="fa fa-check"></i>Create an array</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#common-array-and-tensor-operations-in-numpy-and-pytorch"><i class="fa fa-check"></i><b>2.2</b> Common array and tensor operations in NumPy and PyTorch</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#reshape-an-array-1"><i class="fa fa-check"></i>Reshape an array</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#generate-a-random-array-in-numpy"><i class="fa fa-check"></i>Generate a random array in NumPy</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#generate-a-random-array-in-pytorch"><i class="fa fa-check"></i>Generate a random array in PyTorch</a></li>
<li><a href="pytorch-and-numpy.html#convert-a-numpy-array-to-a-pytorch-tensor-1">Convert a <code>numpy</code> array to a PyTorch tensor</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#python-built-in-functions-1"><i class="fa fa-check"></i><b>2.3</b> Python built-in functions</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#length-of-a-dataset-1"><i class="fa fa-check"></i>Length of a dataset</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#iterators-1"><i class="fa fa-check"></i>Iterators</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#types-and-instances-1"><i class="fa fa-check"></i>Types and instances</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>3</b> rTorch vs PyTorch: Whatâ€™s different</a><ul>
<li class="chapter" data-level="3.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>3.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="3.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-modules-and-functions-from-torch"><i class="fa fa-check"></i><b>3.2</b> Call modules and functions from <code>torch</code></a></li>
<li class="chapter" data-level="3.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>3.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="3.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate-through-datasets"><i class="fa fa-check"></i><b>3.4</b> How to iterate through datasets</a><ul>
<li class="chapter" data-level="3.4.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>3.4.1</b> Enumeration</a></li>
<li class="chapter" data-level="3.4.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>3.4.2</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="3.4.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>3.4.3</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>3.5</b> Zero gradient</a><ul>
<li class="chapter" data-level="3.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>3.5.1</b> Version in Python</a></li>
<li class="chapter" data-level="3.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#r-generics-for-pytorch-functions"><i class="fa fa-check"></i><b>3.6</b> R generics for PyTorch functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="converting-tensors.html"><a href="converting-tensors.html"><i class="fa fa-check"></i><b>4</b> Converting tensors</a><ul>
<li class="chapter" data-level="4.1" data-path="converting-tensors.html"><a href="converting-tensors.html#transforming-a-tensor-from-numpy-and-viceversa"><i class="fa fa-check"></i><b>4.1</b> Transforming a tensor from <code>numpy</code> and viceversa</a><ul>
<li class="chapter" data-level="4.1.1" data-path="converting-tensors.html"><a href="converting-tensors.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>4.1.1</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="4.1.2" data-path="converting-tensors.html"><a href="converting-tensors.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>4.1.2</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="converting-tensors.html"><a href="converting-tensors.html#transforming-a-tensor-from-pytorch-to-r-and-viceversa"><i class="fa fa-check"></i><b>4.2</b> Transforming a tensor from PyTorch to R and viceversa</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="5" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>5</b> Tensors</a><ul>
<li class="chapter" data-level="5.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>5.1</b> Tensor data types</a></li>
<li class="chapter" data-level="5.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>5.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="5.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>5.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="5.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>5.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>5.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="5.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>5.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="5.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>5.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="5.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>5.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>5.4</b> Create tensors</a></li>
<li class="chapter" data-level="5.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>5.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="5.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>5.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>5.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="5.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>5.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="5.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>5.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>5.7</b> Special tensors</a><ul>
<li class="chapter" data-level="5.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>5.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="5.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>5.7.2</b> Ones</a></li>
<li class="chapter" data-level="5.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>5.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>5.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="5.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>5.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="5.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>5.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>5.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="5.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>5.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="5.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>5.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>5.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="5.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>5.10.1</b> Cross product</a></li>
<li class="chapter" data-level="5.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>5.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>5.11</b> Logical operations</a><ul>
<li class="chapter" data-level="5.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>5.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>5.12</b> Distributions</a><ul>
<li class="chapter" data-level="5.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>5.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="5.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>5.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="5.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>5.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>5.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>6</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="6.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>6.1</b> Scalars</a></li>
<li class="chapter" data-level="6.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>6.2</b> Vectors</a></li>
<li class="chapter" data-level="6.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>6.3</b> Matrices</a></li>
<li class="chapter" data-level="6.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>6.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="6.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>6.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="6.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>6.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="6.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>6.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="6.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>6.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="6.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>6.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="6.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>6.10</b> Dot product</a><ul>
<li class="chapter" data-level="6.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-python"><i class="fa fa-check"></i><b>6.10.1</b> Dot product of 2D array using Python</a></li>
<li class="chapter" data-level="6.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-r"><i class="fa fa-check"></i><b>6.10.2</b> Dot product of 2D array using R</a></li>
<li class="chapter" data-level="6.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-with-mm-and-matmul-functions"><i class="fa fa-check"></i><b>6.10.3</b> Dot product with <code>mm</code> and <code>matmul</code> functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html"><i class="fa fa-check"></i><b>7</b> Creating PyTorch classes</a><ul>
<li class="chapter" data-level="7.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#build-a-pytorch-model-class"><i class="fa fa-check"></i><b>7.1</b> Build a PyTorch model class</a><ul>
<li class="chapter" data-level="7.1.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-1-a-neural-network-with-one-layer"><i class="fa fa-check"></i><b>7.1.1</b> Example 1: a neural network with one layer</a></li>
<li class="chapter" data-level="7.1.2" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>7.1.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="8" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>8</b> Example 1 (R): MNIST handwritten digits</a><ul>
<li class="chapter" data-level="8.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>8.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="8.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>8.2</b> Read datasets</a></li>
<li class="chapter" data-level="8.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>8.3</b> Define the model</a></li>
<li class="chapter" data-level="8.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>8.4</b> Training</a></li>
<li class="chapter" data-level="8.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>8.5</b> Prediction</a></li>
<li class="chapter" data-level="8.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>8.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="example-1-python-mnist-handwritten-digits.html"><a href="example-1-python-mnist-handwritten-digits.html"><i class="fa fa-check"></i><b>9</b> Example 1 (Python): MNIST handwritten digits</a></li>
<li class="chapter" data-level="10" data-path="example-2-a-classification-problem-with-logistic-regression.html"><a href="example-2-a-classification-problem-with-logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Example 2: A classification problem with Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="example-2-a-classification-problem-with-logistic-regression.html"><a href="example-2-a-classification-problem-with-logistic-regression.html#code-in-python"><i class="fa fa-check"></i><b>10.1</b> Code in Python</a></li>
</ul></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="11" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Simple linear regression</a><ul>
<li class="chapter" data-level="11.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>11.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="11.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>11.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="11.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>11.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="11.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>11.5</b> Creating the network model</a></li>
<li class="chapter" data-level="11.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>11.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="11.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>11.7</b> Training</a></li>
<li class="chapter" data-level="11.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>11.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Rainfall prediction with Linear Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#training-data"><i class="fa fa-check"></i><b>12.1</b> Training data</a></li>
<li class="chapter" data-level="12.2" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>12.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="12.3" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>12.3</b> Build the model</a></li>
<li class="chapter" data-level="12.4" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>12.4</b> Generate predictions</a></li>
<li class="chapter" data-level="12.5" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>12.5</b> Loss Function</a></li>
<li class="chapter" data-level="12.6" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>12.6</b> Step by step process</a><ul>
<li class="chapter" data-level="12.6.1" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>12.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="12.6.2" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>12.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="12.6.3" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>12.6.3</b> Reset the gradients</a><ul>
<li class="chapter" data-level="12.6.3.1" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#adjust-weights-and-biases-using-gradient-descent"><i class="fa fa-check"></i><b>12.6.3.1</b> Adjust weights and biases using gradient descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>12.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="13" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><i class="fa fa-check"></i><b>13</b> Neural Networks using NumPy, r-base, rTorch and PyTorch</a><ul>
<li class="chapter" data-level="13.1" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#a-neural-network-with-numpy"><i class="fa fa-check"></i><b>13.1</b> A neural network with <code>numpy</code></a></li>
<li class="chapter" data-level="13.2" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#a-neural-network-with-r-base"><i class="fa fa-check"></i><b>13.2</b> A neural network with <code>r-base</code></a></li>
<li class="chapter" data-level="13.3" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#a-neural-network-in-rtorch"><i class="fa fa-check"></i><b>13.3</b> A neural network in <code>rTorch</code></a><ul>
<li class="chapter" data-level="13.3.1" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#load-the-libraries"><i class="fa fa-check"></i><b>13.3.1</b> Load the libraries</a></li>
<li class="chapter" data-level="13.3.2" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#dataset"><i class="fa fa-check"></i><b>13.3.2</b> Dataset</a></li>
<li class="chapter" data-level="13.3.3" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#initialize-the-weights"><i class="fa fa-check"></i><b>13.3.3</b> Initialize the weights</a></li>
<li class="chapter" data-level="13.3.4" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#iterate-through-the-dataset"><i class="fa fa-check"></i><b>13.3.4</b> Iterate through the dataset</a><ul>
<li class="chapter" data-level="13.3.4.1" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#iterate-50-times"><i class="fa fa-check"></i><b>13.3.4.1</b> Iterate 50 times</a></li>
</ul></li>
<li class="chapter" data-level="13.3.5" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>13.3.5</b> Run it at 100 iterations</a><ul>
<li class="chapter" data-level="13.3.5.1" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#iterations"><i class="fa fa-check"></i><b>13.3.5.1</b> 200 iterations</a></li>
<li class="chapter" data-level="13.3.5.2" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#iterations-1"><i class="fa fa-check"></i><b>13.3.5.2</b> 500 iterations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#same-neural-network-but-written-in-pytorch"><i class="fa fa-check"></i><b>13.4</b> Same neural network but written in <code>PyTorch</code></a></li>
<li class="chapter" data-level="13.5" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#original-pytorch-code"><i class="fa fa-check"></i><b>13.5</b> Original PyTorch code</a></li>
<li class="chapter" data-level="13.6" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#exercise"><i class="fa fa-check"></i><b>13.6</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>14</b> A very simple neural network</a><ul>
<li class="chapter" data-level="14.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>14.2</b> Select device</a></li>
<li class="chapter" data-level="14.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>14.3</b> Create the dataset</a></li>
<li class="chapter" data-level="14.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>14.4</b> Define the model</a></li>
<li class="chapter" data-level="14.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>14.5</b> Loss function</a></li>
<li class="chapter" data-level="14.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>14.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="a-very-simple-neural-network" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> A very simple neural network</h1>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">14.1</span> Introduction</h2>
<p>Source: <a href="https://github.com/jcjohnson/pytorch-examples#pytorch-nn" class="uri">https://github.com/jcjohnson/pytorch-examples#pytorch-nn</a></p>
<p>In this example we use the torch <code>nn</code> package to implement our two-layer network:</p>
</div>
<div id="select-device" class="section level2">
<h2><span class="header-section-number">14.2</span> Select device</h2>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="a-very-simple-neural-network.html#cb563-1"></a><span class="kw">library</span>(rTorch)</span>
<span id="cb563-2"><a href="a-very-simple-neural-network.html#cb563-2"></a></span>
<span id="cb563-3"><a href="a-very-simple-neural-network.html#cb563-3"></a>device =<span class="st"> </span>torch<span class="op">$</span><span class="kw">device</span>(<span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb563-4"><a href="a-very-simple-neural-network.html#cb563-4"></a></span>
<span id="cb563-5"><a href="a-very-simple-neural-network.html#cb563-5"></a><span class="co"># device = torch.device(&#39;cuda&#39;) # Uncomment this to run on GPU</span></span></code></pre></div>
<ul>
<li><code>N</code> is batch size;</li>
<li><code>D_in</code> is input dimension;</li>
<li><code>H</code> is hidden dimension;</li>
<li><code>D_out</code> is output dimension.</li>
</ul>
</div>
<div id="create-the-dataset" class="section level2">
<h2><span class="header-section-number">14.3</span> Create the dataset</h2>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="a-very-simple-neural-network.html#cb564-1"></a>torch<span class="op">$</span><span class="kw">manual_seed</span>(<span class="dv">0</span>)</span>
<span id="cb564-2"><a href="a-very-simple-neural-network.html#cb564-2"></a></span>
<span id="cb564-3"><a href="a-very-simple-neural-network.html#cb564-3"></a>N &lt;-<span class="st"> </span>64L; D_in &lt;-<span class="st"> </span>1000L; H &lt;-<span class="st"> </span>100L; D_out &lt;-<span class="st"> </span>10L</span>
<span id="cb564-4"><a href="a-very-simple-neural-network.html#cb564-4"></a></span>
<span id="cb564-5"><a href="a-very-simple-neural-network.html#cb564-5"></a><span class="co"># Create random Tensors to hold inputs and outputs</span></span>
<span id="cb564-6"><a href="a-very-simple-neural-network.html#cb564-6"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(N, D_in, <span class="dt">device=</span>device)</span>
<span id="cb564-7"><a href="a-very-simple-neural-network.html#cb564-7"></a>y =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(N, D_out, <span class="dt">device=</span>device)</span></code></pre></div>
<pre><code>#&gt; &lt;torch._C.Generator&gt;</code></pre>
</div>
<div id="define-the-model-1" class="section level2">
<h2><span class="header-section-number">14.4</span> Define the model</h2>
<p>Use the <code>nn</code> package to define our model as a sequence of layers. <code>nn.Sequential</code> is a Module which contains other Modules, and applies them in sequence to produce its output. Each Linear Module computes output from input using a linear function, and holds internal Tensors for its weight and bias.
After constructing the model we use the <code>.to()</code> method to move it to the
desired device.</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="a-very-simple-neural-network.html#cb566-1"></a>model &lt;-<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Sequential</span>(</span>
<span id="cb566-2"><a href="a-very-simple-neural-network.html#cb566-2"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(D_in, H),              <span class="co"># first layer</span></span>
<span id="cb566-3"><a href="a-very-simple-neural-network.html#cb566-3"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">ReLU</span>(),</span>
<span id="cb566-4"><a href="a-very-simple-neural-network.html#cb566-4"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(H, D_out))<span class="op">$</span><span class="kw">to</span>(device)  <span class="co"># output layer</span></span>
<span id="cb566-5"><a href="a-very-simple-neural-network.html#cb566-5"></a></span>
<span id="cb566-6"><a href="a-very-simple-neural-network.html#cb566-6"></a><span class="kw">print</span>(model)</span></code></pre></div>
<pre><code>#&gt; Sequential(
#&gt;   (0): Linear(in_features=1000, out_features=100, bias=True)
#&gt;   (1): ReLU()
#&gt;   (2): Linear(in_features=100, out_features=10, bias=True)
#&gt; )</code></pre>
</div>
<div id="loss-function-1" class="section level2">
<h2><span class="header-section-number">14.5</span> Loss function</h2>
<p>The <code>nn</code> package also contains definitions of popular loss functions; in this case we will use Mean Squared Error (<strong>MSE</strong>) as our loss function. Setting <code>reduction='sum'</code> means that we are computing the <em>sum</em> of squared errors rather than the mean; this is for consistency with the examples above where we manually compute the loss, but in practice it is more common to use mean squared error as a loss by setting <code>reduction='elementwise_mean'</code>.</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="a-very-simple-neural-network.html#cb568-1"></a>loss_fn =<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">MSELoss</span>(<span class="dt">reduction =</span> <span class="st">&#39;sum&#39;</span>)</span></code></pre></div>
</div>
<div id="iterate-through-batches" class="section level2">
<h2><span class="header-section-number">14.6</span> Iterate through batches</h2>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="a-very-simple-neural-network.html#cb569-1"></a>learning_rate =<span class="st"> </span><span class="fl">1e-4</span></span>
<span id="cb569-2"><a href="a-very-simple-neural-network.html#cb569-2"></a></span>
<span id="cb569-3"><a href="a-very-simple-neural-network.html#cb569-3"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">500</span>) {</span>
<span id="cb569-4"><a href="a-very-simple-neural-network.html#cb569-4"></a>  <span class="co"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span>
<span id="cb569-5"><a href="a-very-simple-neural-network.html#cb569-5"></a>  <span class="co"># override the __call__ operator so you can call them like functions. When</span></span>
<span id="cb569-6"><a href="a-very-simple-neural-network.html#cb569-6"></a>  <span class="co"># doing so you pass a Tensor of input data to the Module and it produces</span></span>
<span id="cb569-7"><a href="a-very-simple-neural-network.html#cb569-7"></a>  <span class="co"># a Tensor of output data.</span></span>
<span id="cb569-8"><a href="a-very-simple-neural-network.html#cb569-8"></a>  y_pred =<span class="st"> </span><span class="kw">model</span>(x)</span>
<span id="cb569-9"><a href="a-very-simple-neural-network.html#cb569-9"></a></span>
<span id="cb569-10"><a href="a-very-simple-neural-network.html#cb569-10"></a>  <span class="co"># Compute and print loss. We pass Tensors containing the predicted and true</span></span>
<span id="cb569-11"><a href="a-very-simple-neural-network.html#cb569-11"></a>  <span class="co"># values of y, and the loss function returns a Tensor containing the loss.</span></span>
<span id="cb569-12"><a href="a-very-simple-neural-network.html#cb569-12"></a>  loss =<span class="st"> </span><span class="kw">loss_fn</span>(y_pred, y)</span>
<span id="cb569-13"><a href="a-very-simple-neural-network.html#cb569-13"></a>  </span>
<span id="cb569-14"><a href="a-very-simple-neural-network.html#cb569-14"></a>  <span class="kw">cat</span>(t, <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)</span>
<span id="cb569-15"><a href="a-very-simple-neural-network.html#cb569-15"></a>  <span class="kw">cat</span>(loss<span class="op">$</span><span class="kw">item</span>(), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb569-16"><a href="a-very-simple-neural-network.html#cb569-16"></a>  </span>
<span id="cb569-17"><a href="a-very-simple-neural-network.html#cb569-17"></a>  <span class="co"># Zero the gradients before running the backward pass.</span></span>
<span id="cb569-18"><a href="a-very-simple-neural-network.html#cb569-18"></a>  model<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb569-19"><a href="a-very-simple-neural-network.html#cb569-19"></a></span>
<span id="cb569-20"><a href="a-very-simple-neural-network.html#cb569-20"></a>  <span class="co"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span>
<span id="cb569-21"><a href="a-very-simple-neural-network.html#cb569-21"></a>  <span class="co"># parameters of the model. Internally, the parameters of each Module are stored</span></span>
<span id="cb569-22"><a href="a-very-simple-neural-network.html#cb569-22"></a>  <span class="co"># in Tensors with requires_grad=True, so this call will compute gradients for</span></span>
<span id="cb569-23"><a href="a-very-simple-neural-network.html#cb569-23"></a>  <span class="co"># all learnable parameters in the model.</span></span>
<span id="cb569-24"><a href="a-very-simple-neural-network.html#cb569-24"></a>  loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb569-25"><a href="a-very-simple-neural-network.html#cb569-25"></a></span>
<span id="cb569-26"><a href="a-very-simple-neural-network.html#cb569-26"></a>  <span class="co"># Update the weights using gradient descent. Each parameter is a Tensor, so</span></span>
<span id="cb569-27"><a href="a-very-simple-neural-network.html#cb569-27"></a>  <span class="co"># we can access its data and gradients like we did before.</span></span>
<span id="cb569-28"><a href="a-very-simple-neural-network.html#cb569-28"></a>  <span class="kw">with</span>(torch<span class="op">$</span><span class="kw">no_grad</span>(), {</span>
<span id="cb569-29"><a href="a-very-simple-neural-network.html#cb569-29"></a>      <span class="cf">for</span> (param <span class="cf">in</span> <span class="kw">iterate</span>(model<span class="op">$</span><span class="kw">parameters</span>())) {</span>
<span id="cb569-30"><a href="a-very-simple-neural-network.html#cb569-30"></a>        <span class="co"># in Python this code is much simpler. In R we have to do some conversions</span></span>
<span id="cb569-31"><a href="a-very-simple-neural-network.html#cb569-31"></a>        </span>
<span id="cb569-32"><a href="a-very-simple-neural-network.html#cb569-32"></a>        <span class="co"># param$data &lt;- torch$sub(param$data,</span></span>
<span id="cb569-33"><a href="a-very-simple-neural-network.html#cb569-33"></a>        <span class="co">#                         torch$mul(param$grad$float(),</span></span>
<span id="cb569-34"><a href="a-very-simple-neural-network.html#cb569-34"></a>        <span class="co">#                           torch$scalar_tensor(learning_rate)))</span></span>
<span id="cb569-35"><a href="a-very-simple-neural-network.html#cb569-35"></a>        </span>
<span id="cb569-36"><a href="a-very-simple-neural-network.html#cb569-36"></a>        param<span class="op">$</span>data &lt;-<span class="st"> </span>param<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>param<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span>learning_rate</span>
<span id="cb569-37"><a href="a-very-simple-neural-network.html#cb569-37"></a>      }</span>
<span id="cb569-38"><a href="a-very-simple-neural-network.html#cb569-38"></a>   })</span>
<span id="cb569-39"><a href="a-very-simple-neural-network.html#cb569-39"></a>}  </span></code></pre></div>
<pre><code>#&gt; 1    628 
#&gt; 2    585 
#&gt; 3    547 
#&gt; 4    513 
#&gt; 5    482 
#&gt; 6    455 
#&gt; 7    430 
#&gt; 8    406 
#&gt; 9    385 
#&gt; 10   364 
#&gt; 11   345 
#&gt; 12   328 
#&gt; 13   311 
#&gt; 14   295 
#&gt; 15   280 
#&gt; 16   265 
#&gt; 17   252 
#&gt; 18   239 
#&gt; 19   226 
#&gt; 20   214 
#&gt; 21   203 
#&gt; 22   192 
#&gt; 23   181 
#&gt; 24   172 
#&gt; 25   162 
#&gt; 26   153 
#&gt; 27   145 
#&gt; 28   137 
#&gt; 29   129 
#&gt; 30   122 
#&gt; 31   115 
#&gt; 32   109 
#&gt; 33   103 
#&gt; 34   96.9 
#&gt; 35   91.5 
#&gt; 36   86.3 
#&gt; 37   81.5 
#&gt; 38   76.9 
#&gt; 39   72.6 
#&gt; 40   68.5 
#&gt; 41   64.6 
#&gt; 42   61 
#&gt; 43   57.6 
#&gt; 44   54.3 
#&gt; 45   51.3 
#&gt; 46   48.5 
#&gt; 47   45.8 
#&gt; 48   43.2 
#&gt; 49   40.9 
#&gt; 50   38.6 
#&gt; 51   36.5 
#&gt; 52   34.5 
#&gt; 53   32.7 
#&gt; 54   30.9 
#&gt; 55   29.3 
#&gt; 56   27.8 
#&gt; 57   26.3 
#&gt; 58   24.9 
#&gt; 59   23.7 
#&gt; 60   22.4 
#&gt; 61   21.3 
#&gt; 62   20.2 
#&gt; 63   19.2 
#&gt; 64   18.2 
#&gt; 65   17.3 
#&gt; 66   16.5 
#&gt; 67   15.7 
#&gt; 68   14.9 
#&gt; 69   14.2 
#&gt; 70   13.5 
#&gt; 71   12.9 
#&gt; 72   12.3 
#&gt; 73   11.7 
#&gt; 74   11.1 
#&gt; 75   10.6 
#&gt; 76   10.1 
#&gt; 77   9.67 
#&gt; 78   9.24 
#&gt; 79   8.82 
#&gt; 80   8.42 
#&gt; 81   8.05 
#&gt; 82   7.69 
#&gt; 83   7.35 
#&gt; 84   7.03 
#&gt; 85   6.72 
#&gt; 86   6.43 
#&gt; 87   6.16 
#&gt; 88   5.9 
#&gt; 89   5.65 
#&gt; 90   5.41 
#&gt; 91   5.18 
#&gt; 92   4.97 
#&gt; 93   4.76 
#&gt; 94   4.57 
#&gt; 95   4.38 
#&gt; 96   4.2 
#&gt; 97   4.03 
#&gt; 98   3.87 
#&gt; 99   3.72 
#&gt; 100  3.57 
#&gt; 101  3.43 
#&gt; 102  3.29 
#&gt; 103  3.17 
#&gt; 104  3.04 
#&gt; 105  2.92 
#&gt; 106  2.81 
#&gt; 107  2.7 
#&gt; 108  2.6 
#&gt; 109  2.5 
#&gt; 110  2.41 
#&gt; 111  2.31 
#&gt; 112  2.23 
#&gt; 113  2.14 
#&gt; 114  2.06 
#&gt; 115  1.99 
#&gt; 116  1.91 
#&gt; 117  1.84 
#&gt; 118  1.77 
#&gt; 119  1.71 
#&gt; 120  1.65 
#&gt; 121  1.59 
#&gt; 122  1.53 
#&gt; 123  1.47 
#&gt; 124  1.42 
#&gt; 125  1.37 
#&gt; 126  1.32 
#&gt; 127  1.27 
#&gt; 128  1.23 
#&gt; 129  1.18 
#&gt; 130  1.14 
#&gt; 131  1.1 
#&gt; 132  1.06 
#&gt; 133  1.02 
#&gt; 134  0.989 
#&gt; 135  0.954 
#&gt; 136  0.921 
#&gt; 137  0.889 
#&gt; 138  0.858 
#&gt; 139  0.828 
#&gt; 140  0.799 
#&gt; 141  0.772 
#&gt; 142  0.745 
#&gt; 143  0.719 
#&gt; 144  0.695 
#&gt; 145  0.671 
#&gt; 146  0.648 
#&gt; 147  0.626 
#&gt; 148  0.605 
#&gt; 149  0.584 
#&gt; 150  0.564 
#&gt; 151  0.545 
#&gt; 152  0.527 
#&gt; 153  0.509 
#&gt; 154  0.492 
#&gt; 155  0.476 
#&gt; 156  0.46 
#&gt; 157  0.444 
#&gt; 158  0.43 
#&gt; 159  0.415 
#&gt; 160  0.402 
#&gt; 161  0.388 
#&gt; 162  0.375 
#&gt; 163  0.363 
#&gt; 164  0.351 
#&gt; 165  0.339 
#&gt; 166  0.328 
#&gt; 167  0.318 
#&gt; 168  0.307 
#&gt; 169  0.297 
#&gt; 170  0.287 
#&gt; 171  0.278 
#&gt; 172  0.269 
#&gt; 173  0.26 
#&gt; 174  0.252 
#&gt; 175  0.244 
#&gt; 176  0.236 
#&gt; 177  0.228 
#&gt; 178  0.221 
#&gt; 179  0.214 
#&gt; 180  0.207 
#&gt; 181  0.2 
#&gt; 182  0.194 
#&gt; 183  0.187 
#&gt; 184  0.181 
#&gt; 185  0.176 
#&gt; 186  0.17 
#&gt; 187  0.165 
#&gt; 188  0.159 
#&gt; 189  0.154 
#&gt; 190  0.149 
#&gt; 191  0.145 
#&gt; 192  0.14 
#&gt; 193  0.136 
#&gt; 194  0.131 
#&gt; 195  0.127 
#&gt; 196  0.123 
#&gt; 197  0.119 
#&gt; 198  0.115 
#&gt; 199  0.112 
#&gt; 200  0.108 
#&gt; 201  0.105 
#&gt; 202  0.102 
#&gt; 203  0.0983 
#&gt; 204  0.0952 
#&gt; 205  0.0923 
#&gt; 206  0.0894 
#&gt; 207  0.0866 
#&gt; 208  0.0838 
#&gt; 209  0.0812 
#&gt; 210  0.0787 
#&gt; 211  0.0762 
#&gt; 212  0.0739 
#&gt; 213  0.0716 
#&gt; 214  0.0693 
#&gt; 215  0.0672 
#&gt; 216  0.0651 
#&gt; 217  0.0631 
#&gt; 218  0.0611 
#&gt; 219  0.0592 
#&gt; 220  0.0574 
#&gt; 221  0.0556 
#&gt; 222  0.0539 
#&gt; 223  0.0522 
#&gt; 224  0.0506 
#&gt; 225  0.0491 
#&gt; 226  0.0476 
#&gt; 227  0.0461 
#&gt; 228  0.0447 
#&gt; 229  0.0433 
#&gt; 230  0.042 
#&gt; 231  0.0407 
#&gt; 232  0.0394 
#&gt; 233  0.0382 
#&gt; 234  0.0371 
#&gt; 235  0.0359 
#&gt; 236  0.0348 
#&gt; 237  0.0338 
#&gt; 238  0.0327 
#&gt; 239  0.0317 
#&gt; 240  0.0308 
#&gt; 241  0.0298 
#&gt; 242  0.0289 
#&gt; 243  0.028 
#&gt; 244  0.0272 
#&gt; 245  0.0263 
#&gt; 246  0.0255 
#&gt; 247  0.0248 
#&gt; 248  0.024 
#&gt; 249  0.0233 
#&gt; 250  0.0226 
#&gt; 251  0.0219 
#&gt; 252  0.0212 
#&gt; 253  0.0206 
#&gt; 254  0.02 
#&gt; 255  0.0194 
#&gt; 256  0.0188 
#&gt; 257  0.0182 
#&gt; 258  0.0177 
#&gt; 259  0.0171 
#&gt; 260  0.0166 
#&gt; 261  0.0161 
#&gt; 262  0.0156 
#&gt; 263  0.0151 
#&gt; 264  0.0147 
#&gt; 265  0.0142 
#&gt; 266  0.0138 
#&gt; 267  0.0134 
#&gt; 268  0.013 
#&gt; 269  0.0126 
#&gt; 270  0.0122 
#&gt; 271  0.0119 
#&gt; 272  0.0115 
#&gt; 273  0.0112 
#&gt; 274  0.0108 
#&gt; 275  0.0105 
#&gt; 276  0.0102 
#&gt; 277  0.00988 
#&gt; 278  0.00959 
#&gt; 279  0.0093 
#&gt; 280  0.00902 
#&gt; 281  0.00875 
#&gt; 282  0.00849 
#&gt; 283  0.00824 
#&gt; 284  0.00799 
#&gt; 285  0.00775 
#&gt; 286  0.00752 
#&gt; 287  0.0073 
#&gt; 288  0.00708 
#&gt; 289  0.00687 
#&gt; 290  0.00666 
#&gt; 291  0.00647 
#&gt; 292  0.00627 
#&gt; 293  0.00609 
#&gt; 294  0.00591 
#&gt; 295  0.00573 
#&gt; 296  0.00556 
#&gt; 297  0.0054 
#&gt; 298  0.00524 
#&gt; 299  0.00508 
#&gt; 300  0.00493 
#&gt; 301  0.00478 
#&gt; 302  0.00464 
#&gt; 303  0.0045 
#&gt; 304  0.00437 
#&gt; 305  0.00424 
#&gt; 306  0.00412 
#&gt; 307  0.00399 
#&gt; 308  0.00388 
#&gt; 309  0.00376 
#&gt; 310  0.00365 
#&gt; 311  0.00354 
#&gt; 312  0.00344 
#&gt; 313  0.00334 
#&gt; 314  0.00324 
#&gt; 315  0.00314 
#&gt; 316  0.00305 
#&gt; 317  0.00296 
#&gt; 318  0.00287 
#&gt; 319  0.00279 
#&gt; 320  0.00271 
#&gt; 321  0.00263 
#&gt; 322  0.00255 
#&gt; 323  0.00248 
#&gt; 324  0.0024 
#&gt; 325  0.00233 
#&gt; 326  0.00226 
#&gt; 327  0.0022 
#&gt; 328  0.00213 
#&gt; 329  0.00207 
#&gt; 330  0.00201 
#&gt; 331  0.00195 
#&gt; 332  0.00189 
#&gt; 333  0.00184 
#&gt; 334  0.00178 
#&gt; 335  0.00173 
#&gt; 336  0.00168 
#&gt; 337  0.00163 
#&gt; 338  0.00158 
#&gt; 339  0.00154 
#&gt; 340  0.00149 
#&gt; 341  0.00145 
#&gt; 342  0.00141 
#&gt; 343  0.00137 
#&gt; 344  0.00133 
#&gt; 345  0.00129 
#&gt; 346  0.00125 
#&gt; 347  0.00121 
#&gt; 348  0.00118 
#&gt; 349  0.00114 
#&gt; 350  0.00111 
#&gt; 351  0.00108 
#&gt; 352  0.00105 
#&gt; 353  0.00102 
#&gt; 354  0.000987 
#&gt; 355  0.000958 
#&gt; 356  0.000931 
#&gt; 357  0.000904 
#&gt; 358  0.000877 
#&gt; 359  0.000852 
#&gt; 360  0.000827 
#&gt; 361  0.000803 
#&gt; 362  0.00078 
#&gt; 363  0.000757 
#&gt; 364  0.000735 
#&gt; 365  0.000714 
#&gt; 366  0.000693 
#&gt; 367  0.000673 
#&gt; 368  0.000654 
#&gt; 369  0.000635 
#&gt; 370  0.000617 
#&gt; 371  0.000599 
#&gt; 372  0.000581 
#&gt; 373  0.000565 
#&gt; 374  0.000548 
#&gt; 375  0.000532 
#&gt; 376  0.000517 
#&gt; 377  0.000502 
#&gt; 378  0.000488 
#&gt; 379  0.000474 
#&gt; 380  0.00046 
#&gt; 381  0.000447 
#&gt; 382  0.000434 
#&gt; 383  0.000421 
#&gt; 384  0.000409 
#&gt; 385  0.000397 
#&gt; 386  0.000386 
#&gt; 387  0.000375 
#&gt; 388  0.000364 
#&gt; 389  0.000354 
#&gt; 390  0.000343 
#&gt; 391  0.000334 
#&gt; 392  0.000324 
#&gt; 393  0.000315 
#&gt; 394  0.000306 
#&gt; 395  0.000297 
#&gt; 396  0.000288 
#&gt; 397  0.00028 
#&gt; 398  0.000272 
#&gt; 399  0.000264 
#&gt; 400  0.000257 
#&gt; 401  0.000249 
#&gt; 402  0.000242 
#&gt; 403  0.000235 
#&gt; 404  0.000228 
#&gt; 405  0.000222 
#&gt; 406  0.000216 
#&gt; 407  0.000209 
#&gt; 408  0.000203 
#&gt; 409  0.000198 
#&gt; 410  0.000192 
#&gt; 411  0.000186 
#&gt; 412  0.000181 
#&gt; 413  0.000176 
#&gt; 414  0.000171 
#&gt; 415  0.000166 
#&gt; 416  0.000161 
#&gt; 417  0.000157 
#&gt; 418  0.000152 
#&gt; 419  0.000148 
#&gt; 420  0.000144 
#&gt; 421  0.00014 
#&gt; 422  0.000136 
#&gt; 423  0.000132 
#&gt; 424  0.000128 
#&gt; 425  0.000124 
#&gt; 426  0.000121 
#&gt; 427  0.000117 
#&gt; 428  0.000114 
#&gt; 429  0.000111 
#&gt; 430  0.000108 
#&gt; 431  0.000105 
#&gt; 432  0.000102 
#&gt; 433  9.87e-05 
#&gt; 434  9.59e-05 
#&gt; 435  9.32e-05 
#&gt; 436  9.06e-05 
#&gt; 437  8.8e-05 
#&gt; 438  8.55e-05 
#&gt; 439  8.31e-05 
#&gt; 440  8.07e-05 
#&gt; 441  7.84e-05 
#&gt; 442  7.62e-05 
#&gt; 443  7.4e-05 
#&gt; 444  7.2e-05 
#&gt; 445  6.99e-05 
#&gt; 446  6.79e-05 
#&gt; 447  6.6e-05 
#&gt; 448  6.41e-05 
#&gt; 449  6.23e-05 
#&gt; 450  6.06e-05 
#&gt; 451  5.89e-05 
#&gt; 452  5.72e-05 
#&gt; 453  5.56e-05 
#&gt; 454  5.4e-05 
#&gt; 455  5.25e-05 
#&gt; 456  5.1e-05 
#&gt; 457  4.96e-05 
#&gt; 458  4.82e-05 
#&gt; 459  4.68e-05 
#&gt; 460  4.55e-05 
#&gt; 461  4.42e-05 
#&gt; 462  4.3e-05 
#&gt; 463  4.18e-05 
#&gt; 464  4.06e-05 
#&gt; 465  3.94e-05 
#&gt; 466  3.83e-05 
#&gt; 467  3.72e-05 
#&gt; 468  3.62e-05 
#&gt; 469  3.52e-05 
#&gt; 470  3.42e-05 
#&gt; 471  3.32e-05 
#&gt; 472  3.23e-05 
#&gt; 473  3.14e-05 
#&gt; 474  3.05e-05 
#&gt; 475  2.96e-05 
#&gt; 476  2.88e-05 
#&gt; 477  2.8e-05 
#&gt; 478  2.72e-05 
#&gt; 479  2.65e-05 
#&gt; 480  2.57e-05 
#&gt; 481  2.5e-05 
#&gt; 482  2.43e-05 
#&gt; 483  2.36e-05 
#&gt; 484  2.29e-05 
#&gt; 485  2.23e-05 
#&gt; 486  2.17e-05 
#&gt; 487  2.11e-05 
#&gt; 488  2.05e-05 
#&gt; 489  1.99e-05 
#&gt; 490  1.94e-05 
#&gt; 491  1.88e-05 
#&gt; 492  1.83e-05 
#&gt; 493  1.78e-05 
#&gt; 494  1.73e-05 
#&gt; 495  1.68e-05 
#&gt; 496  1.63e-05 
#&gt; 497  1.59e-05 
#&gt; 498  1.54e-05 
#&gt; 499  1.5e-05 
#&gt; 500  1.46e-05</code></pre>
<p>These two expressions are equivalent, with the first being the long version natural way of doing it in <strong>PyTorch</strong>. The second is using the generics in R for subtraction, multiplication and scalar conversion.</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="a-very-simple-neural-network.html#cb571-1"></a>param<span class="op">$</span>data &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(param<span class="op">$</span>data,</span>
<span id="cb571-2"><a href="a-very-simple-neural-network.html#cb571-2"></a>                        torch<span class="op">$</span><span class="kw">mul</span>(param<span class="op">$</span>grad<span class="op">$</span><span class="kw">float</span>(),</span>
<span id="cb571-3"><a href="a-very-simple-neural-network.html#cb571-3"></a>                          torch<span class="op">$</span><span class="kw">scalar_tensor</span>(learning_rate)))</span></code></pre></div>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="a-very-simple-neural-network.html#cb572-1"></a>param<span class="op">$</span>data &lt;-<span class="st"> </span>param<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>param<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span>learning_rate</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

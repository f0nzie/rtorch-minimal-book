<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 A step-by-step neural network in rTorch | A Minimal rTorch Book</title>
  <meta name="description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 A step-by-step neural network in rTorch | A Minimal rTorch Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 A step-by-step neural network in rTorch | A Minimal rTorch Book" />
  
  <meta name="twitter:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2020-10-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"/>
<link rel="next" href="working-with-data-frame.html"/>
<script src="libs/header-attrs-2.4.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.15/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
      // R show code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('show');
      });
      // Python show code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      // Bash show code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      
  });
  $("#rmd-hide-all-code").click(function() {
      // close the dropdown menu when an option is clicked
      $("#allCodeButton").dropdown("toggle");
      // Hide R code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Python code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Bash code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('hide');
      });
  });


  // index for unique code element ids
  var r_currentIndex  = 1;   // for R code
  var py_currentIndex = 1;   // for Python code
  var sh_currentIndex  = 1;   // for shell code

  // select Python chunks
  var pyCodeBlocks = $('pre.python');
  pyCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse py-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'pycode-643E0F36' + py_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#ebfaeb');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Python code' : 'Python code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#009900');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Python code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Python code');
    });  
   });
  
  

  // select Bash shell chunks
  var shCodeBlocks = $('pre.bash');
  shCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse sh-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'shcode-643E0F36' + sh_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#A0A0A0');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Bash code' : 'Bash code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#cc7a00');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Bash code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Bash code');
    });  
   });  


  // select all R code blocks
  // var rCodeBlocks = $('pre.sourceCode, pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  // adding pre.sourceCode confuses the Python button
  var rCodeBlocks = $('pre.r, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + r_currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#e6faff'); // change color of chunk background

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide R code' : 'R code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);
    
    // change the background color of the button        
    showCodeButton.css('background-color','#0000ff');
    
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('R code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide R code');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  // show code by default. Use "show" === "hide" to hide
  window.initializeCodeFolding("show" === "show");
});
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The rTorch Minimal Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#getting-help"><i class="fa fa-check"></i><b>1.4</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html"><i class="fa fa-check"></i><b>2</b> PyTorch and NumPy</a>
<ul>
<li class="chapter" data-level="2.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#callable-pytorch-modules-from-rtorch"><i class="fa fa-check"></i><b>2.1</b> Callable PyTorch modules from rTorch</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#the-torchvision-module"><i class="fa fa-check"></i><b>2.1.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="2.1.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#the-numpy-module"><i class="fa fa-check"></i><b>2.1.2</b> The <code>numpy</code> module</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#common-array-and-tensor-operations-in-numpy-and-pytorch"><i class="fa fa-check"></i><b>2.2</b> Common array and tensor operations in NumPy and PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#python-built-in-functions"><i class="fa fa-check"></i><b>2.3</b> Python built-in functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>3</b> rTorch vs PyTorch: What’s different</a>
<ul>
<li class="chapter" data-level="3.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>3.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="3.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-modules-and-functions-from-torch"><i class="fa fa-check"></i><b>3.2</b> Call modules and functions from <code>torch</code></a></li>
<li class="chapter" data-level="3.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>3.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="3.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate-through-datasets"><i class="fa fa-check"></i><b>3.4</b> How to iterate through datasets</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>3.4.1</b> Enumeration</a></li>
<li class="chapter" data-level="3.4.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>3.4.2</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="3.4.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>3.4.3</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>3.5</b> Zero gradient</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>3.5.1</b> Version in Python</a></li>
<li class="chapter" data-level="3.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#r-generics-for-pytorch-functions"><i class="fa fa-check"></i><b>3.6</b> R generics for PyTorch functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="converting-tensors.html"><a href="converting-tensors.html"><i class="fa fa-check"></i><b>4</b> Converting tensors</a>
<ul>
<li class="chapter" data-level="4.1" data-path="converting-tensors.html"><a href="converting-tensors.html#transforming-a-tensor-from-numpy-and-viceversa"><i class="fa fa-check"></i><b>4.1</b> Transforming a tensor from <code>numpy</code> and viceversa</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="converting-tensors.html"><a href="converting-tensors.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>4.1.1</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="4.1.2" data-path="converting-tensors.html"><a href="converting-tensors.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>4.1.2</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="converting-tensors.html"><a href="converting-tensors.html#transforming-a-tensor-from-pytorch-to-r-and-viceversa"><i class="fa fa-check"></i><b>4.2</b> Transforming a tensor from PyTorch to R and viceversa</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="5" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>5</b> Tensors</a>
<ul>
<li class="chapter" data-level="5.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>5.1</b> Tensor data types</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="tensors.html"><a href="tensors.html#major-tensor-types"><i class="fa fa-check"></i><b>5.1.1</b> Major tensor types</a></li>
<li class="chapter" data-level="5.1.2" data-path="tensors.html"><a href="tensors.html#example-basic-attributes-of-a-4d-tensor"><i class="fa fa-check"></i><b>5.1.2</b> Example: Basic attributes of a 4D tensor</a></li>
<li class="chapter" data-level="5.1.3" data-path="tensors.html"><a href="tensors.html#example-attributes-of-a-3d-tensor"><i class="fa fa-check"></i><b>5.1.3</b> Example: Attributes of a 3D tensor</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>5.2</b> Arithmetic of tensors</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>5.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="5.2.2" data-path="tensors.html"><a href="tensors.html#add-an-element-of-a-tensor-to-another-tensor"><i class="fa fa-check"></i><b>5.2.2</b> Add an element of a tensor to another tensor</a></li>
<li class="chapter" data-level="5.2.3" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>5.2.3</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>5.3</b> NumPy and PyTorch</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="tensors.html"><a href="tensors.html#in-python-we-use-tuples-in-r-we-use-vectors"><i class="fa fa-check"></i><b>5.3.1</b> In Python we use Tuples, in R we use vectors</a></li>
<li class="chapter" data-level="5.3.2" data-path="tensors.html"><a href="tensors.html#build-a-numpy-array-from-three-r-vectors"><i class="fa fa-check"></i><b>5.3.2</b> Build a numpy array from three R vectors</a></li>
<li class="chapter" data-level="5.3.3" data-path="tensors.html"><a href="tensors.html#convert-a-numpy-array-to-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>5.3.3</b> Convert a numpy array to a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="5.3.4" data-path="tensors.html"><a href="tensors.html#create-and-fill-a-tensor"><i class="fa fa-check"></i><b>5.3.4</b> Create and fill a tensor</a></li>
<li class="chapter" data-level="5.3.5" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>5.3.5</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>5.4</b> Create tensors</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>5.4.1</b> Tensor fill</a></li>
<li class="chapter" data-level="5.4.2" data-path="tensors.html"><a href="tensors.html#initialize-tensor-with-a-range-of-values"><i class="fa fa-check"></i><b>5.4.2</b> Initialize Tensor with a range of values</a></li>
<li class="chapter" data-level="5.4.3" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>5.4.3</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="5.4.4" data-path="tensors.html"><a href="tensors.html#fill-a-tensor-in-place-out-of-place"><i class="fa fa-check"></i><b>5.4.4</b> Fill a tensor In-place / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>5.5</b> Tensor resizing</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="tensors.html"><a href="tensors.html#exercise"><i class="fa fa-check"></i><b>5.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>5.6</b> Concatenate tensors</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors-by-dim0-rows"><i class="fa fa-check"></i><b>5.6.1</b> Concatenate tensors by <code>dim=0</code> (rows)</a></li>
<li class="chapter" data-level="5.6.2" data-path="tensors.html"><a href="tensors.html#concatenate-tensors-by-dim1-columns"><i class="fa fa-check"></i><b>5.6.2</b> Concatenate tensors by <code>dim=1</code> (columns)</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>5.7</b> Reshape tensors</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="tensors.html"><a href="tensors.html#with-chunk"><i class="fa fa-check"></i><b>5.7.1</b> With <code>chunk()</code>:</a></li>
<li class="chapter" data-level="5.7.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>5.7.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>5.8</b> Special tensors</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>5.8.1</b> Identity matrix</a></li>
<li class="chapter" data-level="5.8.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>5.8.2</b> Ones</a></li>
<li class="chapter" data-level="5.8.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>5.8.3</b> Zeros</a></li>
<li class="chapter" data-level="5.8.4" data-path="tensors.html"><a href="tensors.html#diagonal-operations"><i class="fa fa-check"></i><b>5.8.4</b> Diagonal operations</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>5.9</b> Access to tensor elements</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>5.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="5.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>5.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>5.10</b> Other tensor operations</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>5.10.1</b> Cross product</a></li>
<li class="chapter" data-level="5.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>5.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>5.11</b> Logical operations</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="tensors.html"><a href="tensors.html#using-a-function-to-extract-a-unique-logical-result"><i class="fa fa-check"></i><b>5.11.1</b> Using a function to extract a unique logical result</a></li>
<li class="chapter" data-level="5.11.2" data-path="tensors.html"><a href="tensors.html#greater-than-gt"><i class="fa fa-check"></i><b>5.11.2</b> Greater than (<code>gt</code>)</a></li>
<li class="chapter" data-level="5.11.3" data-path="tensors.html"><a href="tensors.html#less-than-or-equal-le"><i class="fa fa-check"></i><b>5.11.3</b> Less than or equal (<code>le</code>)</a></li>
<li class="chapter" data-level="5.11.4" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>5.11.4</b> Logical NOT (<code>!</code>)</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>5.12</b> Distributions</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>5.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="5.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>5.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="5.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>5.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>5.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>6</b> Linear Algebra with Torch</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>6.1</b> Scalars</a></li>
<li class="chapter" data-level="6.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>6.2</b> Vectors</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="linearalgebra.html"><a href="linearalgebra.html#vector-to-matrix-matrix-to-tensor"><i class="fa fa-check"></i><b>6.2.1</b> Vector to matrix, matrix to tensor</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>6.3</b> Matrices</a></li>
<li class="chapter" data-level="6.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>6.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="6.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>6.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="6.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>6.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="6.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>6.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="6.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>6.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="6.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>6.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="6.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>6.10</b> Dot product</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-python"><i class="fa fa-check"></i><b>6.10.1</b> Dot product of 2D array using Python</a></li>
<li class="chapter" data-level="6.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-r"><i class="fa fa-check"></i><b>6.10.2</b> Dot product of 2D array using R</a></li>
<li class="chapter" data-level="6.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-with-mm-and-matmul-functions"><i class="fa fa-check"></i><b>6.10.3</b> Dot product with <code>mm</code> and <code>matmul</code> functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html"><i class="fa fa-check"></i><b>7</b> Creating PyTorch classes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#build-a-pytorch-model-class"><i class="fa fa-check"></i><b>7.1</b> Build a PyTorch model class</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-1-a-neural-network-with-one-layer"><i class="fa fa-check"></i><b>7.1.1</b> Example 1: a neural network with one layer</a></li>
<li class="chapter" data-level="7.1.2" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>7.1.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="8" data-path="example-1-a-classification-problem-with-logistic-regression.html"><a href="example-1-a-classification-problem-with-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Example 1: A classification problem with Logistic Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="example-1-a-classification-problem-with-logistic-regression.html"><a href="example-1-a-classification-problem-with-logistic-regression.html#code-in-python"><i class="fa fa-check"></i><b>8.1</b> Code in Python</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>9</b> Example 2: MNIST handwritten digits</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mnistdigits.html"><a href="mnistdigits.html#code-in-r"><i class="fa fa-check"></i><b>9.1</b> Code in R</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>9.1.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="9.1.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>9.1.2</b> Read datasets</a></li>
<li class="chapter" data-level="9.1.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>9.1.3</b> Define the model</a></li>
<li class="chapter" data-level="9.1.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>9.1.4</b> Training</a></li>
<li class="chapter" data-level="9.1.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>9.1.5</b> Prediction</a></li>
<li class="chapter" data-level="9.1.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>9.1.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="mnistdigits.html"><a href="mnistdigits.html#code-in-python-1"><i class="fa fa-check"></i><b>9.2</b> Code in Python</a></li>
</ul></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="10" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>10</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="linear-regression.html"><a href="linear-regression.html#introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="linear-regression.html"><a href="linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>10.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="10.3" data-path="linear-regression.html"><a href="linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>10.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="10.4" data-path="linear-regression.html"><a href="linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>10.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="10.5" data-path="linear-regression.html"><a href="linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>10.5</b> Creating the network model</a></li>
<li class="chapter" data-level="10.6" data-path="linear-regression.html"><a href="linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>10.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="10.7" data-path="linear-regression.html"><a href="linear-regression.html#training-1"><i class="fa fa-check"></i><b>10.7</b> Training</a></li>
<li class="chapter" data-level="10.8" data-path="linear-regression.html"><a href="linear-regression.html#results"><i class="fa fa-check"></i><b>10.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Rainfall prediction with Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#training-data"><i class="fa fa-check"></i><b>11.1</b> Training data</a></li>
<li class="chapter" data-level="11.2" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>11.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="11.3" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>11.3</b> Build the model</a></li>
<li class="chapter" data-level="11.4" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>11.4</b> Generate predictions</a></li>
<li class="chapter" data-level="11.5" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>11.5</b> Loss Function</a></li>
<li class="chapter" data-level="11.6" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>11.6</b> Step by step process</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>11.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="11.6.2" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>11.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="11.6.3" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>11.6.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="rainfall-prediction-with-linear-regression.html"><a href="rainfall-prediction-with-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>11.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="12" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><i class="fa fa-check"></i><b>12</b> Neural Networks using NumPy, r-base, rTorch and PyTorch</a>
<ul>
<li class="chapter" data-level="12.1" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#a-neural-network-with-numpy"><i class="fa fa-check"></i><b>12.1</b> A neural network with <code>numpy</code></a></li>
<li class="chapter" data-level="12.2" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#a-neural-network-with-r-base"><i class="fa fa-check"></i><b>12.2</b> A neural network with <code>r-base</code></a></li>
<li class="chapter" data-level="12.3" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#the-neural-network-written-in-pytorch"><i class="fa fa-check"></i><b>12.3</b> The neural network written in <code>PyTorch</code></a></li>
<li class="chapter" data-level="12.4" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#a-neural-network-written-in-rtorch"><i class="fa fa-check"></i><b>12.4</b> A neural network written in <code>rTorch</code></a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#load-the-libraries"><i class="fa fa-check"></i><b>12.4.1</b> Load the libraries</a></li>
<li class="chapter" data-level="12.4.2" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#dataset"><i class="fa fa-check"></i><b>12.4.2</b> Dataset</a></li>
<li class="chapter" data-level="12.4.3" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#initialize-the-weights"><i class="fa fa-check"></i><b>12.4.3</b> Initialize the weights</a></li>
<li class="chapter" data-level="12.4.4" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#iterate-through-the-dataset"><i class="fa fa-check"></i><b>12.4.4</b> Iterate through the dataset</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#complete-code-for-neural-network-in-rtorch"><i class="fa fa-check"></i><b>12.5</b> Complete code for neural network in rTorch</a></li>
<li class="chapter" data-level="12.6" data-path="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html"><a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html#exercise-2"><i class="fa fa-check"></i><b>12.6</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html"><i class="fa fa-check"></i><b>13</b> A step-by-step neural network in rTorch</a>
<ul>
<li class="chapter" data-level="13.1" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#introduction-1"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#select-device"><i class="fa fa-check"></i><b>13.2</b> Select device</a></li>
<li class="chapter" data-level="13.3" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#create-the-dataset"><i class="fa fa-check"></i><b>13.3</b> Create the dataset</a></li>
<li class="chapter" data-level="13.4" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#define-the-model-1"><i class="fa fa-check"></i><b>13.4</b> Define the model</a></li>
<li class="chapter" data-level="13.5" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#the-loss-function"><i class="fa fa-check"></i><b>13.5</b> The Loss function</a></li>
<li class="chapter" data-level="13.6" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#iterate-through-the-dataset-1"><i class="fa fa-check"></i><b>13.6</b> Iterate through the dataset</a></li>
<li class="chapter" data-level="13.7" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#using-r-generics-to-simplify-tensor-operations"><i class="fa fa-check"></i><b>13.7</b> Using R generics to simplify tensor operations</a></li>
<li class="chapter" data-level="13.8" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#a-more-elegant-way-of-writing-the-neural-network"><i class="fa fa-check"></i><b>13.8</b> A more elegant way of writing the neural network</a></li>
<li class="chapter" data-level="13.9" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#create-a-browseable-dataframe"><i class="fa fa-check"></i><b>13.9</b> Create a browseable dataframe</a></li>
<li class="chapter" data-level="13.10" data-path="a-step-by-step-neural-network-in-rtorch.html"><a href="a-step-by-step-neural-network-in-rtorch.html#plot-the-loss-at-each-iteration"><i class="fa fa-check"></i><b>13.10</b> Plot the loss at each iteration</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="14" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>14</b> Working with data.frame</a>
<ul>
<li class="chapter" data-level="14.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>14.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="14.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>14.2</b> Load dataset</a></li>
<li class="chapter" data-level="14.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>14.3</b> Summary statistics for tensors</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>14.3.1</b> using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>15</b> Working with data.table</a>
<ul>
<li class="chapter" data-level="15.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>15.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="15.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>15.2</b> Load dataset</a></li>
<li class="chapter" data-level="15.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#read-the-datasets-without-normalization"><i class="fa fa-check"></i><b>15.3</b> Read the datasets without normalization</a></li>
<li class="chapter" data-level="15.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>15.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#the-sigmoid-function"><i class="fa fa-check"></i><b>B.1</b> The Sigmoid function</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#the-relu-function"><i class="fa fa-check"></i><b>B.2</b> The ReLU function</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#the-tanh-function"><i class="fa fa-check"></i><b>B.3</b> The tanh function</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#the-softmax-activation-function"><i class="fa fa-check"></i><b>B.4</b> The Softmax Activation function</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#coding-your-own-activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Coding your own activation functions in Python</a>
<ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li><a href="appendixB.html#visualization-with-matplotlib">Visualization with <code>matplotlib</code></a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="a-step-by-step-neural-network-in-rtorch" class="section level1" number="13">
<h1><span class="header-section-number">Chapter 13</span> A step-by-step neural network in rTorch</h1>
<div id="introduction-1" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Introduction</h2>
<p>Source: <a href="https://github.com/jcjohnson/pytorch-examples#pytorch-nn" class="uri">https://github.com/jcjohnson/pytorch-examples#pytorch-nn</a></p>
<p>In this example we use the torch <code>nn</code> package to implement our two-layer network:</p>
</div>
<div id="select-device" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Select device</h2>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb536-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rTorch)</span>
<span id="cb536-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb536-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb536-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb536-3" aria-hidden="true" tabindex="-1"></a>device <span class="ot">=</span> torch<span class="sc">$</span><span class="fu">device</span>(<span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb536-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb536-4" aria-hidden="true" tabindex="-1"></a><span class="co"># device = torch.device(&#39;cuda&#39;) # Uncomment this to run on GPU</span></span></code></pre></div>
<ul>
<li><code>N</code> is batch size;</li>
<li><code>D_in</code> is input dimension;</li>
<li><code>H</code> is hidden dimension;</li>
<li><code>D_out</code> is output dimension.</li>
</ul>
</div>
<div id="create-the-dataset" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Create the dataset</h2>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb537-1" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(torch<span class="sc">$</span><span class="fu">manual_seed</span>(<span class="dv">0</span>))   <span class="co"># do not show the generator output</span></span>
<span id="cb537-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb537-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> 64L; D_in <span class="ot">&lt;-</span> 1000L; H <span class="ot">&lt;-</span> 100L; D_out <span class="ot">&lt;-</span> 10L</span>
<span id="cb537-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb537-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb537-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb537-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create random Tensors to hold inputs and outputs</span></span>
<span id="cb537-5"><a href="a-step-by-step-neural-network-in-rtorch.html#cb537-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> torch<span class="sc">$</span><span class="fu">randn</span>(N, D_in, <span class="at">device=</span>device)</span>
<span id="cb537-6"><a href="a-step-by-step-neural-network-in-rtorch.html#cb537-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> torch<span class="sc">$</span><span class="fu">randn</span>(N, D_out, <span class="at">device=</span>device)</span></code></pre></div>
</div>
<div id="define-the-model-1" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> Define the model</h2>
<p>We use the <code>nn</code> package to define our model as a sequence of layers. <code>nn.Sequential</code> applies these leayers in sequence to produce an output. Each <em>Linear Module</em> computes the output by using a linear function, and holds also tensors for its weights and biases. After constructing the model we use the <code>.to()</code> method to move it to the desired device, which could be <code>CPU</code> or <code>GPU</code>. Remember that we selected <code>CPU</code> with <code>torch$device('cpu')</code>.</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb538-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb538-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb538-2" aria-hidden="true" tabindex="-1"></a>  torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">Linear</span>(D_in, H),              <span class="co"># first layer</span></span>
<span id="cb538-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb538-3" aria-hidden="true" tabindex="-1"></a>  torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">ReLU</span>(),</span>
<span id="cb538-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb538-4" aria-hidden="true" tabindex="-1"></a>  torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">Linear</span>(H, D_out))<span class="sc">$</span><span class="fu">to</span>(device)  <span class="co"># output layer</span></span>
<span id="cb538-5"><a href="a-step-by-step-neural-network-in-rtorch.html#cb538-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb538-6"><a href="a-step-by-step-neural-network-in-rtorch.html#cb538-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(model)</span></code></pre></div>
<pre><code>#&gt; Sequential(
#&gt;   (0): Linear(in_features=1000, out_features=100, bias=True)
#&gt;   (1): ReLU()
#&gt;   (2): Linear(in_features=100, out_features=10, bias=True)
#&gt; )</code></pre>
</div>
<div id="the-loss-function" class="section level2" number="13.5">
<h2><span class="header-section-number">13.5</span> The Loss function</h2>
<p>The <code>nn</code> package also contains definitions of several loss functions; in this case we will use <strong>Mean Squared Error</strong> (<span class="math inline">\(MSE\)</span>) as our loss function. Setting <code>reduction='sum'</code> means that we are computing the <em>sum</em> of squared errors rather than the <strong>mean</strong>; this is for consistency with the examples above where we manually compute the loss, but in practice it is more common to use the mean squared error as a loss by setting <code>reduction='elementwise_mean'</code>.</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb540-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="ot">=</span> torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">MSELoss</span>(<span class="at">reduction =</span> <span class="st">&#39;sum&#39;</span>)</span></code></pre></div>
</div>
<div id="iterate-through-the-dataset-1" class="section level2" number="13.6">
<h2><span class="header-section-number">13.6</span> Iterate through the dataset</h2>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="ot">=</span> <span class="fl">1e-4</span></span>
<span id="cb541-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb541-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>) {</span>
<span id="cb541-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span>
<span id="cb541-5"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># override the __call__ operator so you can call them like functions. When</span></span>
<span id="cb541-6"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># doing so you pass a Tensor of input data to the Module and it produces</span></span>
<span id="cb541-7"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># a Tensor of output data.</span></span>
<span id="cb541-8"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-8" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="ot">=</span> <span class="fu">model</span>(x)</span>
<span id="cb541-9"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb541-10"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute and print loss. We pass Tensors containing the predicted and true</span></span>
<span id="cb541-11"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># values of y, and the loss function returns a Tensor containing the loss.</span></span>
<span id="cb541-12"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-12" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">loss_fn</span>(y_pred, y)</span>
<span id="cb541-13"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(t, <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>)</span>
<span id="cb541-14"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(loss<span class="sc">$</span><span class="fu">item</span>(), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb541-15"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb541-16"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Zero the gradients before running the backward pass.</span></span>
<span id="cb541-17"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-17" aria-hidden="true" tabindex="-1"></a>  model<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb541-18"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb541-19"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span>
<span id="cb541-20"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># parameters of the model. Internally, the parameters of each Module are stored</span></span>
<span id="cb541-21"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># in Tensors with requires_grad=True, so this call will compute gradients for</span></span>
<span id="cb541-22"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># all learnable parameters in the model.</span></span>
<span id="cb541-23"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-23" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb541-24"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb541-25"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update the weights using gradient descent. Each parameter is a Tensor, so</span></span>
<span id="cb541-26"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># we can access its data and gradients like we did before.</span></span>
<span id="cb541-27"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(torch<span class="sc">$</span><span class="fu">no_grad</span>(), {</span>
<span id="cb541-28"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-28" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (param <span class="cf">in</span> <span class="fu">iterate</span>(model<span class="sc">$</span><span class="fu">parameters</span>())) {</span>
<span id="cb541-29"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># in Python this code is much simpler. In R we have to do some conversions</span></span>
<span id="cb541-30"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># param$data &lt;- torch$sub(param$data,</span></span>
<span id="cb541-31"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">#                         torch$mul(param$grad$float(),</span></span>
<span id="cb541-32"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-32" aria-hidden="true" tabindex="-1"></a>        <span class="co">#                           torch$scalar_tensor(learning_rate)))</span></span>
<span id="cb541-33"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-33" aria-hidden="true" tabindex="-1"></a>        param<span class="sc">$</span>data <span class="ot">&lt;-</span> param<span class="sc">$</span>data <span class="sc">-</span> param<span class="sc">$</span>grad <span class="sc">*</span> learning_rate</span>
<span id="cb541-34"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-34" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb541-35"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-35" aria-hidden="true" tabindex="-1"></a>   })</span>
<span id="cb541-36"><a href="a-step-by-step-neural-network-in-rtorch.html#cb541-36" aria-hidden="true" tabindex="-1"></a>}  </span></code></pre></div>
<pre><code>#&gt; 1    708 
#&gt; 2    658 
#&gt; 3    613 
#&gt; 4    575 
#&gt; 5    540 
#&gt; 6    508 
#&gt; 7    479 
#&gt; 8    452 
#&gt; 9    428 
#&gt; 10   404 
#&gt; 11   383 
#&gt; 12   362 
#&gt; 13   343 
#&gt; 14   325 
#&gt; 15   307 
#&gt; 16   291 
#&gt; 17   275 
#&gt; 18   261 
#&gt; 19   247 
#&gt; 20   233 
#&gt; 21   220 
#&gt; 22   208 
#&gt; 23   196 
#&gt; 24   185 
#&gt; 25   174 
#&gt; 26   164 
#&gt; 27   155 
#&gt; 28   146 
#&gt; 29   137 
#&gt; 30   129 
#&gt; 31   121 
#&gt; 32   114 
#&gt; 33   107 
#&gt; 34   100 
#&gt; 35   94.1 
#&gt; 36   88.4 
#&gt; 37   83 
#&gt; 38   77.9 
#&gt; 39   73.2 
#&gt; 40   68.7 
#&gt; 41   64.5 
#&gt; 42   60.6 
#&gt; 43   57 
#&gt; 44   53.5 
#&gt; 45   50.3 
#&gt; 46   47.3 
#&gt; 47   44.5 
#&gt; 48   41.8 
#&gt; 49   39.3 
#&gt; 50   37 
#&gt; 51   34.8 
#&gt; 52   32.8 
#&gt; 53   30.8 
#&gt; 54   29 
#&gt; 55   27.4 
#&gt; 56   25.8 
#&gt; 57   24.3 
#&gt; 58   22.9 
#&gt; 59   21.6 
#&gt; 60   20.4 
#&gt; 61   19.2 
#&gt; 62   18.1 
#&gt; 63   17.1 
#&gt; 64   16.2 
#&gt; 65   15.3 
#&gt; 66   14.4 
#&gt; 67   13.6 
#&gt; 68   12.9 
#&gt; 69   12.2 
#&gt; 70   11.5 
#&gt; 71   10.9 
#&gt; 72   10.3 
#&gt; 73   9.79 
#&gt; 74   9.27 
#&gt; 75   8.79 
#&gt; 76   8.32 
#&gt; 77   7.89 
#&gt; 78   7.48 
#&gt; 79   7.09 
#&gt; 80   6.73 
#&gt; 81   6.39 
#&gt; 82   6.06 
#&gt; 83   5.75 
#&gt; 84   5.47 
#&gt; 85   5.19 
#&gt; 86   4.93 
#&gt; 87   4.69 
#&gt; 88   4.46 
#&gt; 89   4.24 
#&gt; 90   4.03 
#&gt; 91   3.83 
#&gt; 92   3.65 
#&gt; 93   3.47 
#&gt; 94   3.3 
#&gt; 95   3.14 
#&gt; 96   2.99 
#&gt; 97   2.85 
#&gt; 98   2.72 
#&gt; 99   2.59 
#&gt; 100  2.47 
#&gt; 101  2.35 
#&gt; 102  2.24 
#&gt; 103  2.14 
#&gt; 104  2.04 
#&gt; 105  1.95 
#&gt; 106  1.86 
#&gt; 107  1.77 
#&gt; 108  1.69 
#&gt; 109  1.62 
#&gt; 110  1.54 
#&gt; 111  1.48 
#&gt; 112  1.41 
#&gt; 113  1.35 
#&gt; 114  1.29 
#&gt; 115  1.23 
#&gt; 116  1.18 
#&gt; 117  1.12 
#&gt; 118  1.08 
#&gt; 119  1.03 
#&gt; 120  0.985 
#&gt; 121  0.942 
#&gt; 122  0.902 
#&gt; 123  0.863 
#&gt; 124  0.826 
#&gt; 125  0.791 
#&gt; 126  0.758 
#&gt; 127  0.726 
#&gt; 128  0.695 
#&gt; 129  0.666 
#&gt; 130  0.638 
#&gt; 131  0.612 
#&gt; 132  0.586 
#&gt; 133  0.562 
#&gt; 134  0.539 
#&gt; 135  0.517 
#&gt; 136  0.496 
#&gt; 137  0.476 
#&gt; 138  0.457 
#&gt; 139  0.438 
#&gt; 140  0.421 
#&gt; 141  0.404 
#&gt; 142  0.388 
#&gt; 143  0.373 
#&gt; 144  0.358 
#&gt; 145  0.344 
#&gt; 146  0.33 
#&gt; 147  0.318 
#&gt; 148  0.305 
#&gt; 149  0.293 
#&gt; 150  0.282 
#&gt; 151  0.271 
#&gt; 152  0.261 
#&gt; 153  0.251 
#&gt; 154  0.241 
#&gt; 155  0.232 
#&gt; 156  0.223 
#&gt; 157  0.215 
#&gt; 158  0.207 
#&gt; 159  0.199 
#&gt; 160  0.192 
#&gt; 161  0.185 
#&gt; 162  0.178 
#&gt; 163  0.171 
#&gt; 164  0.165 
#&gt; 165  0.159 
#&gt; 166  0.153 
#&gt; 167  0.147 
#&gt; 168  0.142 
#&gt; 169  0.137 
#&gt; 170  0.132 
#&gt; 171  0.127 
#&gt; 172  0.123 
#&gt; 173  0.118 
#&gt; 174  0.114 
#&gt; 175  0.11 
#&gt; 176  0.106 
#&gt; 177  0.102 
#&gt; 178  0.0987 
#&gt; 179  0.0952 
#&gt; 180  0.0918 
#&gt; 181  0.0886 
#&gt; 182  0.0855 
#&gt; 183  0.0825 
#&gt; 184  0.0797 
#&gt; 185  0.0769 
#&gt; 186  0.0742 
#&gt; 187  0.0717 
#&gt; 188  0.0692 
#&gt; 189  0.0668 
#&gt; 190  0.0645 
#&gt; 191  0.0623 
#&gt; 192  0.0602 
#&gt; 193  0.0582 
#&gt; 194  0.0562 
#&gt; 195  0.0543 
#&gt; 196  0.0525 
#&gt; 197  0.0507 
#&gt; 198  0.049 
#&gt; 199  0.0473 
#&gt; 200  0.0458 
#&gt; 201  0.0442 
#&gt; 202  0.0428 
#&gt; 203  0.0413 
#&gt; 204  0.04 
#&gt; 205  0.0386 
#&gt; 206  0.0374 
#&gt; 207  0.0361 
#&gt; 208  0.0349 
#&gt; 209  0.0338 
#&gt; 210  0.0327 
#&gt; 211  0.0316 
#&gt; 212  0.0306 
#&gt; 213  0.0296 
#&gt; 214  0.0286 
#&gt; 215  0.0277 
#&gt; 216  0.0268 
#&gt; 217  0.0259 
#&gt; 218  0.0251 
#&gt; 219  0.0243 
#&gt; 220  0.0235 
#&gt; 221  0.0228 
#&gt; 222  0.022 
#&gt; 223  0.0213 
#&gt; 224  0.0206 
#&gt; 225  0.02 
#&gt; 226  0.0193 
#&gt; 227  0.0187 
#&gt; 228  0.0181 
#&gt; 229  0.0176 
#&gt; 230  0.017 
#&gt; 231  0.0165 
#&gt; 232  0.016 
#&gt; 233  0.0155 
#&gt; 234  0.015 
#&gt; 235  0.0145 
#&gt; 236  0.014 
#&gt; 237  0.0136 
#&gt; 238  0.0132 
#&gt; 239  0.0128 
#&gt; 240  0.0124 
#&gt; 241  0.012 
#&gt; 242  0.0116 
#&gt; 243  0.0113 
#&gt; 244  0.0109 
#&gt; 245  0.0106 
#&gt; 246  0.0102 
#&gt; 247  0.00993 
#&gt; 248  0.00963 
#&gt; 249  0.00933 
#&gt; 250  0.00905 
#&gt; 251  0.00877 
#&gt; 252  0.0085 
#&gt; 253  0.00824 
#&gt; 254  0.00799 
#&gt; 255  0.00775 
#&gt; 256  0.00751 
#&gt; 257  0.00728 
#&gt; 258  0.00706 
#&gt; 259  0.00685 
#&gt; 260  0.00664 
#&gt; 261  0.00644 
#&gt; 262  0.00625 
#&gt; 263  0.00606 
#&gt; 264  0.00588 
#&gt; 265  0.0057 
#&gt; 266  0.00553 
#&gt; 267  0.00536 
#&gt; 268  0.0052 
#&gt; 269  0.00505 
#&gt; 270  0.00489 
#&gt; 271  0.00475 
#&gt; 272  0.00461 
#&gt; 273  0.00447 
#&gt; 274  0.00434 
#&gt; 275  0.00421 
#&gt; 276  0.00408 
#&gt; 277  0.00396 
#&gt; 278  0.00384 
#&gt; 279  0.00373 
#&gt; 280  0.00362 
#&gt; 281  0.00351 
#&gt; 282  0.00341 
#&gt; 283  0.00331 
#&gt; 284  0.00321 
#&gt; 285  0.00311 
#&gt; 286  0.00302 
#&gt; 287  0.00293 
#&gt; 288  0.00285 
#&gt; 289  0.00276 
#&gt; 290  0.00268 
#&gt; 291  0.0026 
#&gt; 292  0.00253 
#&gt; 293  0.00245 
#&gt; 294  0.00238 
#&gt; 295  0.00231 
#&gt; 296  0.00224 
#&gt; 297  0.00218 
#&gt; 298  0.00212 
#&gt; 299  0.00205 
#&gt; 300  0.00199 
#&gt; 301  0.00194 
#&gt; 302  0.00188 
#&gt; 303  0.00183 
#&gt; 304  0.00177 
#&gt; 305  0.00172 
#&gt; 306  0.00167 
#&gt; 307  0.00162 
#&gt; 308  0.00158 
#&gt; 309  0.00153 
#&gt; 310  0.00149 
#&gt; 311  0.00145 
#&gt; 312  0.0014 
#&gt; 313  0.00136 
#&gt; 314  0.00132 
#&gt; 315  0.00129 
#&gt; 316  0.00125 
#&gt; 317  0.00121 
#&gt; 318  0.00118 
#&gt; 319  0.00115 
#&gt; 320  0.00111 
#&gt; 321  0.00108 
#&gt; 322  0.00105 
#&gt; 323  0.00102 
#&gt; 324  0.000992 
#&gt; 325  0.000964 
#&gt; 326  0.000936 
#&gt; 327  0.00091 
#&gt; 328  0.000884 
#&gt; 329  0.000859 
#&gt; 330  0.000834 
#&gt; 331  0.000811 
#&gt; 332  0.000788 
#&gt; 333  0.000766 
#&gt; 334  0.000744 
#&gt; 335  0.000723 
#&gt; 336  0.000702 
#&gt; 337  0.000683 
#&gt; 338  0.000663 
#&gt; 339  0.000645 
#&gt; 340  0.000626 
#&gt; 341  0.000609 
#&gt; 342  0.000592 
#&gt; 343  0.000575 
#&gt; 344  0.000559 
#&gt; 345  0.000543 
#&gt; 346  0.000528 
#&gt; 347  0.000513 
#&gt; 348  0.000499 
#&gt; 349  0.000485 
#&gt; 350  0.000471 
#&gt; 351  0.000458 
#&gt; 352  0.000445 
#&gt; 353  0.000433 
#&gt; 354  0.000421 
#&gt; 355  0.000409 
#&gt; 356  0.000397 
#&gt; 357  0.000386 
#&gt; 358  0.000375 
#&gt; 359  0.000365 
#&gt; 360  0.000355 
#&gt; 361  0.000345 
#&gt; 362  0.000335 
#&gt; 363  0.000326 
#&gt; 364  0.000317 
#&gt; 365  0.000308 
#&gt; 366  0.000299 
#&gt; 367  0.000291 
#&gt; 368  0.000283 
#&gt; 369  0.000275 
#&gt; 370  0.000268 
#&gt; 371  0.00026 
#&gt; 372  0.000253 
#&gt; 373  0.000246 
#&gt; 374  0.000239 
#&gt; 375  0.000232 
#&gt; 376  0.000226 
#&gt; 377  0.00022 
#&gt; 378  0.000214 
#&gt; 379  0.000208 
#&gt; 380  0.000202 
#&gt; 381  0.000196 
#&gt; 382  0.000191 
#&gt; 383  0.000186 
#&gt; 384  0.000181 
#&gt; 385  0.000176 
#&gt; 386  0.000171 
#&gt; 387  0.000166 
#&gt; 388  0.000161 
#&gt; 389  0.000157 
#&gt; 390  0.000153 
#&gt; 391  0.000148 
#&gt; 392  0.000144 
#&gt; 393  0.00014 
#&gt; 394  0.000136 
#&gt; 395  0.000133 
#&gt; 396  0.000129 
#&gt; 397  0.000125 
#&gt; 398  0.000122 
#&gt; 399  0.000119 
#&gt; 400  0.000115 
#&gt; 401  0.000112 
#&gt; 402  0.000109 
#&gt; 403  0.000106 
#&gt; 404  0.000103 
#&gt; 405  1e-04 
#&gt; 406  9.77e-05 
#&gt; 407  9.5e-05 
#&gt; 408  9.24e-05 
#&gt; 409  8.98e-05 
#&gt; 410  8.74e-05 
#&gt; 411  8.5e-05 
#&gt; 412  8.26e-05 
#&gt; 413  8.04e-05 
#&gt; 414  7.82e-05 
#&gt; 415  7.6e-05 
#&gt; 416  7.4e-05 
#&gt; 417  7.19e-05 
#&gt; 418  7e-05 
#&gt; 419  6.81e-05 
#&gt; 420  6.62e-05 
#&gt; 421  6.44e-05 
#&gt; 422  6.26e-05 
#&gt; 423  6.09e-05 
#&gt; 424  5.92e-05 
#&gt; 425  5.76e-05 
#&gt; 426  5.61e-05 
#&gt; 427  5.45e-05 
#&gt; 428  5.3e-05 
#&gt; 429  5.16e-05 
#&gt; 430  5.02e-05 
#&gt; 431  4.88e-05 
#&gt; 432  4.75e-05 
#&gt; 433  4.62e-05 
#&gt; 434  4.49e-05 
#&gt; 435  4.37e-05 
#&gt; 436  4.25e-05 
#&gt; 437  4.14e-05 
#&gt; 438  4.02e-05 
#&gt; 439  3.91e-05 
#&gt; 440  3.81e-05 
#&gt; 441  3.7e-05 
#&gt; 442  3.6e-05 
#&gt; 443  3.5e-05 
#&gt; 444  3.41e-05 
#&gt; 445  3.32e-05 
#&gt; 446  3.23e-05 
#&gt; 447  3.14e-05 
#&gt; 448  3.05e-05 
#&gt; 449  2.97e-05 
#&gt; 450  2.89e-05 
#&gt; 451  2.81e-05 
#&gt; 452  2.73e-05 
#&gt; 453  2.66e-05 
#&gt; 454  2.59e-05 
#&gt; 455  2.52e-05 
#&gt; 456  2.45e-05 
#&gt; 457  2.38e-05 
#&gt; 458  2.32e-05 
#&gt; 459  2.26e-05 
#&gt; 460  2.19e-05 
#&gt; 461  2.14e-05 
#&gt; 462  2.08e-05 
#&gt; 463  2.02e-05 
#&gt; 464  1.97e-05 
#&gt; 465  1.91e-05 
#&gt; 466  1.86e-05 
#&gt; 467  1.81e-05 
#&gt; 468  1.76e-05 
#&gt; 469  1.71e-05 
#&gt; 470  1.67e-05 
#&gt; 471  1.62e-05 
#&gt; 472  1.58e-05 
#&gt; 473  1.54e-05 
#&gt; 474  1.49e-05 
#&gt; 475  1.45e-05 
#&gt; 476  1.41e-05 
#&gt; 477  1.38e-05 
#&gt; 478  1.34e-05 
#&gt; 479  1.3e-05 
#&gt; 480  1.27e-05 
#&gt; 481  1.23e-05 
#&gt; 482  1.2e-05 
#&gt; 483  1.17e-05 
#&gt; 484  1.14e-05 
#&gt; 485  1.11e-05 
#&gt; 486  1.08e-05 
#&gt; 487  1.05e-05 
#&gt; 488  1.02e-05 
#&gt; 489  9.92e-06 
#&gt; 490  9.65e-06 
#&gt; 491  9.39e-06 
#&gt; 492  9.14e-06 
#&gt; 493  8.89e-06 
#&gt; 494  8.65e-06 
#&gt; 495  8.42e-06 
#&gt; 496  8.19e-06 
#&gt; 497  7.97e-06 
#&gt; 498  7.75e-06 
#&gt; 499  7.55e-06 
#&gt; 500  7.34e-06</code></pre>
</div>
<div id="using-r-generics-to-simplify-tensor-operations" class="section level2" number="13.7">
<h2><span class="header-section-number">13.7</span> Using R generics to simplify tensor operations</h2>
<p>The following two expressions are equivalent, with the first being the long version natural way of doing it in <strong>PyTorch</strong>. The second is using the generics in R for subtraction, multiplication and scalar conversion.</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb543-1" aria-hidden="true" tabindex="-1"></a>param<span class="sc">$</span>data <span class="ot">&lt;-</span> torch<span class="sc">$</span><span class="fu">sub</span>(param<span class="sc">$</span>data,</span>
<span id="cb543-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb543-2" aria-hidden="true" tabindex="-1"></a>                        torch<span class="sc">$</span><span class="fu">mul</span>(param<span class="sc">$</span>grad<span class="sc">$</span><span class="fu">float</span>(),</span>
<span id="cb543-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb543-3" aria-hidden="true" tabindex="-1"></a>                          torch<span class="sc">$</span><span class="fu">scalar_tensor</span>(learning_rate)))</span></code></pre></div>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb544-1" aria-hidden="true" tabindex="-1"></a>param<span class="sc">$</span>data <span class="ot">&lt;-</span> param<span class="sc">$</span>data <span class="sc">-</span> param<span class="sc">$</span>grad <span class="sc">*</span> learning_rate</span></code></pre></div>
</div>
<div id="a-more-elegant-way-of-writing-the-neural-network" class="section level2" number="13.8">
<h2><span class="header-section-number">13.8</span> A more elegant way of writing the neural network</h2>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-1" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(torch<span class="sc">$</span><span class="fu">manual_seed</span>(<span class="dv">0</span>))   <span class="co"># do not show the generator output</span></span>
<span id="cb545-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-2" aria-hidden="true" tabindex="-1"></a><span class="co"># layer properties</span></span>
<span id="cb545-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> 64L; D_in <span class="ot">&lt;-</span> 1000L; H <span class="ot">&lt;-</span> 100L; D_out <span class="ot">&lt;-</span> 10L</span>
<span id="cb545-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-5"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create random Tensors to hold inputs and outputs</span></span>
<span id="cb545-6"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> torch<span class="sc">$</span><span class="fu">randn</span>(N, D_in, <span class="at">device=</span>device)</span>
<span id="cb545-7"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> torch<span class="sc">$</span><span class="fu">randn</span>(N, D_out, <span class="at">device=</span>device)</span>
<span id="cb545-8"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-9"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set up the neural network</span></span>
<span id="cb545-10"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb545-11"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-11" aria-hidden="true" tabindex="-1"></a>  torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">Linear</span>(D_in, H),              <span class="co"># first layer</span></span>
<span id="cb545-12"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-12" aria-hidden="true" tabindex="-1"></a>  torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">ReLU</span>(),                       <span class="co"># activation</span></span>
<span id="cb545-13"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-13" aria-hidden="true" tabindex="-1"></a>  torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">Linear</span>(H, D_out))<span class="sc">$</span><span class="fu">to</span>(device)  <span class="co"># output layer</span></span>
<span id="cb545-14"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-15"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-15" aria-hidden="true" tabindex="-1"></a><span class="co"># specify how we will be computing the loss</span></span>
<span id="cb545-16"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="ot">=</span> torch<span class="sc">$</span>nn<span class="sc">$</span><span class="fu">MSELoss</span>(<span class="at">reduction =</span> <span class="st">&#39;sum&#39;</span>)</span>
<span id="cb545-17"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-18"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-18" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="ot">=</span> <span class="fl">1e-4</span></span>
<span id="cb545-19"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-19" aria-hidden="true" tabindex="-1"></a>loss_row <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="fu">vector</span>())     <span class="co"># collect a list for the final dataframe</span></span>
<span id="cb545-20"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-21"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>) {</span>
<span id="cb545-22"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span>
<span id="cb545-23"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># override the __call__ operator so you can call them like functions. When</span></span>
<span id="cb545-24"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># doing so you pass a Tensor of input data to the Module and it produces</span></span>
<span id="cb545-25"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># a Tensor of output data.</span></span>
<span id="cb545-26"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-26" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="ot">=</span> <span class="fu">model</span>(x)</span>
<span id="cb545-27"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-28"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute and print loss. We pass Tensors containing the predicted and true</span></span>
<span id="cb545-29"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># values of y, and the loss function returns a Tensor containing the loss.</span></span>
<span id="cb545-30"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-30" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">loss_fn</span>(y_pred, y)  <span class="co"># (y_pred - y) is a tensor; loss_fn output is a scalar</span></span>
<span id="cb545-31"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-31" aria-hidden="true" tabindex="-1"></a>  loss_row[[t]] <span class="ot">&lt;-</span> <span class="fu">c</span>(t, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb545-32"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb545-33"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Zero the gradients before running the backward pass.</span></span>
<span id="cb545-34"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-34" aria-hidden="true" tabindex="-1"></a>  model<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb545-35"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-36"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span>
<span id="cb545-37"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># parameters of the model. Internally, the parameters of each module are stored</span></span>
<span id="cb545-38"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># in tensors with `requires_grad=True`, so this call will compute gradients for</span></span>
<span id="cb545-39"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># all learnable parameters in the model.</span></span>
<span id="cb545-40"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-40" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb545-41"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-42"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-42" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update the weights using gradient descent. Each parameter is a tensor, so</span></span>
<span id="cb545-43"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-43" aria-hidden="true" tabindex="-1"></a>  <span class="co"># we can access its data and gradients like we did before.</span></span>
<span id="cb545-44"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(torch<span class="sc">$</span><span class="fu">no_grad</span>(), {</span>
<span id="cb545-45"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-45" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (param <span class="cf">in</span> <span class="fu">iterate</span>(model<span class="sc">$</span><span class="fu">parameters</span>())) {</span>
<span id="cb545-46"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># using R generics</span></span>
<span id="cb545-47"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-47" aria-hidden="true" tabindex="-1"></a>        param<span class="sc">$</span>data <span class="ot">&lt;-</span> param<span class="sc">$</span>data <span class="sc">-</span> param<span class="sc">$</span>grad <span class="sc">*</span> learning_rate</span>
<span id="cb545-48"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-48" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb545-49"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-49" aria-hidden="true" tabindex="-1"></a>   })</span>
<span id="cb545-50"><a href="a-step-by-step-neural-network-in-rtorch.html#cb545-50" aria-hidden="true" tabindex="-1"></a>}  </span></code></pre></div>
</div>
<div id="create-a-browseable-dataframe" class="section level2" number="13.9">
<h2><span class="header-section-number">13.9</span> Create a browseable dataframe</h2>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb546-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DT)</span>
<span id="cb546-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb546-2" aria-hidden="true" tabindex="-1"></a>loss_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">Reduce</span>(rbind, loss_row), <span class="at">row.names =</span> <span class="cn">NULL</span>)</span>
<span id="cb546-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb546-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(loss_df)[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">&quot;iter&quot;</span></span>
<span id="cb546-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb546-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(loss_df)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">&quot;loss&quot;</span></span>
<span id="cb546-5"><a href="a-step-by-step-neural-network-in-rtorch.html#cb546-5" aria-hidden="true" tabindex="-1"></a>DT<span class="sc">::</span><span class="fu">datatable</span>(loss_df)</span></code></pre></div>
<div id="htmlwidget-13497ac384dc0636e9b0" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-13497ac384dc0636e9b0">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301","302","303","304","305","306","307","308","309","310","311","312","313","314","315","316","317","318","319","320","321","322","323","324","325","326","327","328","329","330","331","332","333","334","335","336","337","338","339","340","341","342","343","344","345","346","347","348","349","350","351","352","353","354","355","356","357","358","359","360","361","362","363","364","365","366","367","368","369","370","371","372","373","374","375","376","377","378","379","380","381","382","383","384","385","386","387","388","389","390","391","392","393","394","395","396","397","398","399","400","401","402","403","404","405","406","407","408","409","410","411","412","413","414","415","416","417","418","419","420","421","422","423","424","425","426","427","428","429","430","431","432","433","434","435","436","437","438","439","440","441","442","443","444","445","446","447","448","449","450","451","452","453","454","455","456","457","458","459","460","461","462","463","464","465","466","467","468","469","470","471","472","473","474","475","476","477","478","479","480","481","482","483","484","485","486","487","488","489","490","491","492","493","494","495","496","497","498","499","500"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],[708.097058522568,657.507176164087,613.313121996919,574.613918856374,539.783451190871,508.086160447481,479.150721598493,452.452675704842,427.593117087184,404.459081269607,382.735742757396,362.21977991161,342.870497761619,324.595883456043,307.298597161424,290.906979291491,275.374511247836,260.613613111093,246.505016064608,233.066278806811,220.209570270581,207.928521264061,196.213268504103,185.047328523698,174.428470498939,164.328019448859,154.712411347439,145.587039847798,136.929573922233,128.719133058759,120.971692211216,113.658710950392,106.766372773387,100.26504862834,94.1469922623051,88.3950438430052,82.9995260359694,77.9439249010276,73.191634486882,68.731929568269,64.5489296480526,60.6287128788902,56.9627632346523,53.5180550332398,50.2906358356073,47.2754854779024,44.4512912378185,41.8040545938131,39.3194059518114,36.9888188589405,34.8019058546359,32.7534951484537,30.836822296221,29.0412041768172,27.3589751770954,25.7782473505275,24.2949188361096,22.9032736719311,21.5966070274388,20.3701501556853,19.2175196841687,18.1382148762514,17.1231423210965,16.172034202854,15.2770069245247,14.4361683202158,13.6443759662036,12.8999193642241,12.2003323338867,11.5419736681123,10.9226355491703,10.3386315705422,9.78967201543815,9.2728106086622,8.78584874618205,8.3245861421634,7.89018516615734,7.48023393866453,7.09417586761545,6.7300061864097,6.3861508167251,6.06175246941425,5.75499411698409,5.4655122504309,5.19171530996734,4.93270221280803,4.68760422413414,4.45602686380808,4.23700764626953,4.02939050593876,3.83293695511758,3.64675999729106,3.47035348428656,3.30331725146392,3.14478833922966,2.99466824848845,2.8524171765862,2.71761864861502,2.58974819024101,2.46847460064415,2.3533024714374,2.24397562069638,2.14014076263817,2.04158302620902,1.94793085516593,1.85889924887018,1.77418710813331,1.69375239322558,1.61724536525518,1.54454930635714,1.4753741947405,1.40955455254979,1.34686874474049,1.28720588061169,1.230365118804,1.17627590223578,1.12484350842593,1.07581770694082,1.0290814906125,0.984586859735015,0.942140838735914,0.901633807227052,0.863005794419465,0.826177160681131,0.791090304725862,0.757575380272704,0.725608764203015,0.69512270468135,0.666026847153863,0.638236769507383,0.611722674839667,0.586382726819508,0.562184109341094,0.539075646080641,0.516987554761674,0.495934866640476,0.475843834829299,0.456647632473473,0.438315189123219,0.420794238869138,0.404033690991634,0.387989120642135,0.372644765216374,0.357958666054217,0.343906602703018,0.330460611193193,0.31759180602381,0.305251144446555,0.293440440977147,0.282127895455011,0.27127923802877,0.26089732324717,0.250936671277012,0.241383741733204,0.232232360167012,0.223448770646776,0.215026013138789,0.206953234030693,0.199205617457599,0.191778589149358,0.18464210142452,0.177795499546926,0.171221278765603,0.164914905454092,0.158862989236073,0.15304789248449,0.147464141555387,0.142095932560567,0.136939706691837,0.131989537099678,0.127230249682632,0.122655949773613,0.118257893399875,0.114031888307509,0.109965577176213,0.106054918489537,0.102293848518802,0.0986803104537796,0.0952002711729645,0.0918496228816434,0.088629181854049,0.0855298859507861,0.082544863163715,0.0796724195930313,0.076908519893697,0.0742467455798315,0.0716830005305682,0.0692136296361101,0.0668391840872034,0.0645491445905044,0.0623422843008145,0.0602146056796307,0.0581652864609852,0.056190391348975,0.0542877247719631,0.0524540067785854,0.0506865084939448,0.0489841896336188,0.047340813998938,0.0457567694990164,0.0442284642322956,0.0427546238246355,0.0413326124473181,0.0399605946255968,0.0386378582984331,0.0373622240701008,0.0361298045644352,0.034940629306793,0.0337938142777658,0.0326858869382644,0.0316161596330207,0.0305835645996358,0.0295873719213168,0.028626111410738,0.0276966877462436,0.0267998290812921,0.0259330699438469,0.0250958932783669,0.024287968206652,0.0235071465950779,0.0227526727470858,0.0220235074447473,0.0213196133517834,0.0206389252083861,0.0199812695066656,0.0193457640957401,0.018731208915781,0.0181374280683897,0.0175632698532361,0.0170084246571154,0.0164721062483989,0.0159535314960621,0.0154519383445539,0.0149668914955577,0.0144978379737433,0.0140441088135793,0.0136052569068304,0.0131808457386149,0.0127702926699031,0.01237316191243,0.0119888028983317,0.0116173285097004,0.0112577144158531,0.0109096931471222,0.0105730138036877,0.0102470362013635,0.0099318148577239,0.0096265251254363,0.00933114464807592,0.0090454603188349,0.00876864868291016,0.00850086224057185,0.0082413480094597,0.00799006549721679,0.00774677157048488,0.00751122946807779,0.00728310923759972,0.00706221939523054,0.00684826150712707,0.00664124178189329,0.00644052400009415,0.00624629480266548,0.00605792565792237,0.00587553103678525,0.00569876970568515,0.00552761154473737,0.00536176967147933,0.00520101866699606,0.00504527881589404,0.0048943681045986,0.0047481477900895,0.00460670436531986,0.00446939075795976,0.00433624387366077,0.00420723623518017,0.00408218090522059,0.00396098092601281,0.0038432830495422,0.0037291569108766,0.00361856677247329,0.0035113220361816,0.00340741913101846,0.00330678494848946,0.00320913235244225,0.0031144525802294,0.00302262358569178,0.00293361540560099,0.00284736102162922,0.00276369738451852,0.00268259666655628,0.00260387030934017,0.0025275591694074,0.00245354800160322,0.00238178739823108,0.00231216298305395,0.0022446217301241,0.0021791238091761,0.00211557952762092,0.00205393603787755,0.00199416503279375,0.00193616452580938,0.00188006682247276,0.00182572766196336,0.00177301829299912,0.00172189113585577,0.00167229519805181,0.00162411919959365,0.00157736467880267,0.00153201316588245,0.00148798810770877,0.00144527354145152,0.0014038081699913,0.00136356765204846,0.0013245144873981,0.00128660380048608,0.00124981820682806,0.0012141481273348,0.00117949152970845,0.00114582974755525,0.00111315194189465,0.00108143684050499,0.00105065565986643,0.00102074710943825,0.000991712050777097,0.000963532926361114,0.000936163585096578,0.000909610465292727,0.000883800401495943,0.000858759845275733,0.00083441293841084,0.00081077064403544,0.0007878181614647,0.000765532500438301,0.000743881883591636,0.000722861170498071,0.000702435417908485,0.000682605868566908,0.000663349253666371,0.000644646378149815,0.00062647727746178,0.000608839944961863,0.000591698064556041,0.000575047513620378,0.000558883856239345,0.000543175096504675,0.0005279120764226,0.000513085301189578,0.000498684198911801,0.000484690760737749,0.000471100546058663,0.000457901262150492,0.000445076286193981,0.000432622261611493,0.000420523511787808,0.000408762957023818,0.000397337210453637,0.00038623311720218,0.000375444797575732,0.000364959643053998,0.000354774866739812,0.000344881315291217,0.000335268977628679,0.000325927099108869,0.000316846176094814,0.000308021258266266,0.000299449179815186,0.00029112094483066,0.000283024684237416,0.000275156865821835,0.000267510919170964,0.000260080779556445,0.000252863039763896,0.000245843430346615,0.000239021075546322,0.000232393307240816,0.000225948816222628,0.00021968831544494,0.000213603569828166,0.000207688669597717,0.000201939954275652,0.000196351978905243,0.000190919921889732,0.000185639646338631,0.000180508412594943,0.00017551944381888,0.000170670076783811,0.000165957621920688,0.000161376454271191,0.000156921622307476,0.000152593532485718,0.000148388037230739,0.000144298715714602,0.000140326136325627,0.000136459406485377,0.000132700387413225,0.000129045896753001,0.000125494115565213,0.000122041009302626,0.000118682828763389,0.000115418432854091,0.000112244653308329,0.000109159510511359,0.00010615965793155,0.00010324281488913,0.000100407539699733,9.76531732237462e-05,9.49737354476376e-05,9.23682045308059e-05,8.98347273019072e-05,8.73714919060235e-05,8.49767578993282e-05,8.26474861581144e-05,8.03824752049844e-05,7.81804853702694e-05,7.60399710483978e-05,7.39579373053944e-05,7.19337208420729e-05,6.99651592001038e-05,6.80520558628051e-05,6.61916097845199e-05,6.43818649308033e-05,6.26219268570786e-05,6.09111153604281e-05,5.9246559265836e-05,5.76281059228924e-05,5.60543549180443e-05,5.45241172021819e-05,5.30371484746548e-05,5.15906335574876e-05,5.01833053013523e-05,4.88143518286976e-05,4.74830628372067e-05,4.61892114541961e-05,4.4930349972535e-05,4.37059545235506e-05,4.25150031503215e-05,4.13565978893178e-05,4.02302083880934e-05,3.91348434792645e-05,3.80693041440581e-05,3.70333151283622e-05,3.60254978148559e-05,3.50453186801056e-05,3.40919151480739e-05,3.31650961669888e-05,3.22636194431574e-05,3.13873242079585e-05,3.05342386821098e-05,2.97046670536831e-05,2.88975198217236e-05,2.81129293303522e-05,2.73496554280505e-05,2.66072025301324e-05,2.58847745907107e-05,2.51822082794478e-05,2.44988388050264e-05,2.38340048690569e-05,2.31874123241354e-05,2.25589620937478e-05,2.19476889152731e-05,2.13525695700984e-05,2.07738503554294e-05,2.02108183270243e-05,1.96631141694699e-05,1.91305166716304e-05,1.86122707194363e-05,1.81082072653387e-05,1.76178575467513e-05,1.71411302749814e-05,1.66771500067816e-05,1.62260053770539e-05,1.57872034286032e-05,1.53604049061644e-05,1.49455119941021e-05,1.45415707884789e-05,1.41489425955466e-05,1.37667867847709e-05,1.3395028065003e-05,1.30333127609981e-05,1.26814616692542e-05,1.23391431850536e-05,1.20061185909355e-05,1.16822156348448e-05,1.13670265739399e-05,1.10604024631389e-05,1.07620909757511e-05,1.04719526503166e-05,1.0189797434838e-05,9.91520004824534e-06,9.64798750644268e-06,9.38799160806976e-06,9.13500728231335e-06,8.88885493578276e-06,8.64939536896704e-06,8.41646665067006e-06,8.18987001635188e-06,7.96941647734819e-06,7.75485152701393e-06,7.54611837321885e-06,7.3430371549506e-06]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>iter<\/th>\n      <th>loss<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="plot-the-loss-at-each-iteration" class="section level2" number="13.10">
<h2><span class="header-section-number">13.10</span> Plot the loss at each iteration</h2>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="a-step-by-step-neural-network-in-rtorch.html#cb547-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb547-2"><a href="a-step-by-step-neural-network-in-rtorch.html#cb547-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb547-3"><a href="a-step-by-step-neural-network-in-rtorch.html#cb547-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(loss_df, <span class="fu">aes</span>(<span class="at">x =</span> iter, <span class="at">y =</span> loss)) <span class="sc">+</span></span>
<span id="cb547-4"><a href="a-step-by-step-neural-network-in-rtorch.html#cb547-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="rtorch-minimal-book_files/figure-html/plot-loss-1.png" width="70%" style="display: block; margin: auto;" /></p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="neural-networks-using-numpy-r-base-rtorch-and-pytorch.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="working-with-data-frame.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/f0nzie/rtorch-minimal-book/edit/main/0502-neural_networks-steps.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

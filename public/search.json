[{"path":"index.html","id":"prerequisites","chapter":"Prerequisites","heading":"Prerequisites","text":"Last update: Sun Oct 25 12:05:18 2020 -0500 (79503f6ee)need couple things get rTorch working:Install Python Anaconda. Preferably, 64-bits, Python 3.6+. successfully tested Anaconda four different operating systems: Windows (Win10 Windows Server 2008); macOS (Sierra, Mojave Catalina); Linux (Debian, Fedora Ubuntu); lastly, Solaris 10. tests required CRAN.Install Python Anaconda. Preferably, 64-bits, Python 3.6+. successfully tested Anaconda four different operating systems: Windows (Win10 Windows Server 2008); macOS (Sierra, Mojave Catalina); Linux (Debian, Fedora Ubuntu); lastly, Solaris 10. tests required CRAN.Install R, Rtools RStudio. used two R versions R-3.6.3 R-4.0.2.Install R, Rtools RStudio. used two R versions R-3.6.3 R-4.0.2.Install R package reticulate, one provides connection R Python.Install R package reticulate, one provides connection R Python.Install stable version rTorch CRAN, latest version development via GitHub.Install stable version rTorch CRAN, latest version development via GitHub.Note. mandatory previously created Python environment Anaconda, PyTorch TorchVision already installed, another option reason reticulate refuses communicate conda environment. Keep mind also get rTorch conda environment installed directly R console, similar fashion R-TensorFlow . Use function install_pytorch() install conda environment PyTorch.","code":""},{"path":"index.html","id":"installation","chapter":"Prerequisites","heading":"Installation","text":"rTorch package can installed CRAN Github.CRAN:GitHub, install rTorch :install rTorch main master branch.want play latest rTorch version, install develop branch, like :clone Git terminal :allow build rTorch source.","code":"\ninstall.packages(\"rTorch\")\ndevtools::install_github(\"f0nzie/rTorch\")\ndevtools::install_github(\"f0nzie/rTorch\", ref=\"develop\")git clone https://github.com/f0nzie/rTorch.git"},{"path":"index.html","id":"python-anaconda","chapter":"Prerequisites","heading":"Python Anaconda","text":"preference installing Anaconda environment first, steps:","code":""},{"path":"index.html","id":"example","chapter":"Prerequisites","heading":"Example","text":"Create conda environment terminal :Activate new environment withInstall PyTorch related packages :last part -c pytorch specifies stable conda channel download PyTorch packages. conda installation may work don’t indicate channel.Now, can load rTorch R RStudio :","code":"conda create -n r-torch python=3.7conda activate r-torchconda install python=3.6.6 pytorch torchvision cpuonly matplotlib pandas -c pytorch\nlibrary(rTorch)"},{"path":"index.html","id":"automatic-installation","chapter":"Prerequisites","heading":"Automatic installation","text":"used idea automatic installation tensorflow package R, create function rTorch::install_pytorch(). function allow install conda environment complete PyTorch requirements plus packages specify. Example:explained detailed rTorch package manual.Note. matplotlib pandas really necessary rTorch work, asked matplotlib pandas work PyTorch. , decided install testing experimentation. work.","code":"\nrTorch:::install_conda(package=\"pytorch=1.4\", envname=\"r-torch\", \n                       conda=\"auto\", conda_python_version = \"3.6\", pip=FALSE, \n                       channel=\"pytorch\", \n                       extra_packages=c(\"torchvision\", \n                                        \"cpuonly\", \n                                        \"matplotlib\", \n                                        \"pandas\"))"},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"Last update: Sun Oct 25 13:00:41 2020 -0500 (265c0b3c1)","code":""},{"path":"intro.html","id":"motivation","chapter":"1 Introduction","heading":"1.1 Motivation","text":"want package something already working well, PyTorch?several reasons, main one bring another machine learning framework R. Probably, just feel PyTorch comfortable work . Feels pretty much like everything else Python. pythonic. tried frameworks R. closest matches natural language like PyTorch, MXnet. Unfortunately, MXnet hardest install maintain updates.Yes. worked directly PyTorch native Python environment, Jupyter, PyCharm, vscode notebooks hard quit RMarkdown get used . real thing regards literate programming reproducibility. contribute improving quality code establishes workflow better understanding subject intended readers (Knuth 1983), called literate programming paradigm (Cordes Brown 1991).additional benefit giving ability write combination Python R code together document. times better create class Python; times R convenient handle data structure. show examples using data.frame data.table along PyTorch tensors.","code":""},{"path":"intro.html","id":"start-using-rtorch","chapter":"1 Introduction","heading":"1.2 Start using rTorch","text":"Start using rTorch simple. installing minimum system requirements -conda -, just call :several ways testing rTorch running. Let’s see :","code":"\nlibrary(rTorch)"},{"path":"intro.html","id":"get-the-pytorch-version","chapter":"1 Introduction","heading":"1.2.1 Get the PyTorch version","text":"","code":"\nrTorch::torch_version()#> [1] \"1.6\""},{"path":"intro.html","id":"pytorch-configuration","chapter":"1 Introduction","heading":"1.2.2 PyTorch configuration","text":"show PyTorch version current version Python installed, well paths folders reside.","code":"\nrTorch::torch_config()#> PyTorch v1.6.0 (~/miniconda3/envs/r-torch/lib/python3.7/site-packages/torch)\n#> Python v3.7 (~/miniconda3/envs/r-torch/bin/python)\n#> NumPy v1.19.4)"},{"path":"intro.html","id":"what-can-you-do-with-rtorch","chapter":"1 Introduction","heading":"1.3 What can you do with rTorch","text":"Practically, can everything PyTorch within R ecosystem. Additionally rTorch module, can extract methods, functions classes, available two modules: torchvision np, short numpy. use modules :","code":"\nrTorch::torchvision\nrTorch::np\nrTorch::torch#> Module(torchvision)\n#> Module(numpy)\n#> Module(torch)"},{"path":"intro.html","id":"getting-help","chapter":"1 Introduction","heading":"1.4 Getting help","text":"get glimpse first lines help(\"torch\") via Python chunk:Finally, classes module torchvision.datasets. using Python list using help function.words, functions, modules, classes PyTorch available rTorch.","code":"help(\"torch\")...\n#> NAME\n#>     torch\n#> \n#> DESCRIPTION\n#>     The torch package contains data structures for multi-dimensional\n#>     tensors and mathematical operations over these are defined.\n#>     Additionally, it provides many utilities for efficient serializing of\n#>     Tensors and arbitrary types, and other useful utilities.\n...help(\"torch.tensor\")...\n#> Help on built-in function tensor in torch:\n#> \n#> torch.tensor = tensor(...)\n#>     tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n#>     \n#>     Constructs a tensor with :attr:`data`.\n#>     \n#>     .. warning::\n#>     \n#>         :func:`torch.tensor` always copies :attr:`data`. If you have a Tensor\n#>         ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n#>         or :func:`torch.Tensor.detach`.\n#>         If you have a NumPy ``ndarray`` and want to avoid a copy, use\n#>         :func:`torch.as_tensor`.\n#>     \n#>     .. warning::\n#>     \n#>         When data is a tensor `x`, :func:`torch.tensor` reads out 'the data' from whatever it is passed,\n#>         and constructs a leaf variable. Therefore ``torch.tensor(x)`` is equivalent to ``x.clone().detach()``\n#>         and ``torch.tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n...help(\"torch.cat\")...\n#> Help on built-in function cat in torch:\n#> \n#> torch.cat = cat(...)\n#>     cat(tensors, dim=0, out=None) -> Tensor\n#>     \n#>     Concatenates the given sequence of :attr:`seq` tensors in the given dimension.\n#>     All tensors must either have the same shape (except in the concatenating\n#>     dimension) or be empty.\n#>     \n#>     :func:`torch.cat` can be seen as an inverse operation for :func:`torch.split`\n#>     and :func:`torch.chunk`.\n#>     \n#>     :func:`torch.cat` can be best understood via examples.\n#>     \n#>     Args:\n#>         tensors (sequence of Tensors): any python sequence of tensors of the same type.\n#>             Non-empty tensors provided must have the same shape, except in the\n#>             cat dimension.\n#>         dim (int, optional): the dimension over which the tensors are concatenated\n#>         out (Tensor, optional): the output tensor.\n...help(\"numpy.arange\")...\n#> Help on built-in function arange in numpy:\n#> \n#> numpy.arange = arange(...)\n#>     arange([start,] stop[, step,], dtype=None)\n#>     \n#>     Return evenly spaced values within a given interval.\n#>     \n#>     Values are generated within the half-open interval ``[start, stop)``\n#>     (in other words, the interval including `start` but excluding `stop`).\n#>     For integer arguments the function is equivalent to the Python built-in\n#>     `range` function, but returns an ndarray rather than a list.\n#>     \n#>     When using a non-integer step, such as 0.1, the results will often not\n#>     be consistent.  It is better to use `numpy.linspace` for these cases.\n#>     \n#>     Parameters\n#>     ----------\n#>     start : number, optional\n#>         Start of interval.  The interval includes this value.  The default\n#>         start value is 0.\n#>     stop : number\n#>         End of interval.  The interval does not include this value, except\n#>         in some cases where `step` is not an integer and floating point\n#>         round-off affects the length of `out`.\n#>     step : number, optional\n...help(\"torchvision.datasets\")...\n#> Help on package torchvision.datasets in torchvision:\n#> \n#> NAME\n#>     torchvision.datasets\n#> \n#> PACKAGE CONTENTS\n#>     caltech\n#>     celeba\n#>     cifar\n#>     cityscapes\n#>     coco\n#>     fakedata\n#>     flickr\n#>     folder\n#>     hmdb51\n#>     imagenet\n#>     kinetics\n#>     lsun\n#>     mnist\n#>     omniglot\n#>     phototour\n#>     samplers (package)\n#>     sbd\n#>     sbu\n#>     semeion\n#>     stl10\n#>     svhn\n#>     ucf101\n#>     usps\n#>     utils\n#>     video_utils\n#>     vision\n#>     voc\n#> \n#> CLASSES\n..."},{"path":"pytorch-and-numpy.html","id":"pytorch-and-numpy","chapter":"2 PyTorch and NumPy","heading":"2 PyTorch and NumPy","text":"Last update: Sun Oct 25 13:00:41 2020 -0500 (265c0b3c1)","code":""},{"path":"pytorch-and-numpy.html","id":"pytorch-modules-in-rtorch","chapter":"2 PyTorch and NumPy","heading":"2.1 PyTorch modules in rTorch","text":"","code":""},{"path":"pytorch-and-numpy.html","id":"torchvision","chapter":"2 PyTorch and NumPy","heading":"2.1.1 torchvision","text":"example using torchvision module. torchvision dataset set function, download popular datasets machine learning made available PyTorch. example, downloading training dataset MNIST handwritten digits. 60,000 images training set 10,000 images test set. images download folder ./datasets, want, can set parameter root.can similarly test dataset set flag train = FALSE. test dataset 10,000 images.","code":"\nlibrary(rTorch)\n\ntransforms  <- torchvision$transforms\n\n# this is the folder where the datasets will be downloaded\nlocal_folder <- './datasets/mnist_digits'\n\ntrain_dataset = torchvision$datasets$MNIST(root = local_folder, \n                                           train = TRUE, \n                                           transform = transforms$ToTensor(),\n                                           download = TRUE)\n\ntrain_dataset#> Dataset MNIST\n#>     Number of datapoints: 60000\n#>     Root location: ./datasets/mnist_digits\n#>     Split: Train\n#>     StandardTransform\n#> Transform: ToTensor()\ntest_dataset = torchvision$datasets$MNIST(root = local_folder, \n                                          train = FALSE, \n                                          transform = transforms$ToTensor())\ntest_dataset#> Dataset MNIST\n#>     Number of datapoints: 10000\n#>     Root location: ./datasets/mnist_digits\n#>     Split: Test\n#>     StandardTransform\n#> Transform: ToTensor()"},{"path":"pytorch-and-numpy.html","id":"numpy","chapter":"2 PyTorch and NumPy","heading":"2.1.2 numpy","text":"numpy automatically installed PyTorch . interdependence . Anytime need transformation available PyTorch, use numpy. Just keep mind numpy support GPUs; convert numpy array torch tensor afterwards.","code":""},{"path":"pytorch-and-numpy.html","id":"common-array-operations","chapter":"2 PyTorch and NumPy","heading":"2.2 Common array operations","text":"several operations perform numpy creating arrays:","code":""},{"path":"pytorch-and-numpy.html","id":"create-an-array","chapter":"2 PyTorch and NumPy","heading":"Create an array","text":"Create array:add instead Python chunk like :Create array desired shape:Create array spelling components type:use train test datasets loaded torchvision.","code":"\n# do some array manipulations with NumPy\na <- np$array(c(1:4))\na#> [1] 1 2 3 4{python}\nimport numpy as np\n\na = np.arange(1, 5)\naimport numpy as np\n\na = np.arange(1, 5)\na#> array([1, 2, 3, 4])\nnp$reshape(np$arange(0, 9), c(3L, 3L))#>      [,1] [,2] [,3]\n#> [1,]    0    1    2\n#> [2,]    3    4    5\n#> [3,]    6    7    8\nnp$array(list(\n             list( 73,  67,  43),\n             list( 87, 134,  58),\n             list(102,  43,  37),\n             list( 73,  67,  43), \n             list( 91,  88,  64), \n             list(102,  43,  37), \n             list( 69,  96,  70), \n             list( 91,  88,  64), \n             list(102,  43,  37), \n             list( 69,  96,  70)\n           ), dtype='float32')#>       [,1] [,2] [,3]\n#>  [1,]   73   67   43\n#>  [2,]   87  134   58\n#>  [3,]  102   43   37\n#>  [4,]   73   67   43\n#>  [5,]   91   88   64\n#>  [6,]  102   43   37\n#>  [7,]   69   96   70\n#>  [8,]   91   88   64\n#>  [9,]  102   43   37\n#> [10,]   69   96   70"},{"path":"pytorch-and-numpy.html","id":"reshape-an-array","chapter":"2 PyTorch and NumPy","heading":"Reshape an array","text":"test dataset loaded MNIST digits, show image handwritten digit label class. plotting image, need :Extract image label datasetConvert tensor numpy arrayReshape tensor 2D arrayPlot digit labelWe simply using r-base image function:","code":"\nrotate <- function(x) t(apply(x, 2, rev))   # function to rotate the matrix\n\n# label for the image\nlabel <- test_dataset[0][[2]]\nlabel    \n\n# convert tensor to numpy array\n.show_img <- test_dataset[0][[1]]$numpy()\ndim(.show_img) \n\n# reshape 3D array to 2D \nshow_img <- np$reshape(.show_img, c(28L, 28L))\ndim(show_img)#> [1] 7\n#> [1]  1 28 28\n#> [1] 28 28\n# show in gray shades and rotate\nimage(rotate(show_img), col = gray.colors(64))\ntitle(label)"},{"path":"pytorch-and-numpy.html","id":"generate-a-random-array-in-numpy","chapter":"2 PyTorch and NumPy","heading":"Generate a random array in NumPy","text":"classes, can tell numpy arrays automatically converted R arrays. Let’s plot x vs y:","code":"\n# set the seed\nnp$random$seed(123L)\n# generate a random array\nx = np$random$rand(100L)\ndim(x)\n# calculate the y array\ny = np$sin(x) * np$power(x, 3L) + 3L * x + np$random$rand(100L) * 0.8\nclass(y)#> [1] 100\n#> [1] \"array\"\nplot(x, y)"},{"path":"pytorch-and-numpy.html","id":"common-tensor-operations","chapter":"2 PyTorch and NumPy","heading":"2.3 Common tensor operations","text":"","code":""},{"path":"pytorch-and-numpy.html","id":"generate-random-tensors","chapter":"2 PyTorch and NumPy","heading":"Generate random tensors","text":"operation can performed pure torch tensors:. similar example . difference time using tensors numpy arrays.Since classes torch tensors, plot R, first need converted numpy, R:","code":"\nlibrary(rTorch)\n\ninvisible(torch$manual_seed(123L))\nx <- torch$rand(100L)     # use torch$randn(100L): positive and negative numbers\ny <- torch$sin(x) * torch$pow(x, 3L) + 3L * x + torch$rand(100L) * 0.8\nclass(x)\nclass(y)#> [1] \"torch.Tensor\"          \"torch._C._TensorBase\"  \"python.builtin.object\"\n#> [1] \"torch.Tensor\"          \"torch._C._TensorBase\"  \"python.builtin.object\"\nplot(x$numpy(), y$numpy())"},{"path":"pytorch-and-numpy.html","id":"numpy-array-to-pytorch-tensor","chapter":"2 PyTorch and NumPy","heading":"numpy array to PyTorch tensor","text":"Converting numpy array PyTorch tensor common operation seen examples using PyTorch. Creating first array numpy. convert torch tensor.another common operation find PyTorch tutorials: converting numpy array certain type tensor type:","code":"\n# input array\nx = np$array(rbind(\n            c(0,0,1),\n            c(0,1,1),\n            c(1,0,1),\n            c(1,1,1)))\n\n# the numpy array\nx#>      [,1] [,2] [,3]\n#> [1,]    0    0    1\n#> [2,]    0    1    1\n#> [3,]    1    0    1\n#> [4,]    1    1    1\n# convert the numpy array to a float type\nXn <- np$float32(x)\n# convert the numpy array to a float tensor\nXt <- torch$FloatTensor(Xn)\nXt#> tensor([[0., 0., 1.],\n#>         [0., 1., 1.],\n#>         [1., 0., 1.],\n#>         [1., 1., 1.]])"},{"path":"pytorch-and-numpy.html","id":"python-built-in-functions","chapter":"2 PyTorch and NumPy","heading":"2.4 Python built-in functions","text":"access Python built-functions make use package reticulate function import_builtins().part built-functions operators offered R package reticulate. using R function grep() discard carry keywords Error, Warning, Exit.","code":"\npy_bi <- reticulate::import_builtins()\ngrep(\"Error|Warning|Exit\", names(py_bi), value = TRUE, invert = TRUE, \n     perl = TRUE)#>  [1] \"abs\"                \"all\"                \"any\"               \n#>  [4] \"ascii\"              \"BaseException\"      \"bin\"               \n#>  [7] \"bool\"               \"breakpoint\"         \"bytearray\"         \n#> [10] \"bytes\"              \"callable\"           \"chr\"               \n#> [13] \"classmethod\"        \"compile\"            \"complex\"           \n#> [16] \"copyright\"          \"credits\"            \"delattr\"           \n#> [19] \"dict\"               \"dir\"                \"divmod\"            \n#> [22] \"Ellipsis\"           \"enumerate\"          \"eval\"              \n#> [25] \"Exception\"          \"exec\"               \"exit\"              \n#> [28] \"False\"              \"filter\"             \"float\"             \n#> [31] \"format\"             \"frozenset\"          \"getattr\"           \n#> [34] \"globals\"            \"hasattr\"            \"hash\"              \n#> [37] \"help\"               \"hex\"                \"id\"                \n#> [40] \"input\"              \"int\"                \"isinstance\"        \n#> [43] \"issubclass\"         \"iter\"               \"KeyboardInterrupt\" \n#> [46] \"len\"                \"license\"            \"list\"              \n#> [49] \"locals\"             \"map\"                \"max\"               \n#> [52] \"memoryview\"         \"min\"                \"next\"              \n#> [55] \"None\"               \"NotImplemented\"     \"object\"            \n#> [58] \"oct\"                \"open\"               \"ord\"               \n#> [61] \"pow\"                \"print\"              \"property\"          \n#> [64] \"quit\"               \"range\"              \"repr\"              \n#> [67] \"reversed\"           \"round\"              \"set\"               \n#> [70] \"setattr\"            \"slice\"              \"sorted\"            \n#> [73] \"staticmethod\"       \"StopAsyncIteration\" \"StopIteration\"     \n#> [76] \"str\"                \"sum\"                \"super\"             \n#> [79] \"True\"               \"tuple\"              \"type\"              \n#> [82] \"vars\"               \"zip\""},{"path":"pytorch-and-numpy.html","id":"length-of-a-dataset","chapter":"2 PyTorch and NumPy","heading":"Length of a dataset","text":"Sometimes, need Python len function find length object:","code":"\npy_bi$len(train_dataset)\npy_bi$len(test_dataset)#> [1] 60000\n#> [1] 10000"},{"path":"pytorch-and-numpy.html","id":"iterators","chapter":"2 PyTorch and NumPy","heading":"Iterators","text":"Iterators used lot dataset operations running neural network. example iterate 100 elements 60,000 MNIST train dataset. goal printing “label” “class” digits reading. digits show ; stored tensors.","code":"\n# iterate through training dataset\nenum_train_dataset <- py_bi$enumerate(train_dataset)\ncat(sprintf(\"%8s %8s \\n\", \"index\", \"label\"))\n\nfor (i in 1:py_bi$len(train_dataset)) {\n    obj <- reticulate::iter_next(enum_train_dataset)\n    idx   <- obj[[1]]        # index number\n    cat(sprintf(\"%8d %5d \\n\", idx, obj[[2]][[2]]))\n    if (i >= 100) break   # print only 100 labels\n}\n#>    index    label \n#>        0     5 \n#>        1     0 \n#>        2     4 \n#>        3     1 \n#>        4     9 \n#>        5     2 \n#>        6     1 \n#>        7     3 \n#>        8     1 \n#>        9     4 \n#>       10     3 \n#>       11     5 \n#>       12     3 \n#>       13     6 \n#>       14     1 \n#>       15     7 \n#>       16     2 \n#>       17     8 \n#>       18     6 \n#>       19     9 \n#>       20     4 \n#>       21     0 \n#>       22     9 \n#>       23     1 \n#>       24     1 \n#>       25     2 \n#>       26     4 \n#>       27     3 \n#>       28     2 \n#>       29     7 \n#>       30     3 \n#>       31     8 \n#>       32     6 \n#>       33     9 \n#>       34     0 \n#>       35     5 \n#>       36     6 \n#>       37     0 \n#>       38     7 \n#>       39     6 \n#>       40     1 \n#>       41     8 \n#>       42     7 \n#>       43     9 \n#>       44     3 \n#>       45     9 \n#>       46     8 \n#>       47     5 \n#>       48     9 \n#>       49     3 \n#>       50     3 \n#>       51     0 \n#>       52     7 \n#>       53     4 \n#>       54     9 \n#>       55     8 \n#>       56     0 \n#>       57     9 \n#>       58     4 \n#>       59     1 \n#>       60     4 \n#>       61     4 \n#>       62     6 \n#>       63     0 \n#>       64     4 \n#>       65     5 \n#>       66     6 \n#>       67     1 \n#>       68     0 \n#>       69     0 \n#>       70     1 \n#>       71     7 \n#>       72     1 \n#>       73     6 \n#>       74     3 \n#>       75     0 \n#>       76     2 \n#>       77     1 \n#>       78     1 \n#>       79     7 \n#>       80     9 \n#>       81     0 \n#>       82     2 \n#>       83     6 \n#>       84     7 \n#>       85     8 \n#>       86     3 \n#>       87     9 \n#>       88     0 \n#>       89     4 \n#>       90     6 \n#>       91     7 \n#>       92     4 \n#>       93     6 \n#>       94     8 \n#>       95     0 \n#>       96     7 \n#>       97     8 \n#>       98     3 \n#>       99     1"},{"path":"pytorch-and-numpy.html","id":"types-and-instances","chapter":"2 PyTorch and NumPy","heading":"Types and instances","text":"Types, instances classes important take decisions process data read datasets. example, want know object certain instance:","code":"\n# get the class of the object\npy_bi$type(train_dataset)\n\n# is train_dataset a torchvision dataset class\npy_bi$isinstance(train_dataset, torchvision$datasets$mnist$MNIST)#> <class 'torchvision.datasets.mnist.MNIST'>\n#> [1] TRUE"},{"path":"rtorch-vs-pytorch.html","id":"rtorch-vs-pytorch","chapter":"3 rTorch vs PyTorch","heading":"3 rTorch vs PyTorch","text":"Last update: Sun Oct 25 13:00:41 2020 -0500 (265c0b3c1)","code":""},{"path":"rtorch-vs-pytorch.html","id":"whats-different","chapter":"3 rTorch vs PyTorch","heading":"3.1 What’s different","text":"chapter explain main differences PyTorch rTorch. things work directly PyTorch need aware minor differences working rTorch. review existing methods.Let’s start loading rTorch:","code":"\nlibrary(rTorch)"},{"path":"rtorch-vs-pytorch.html","id":"calling-objects-from-pytorch","chapter":"3 rTorch vs PyTorch","heading":"3.2 Calling objects from PyTorch","text":"use dollar sign $ call class, function method rTorch modules. case, torch module:Python, using dot separate sub-members object:","code":"\ntorch$tensor(c(1, 2, 3))#> tensor([1., 2., 3.])import torch\ntorch.tensor([1, 2, 3])#> tensor([1, 2, 3])"},{"path":"rtorch-vs-pytorch.html","id":"call-functions-from-torch","chapter":"3 rTorch vs PyTorch","heading":"3.3 Call functions from torch","text":"code equivalent writing code Python:can proceed extract classes, methods functions nn, transforms, dsets objects. example use module torchvision$datasets function transforms$ToTensor(). example, train_dataset MNIST:`","code":"\nlibrary(rTorch)\n# these are the equivalents of the Python import module\nnn          <- torch$nn\ntransforms  <- torchvision$transforms\ndsets       <- torchvision$datasets\n\ntorch$tensor(c(1, 2, 3))#> tensor([1., 2., 3.])import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\n\ntorch.tensor([1, 2, 3])#> tensor([1, 2, 3])\nlocal_folder <- './datasets/mnist_digits'\ntrain_dataset = torchvision$datasets$MNIST(root = local_folder, \n                                           train = TRUE, \n                                           transform = transforms$ToTensor(),\n                                           download = TRUE)\ntrain_dataset#> Dataset MNIST\n#>     Number of datapoints: 60000\n#>     Root location: ./datasets/mnist_digits\n#>     Split: Train\n#>     StandardTransform\n#> Transform: ToTensor()"},{"path":"rtorch-vs-pytorch.html","id":"python-objects","chapter":"3 rTorch vs PyTorch","heading":"3.4 Python objects","text":"Sometimes interested knowing internal components class. case, use reticulate function py_list_attributes().example, want show attributes train_dataset:Knowing internal methods class useful want refer specific property class. example, list , know object train_dataset attribute __len__. can call like :","code":"\nreticulate::py_list_attributes(train_dataset)#>  [1] \"__add__\"                \"__class__\"              \"__delattr__\"           \n#>  [4] \"__dict__\"               \"__dir__\"                \"__doc__\"               \n#>  [7] \"__eq__\"                 \"__format__\"             \"__ge__\"                \n#> [10] \"__getattribute__\"       \"__getitem__\"            \"__gt__\"                \n#> [13] \"__hash__\"               \"__init__\"               \"__init_subclass__\"     \n#> [16] \"__le__\"                 \"__len__\"                \"__lt__\"                \n#> [19] \"__module__\"             \"__ne__\"                 \"__new__\"               \n#> [22] \"__reduce__\"             \"__reduce_ex__\"          \"__repr__\"              \n#> [25] \"__setattr__\"            \"__sizeof__\"             \"__str__\"               \n#> [28] \"__subclasshook__\"       \"__weakref__\"            \"_check_exists\"         \n#> [31] \"_format_transform_repr\" \"_repr_indent\"           \"class_to_idx\"          \n#> [34] \"classes\"                \"data\"                   \"download\"              \n#> [37] \"extra_repr\"             \"processed_folder\"       \"raw_folder\"            \n#> [40] \"resources\"              \"root\"                   \"target_transform\"      \n#> [43] \"targets\"                \"test_data\"              \"test_file\"             \n#> [46] \"test_labels\"            \"train\"                  \"train_data\"            \n#> [49] \"train_labels\"           \"training_file\"          \"transform\"             \n#> [52] \"transforms\"\ntrain_dataset$`__len__`()#> [1] 60000"},{"path":"rtorch-vs-pytorch.html","id":"iterating-through-datasets","chapter":"3 rTorch vs PyTorch","heading":"3.5 Iterating through datasets","text":"","code":""},{"path":"rtorch-vs-pytorch.html","id":"enumeration","chapter":"3 rTorch vs PyTorch","heading":"3.5.1 Enumeration","text":"Given following training dataset x_train, want find number elements tensor. start entering numpy array, convert tensor PyTorch function from_numpy():length similar nelement number elements:","code":"\nx_train_r <- array(c(3.3, 4.4, 5.5, 6.71, 6.93, 4.168, \n                  9.779, 6.182, 7.59, 2.167, 7.042,\n                  10.791, 5.313, 7.997, 3.1), dim = c(15,1))\n\nx_train_np <- r_to_py(x_train_r)\nx_train_   <- torch$from_numpy(x_train_np)          # convert to tensor\nx_train    <- x_train_$type(torch$FloatTensor)      # make it a a FloatTensor\nprint(x_train$dtype)\nprint(x_train)#> torch.float32\n#> tensor([[ 3.3000],\n#>         [ 4.4000],\n#>         [ 5.5000],\n#>         [ 6.7100],\n#>         [ 6.9300],\n#>         [ 4.1680],\n#>         [ 9.7790],\n#>         [ 6.1820],\n#>         [ 7.5900],\n#>         [ 2.1670],\n#>         [ 7.0420],\n#>         [10.7910],\n#>         [ 5.3130],\n#>         [ 7.9970],\n#>         [ 3.1000]])\nlength(x_train)\nx_train$nelement()    # number of elements in the tensor#> [1] 15\n#> [1] 15"},{"path":"rtorch-vs-pytorch.html","id":"enumerate-and-iterate","chapter":"3 rTorch vs PyTorch","heading":"3.5.2 enumerate and iterate","text":"directly use iterate enum_x_train object, get R list index value 1D tensor:","code":"\npy = import_builtins()\n\nenum_x_train = py$enumerate(x_train)\nenum_x_train\n\npy$len(x_train)#> <enumerate>\n#> [1] 15\nxit = iterate(enum_x_train, simplify = TRUE)\nxit#> [[1]]\n#> [[1]][[1]]\n#> [1] 0\n#> \n#> [[1]][[2]]\n#> tensor([3.3000])\n#> \n#> \n#> [[2]]\n#> [[2]][[1]]\n#> [1] 1\n#> \n#> [[2]][[2]]\n#> tensor([4.4000])\n#> \n#> \n#> [[3]]\n#> [[3]][[1]]\n#> [1] 2\n#> \n#> [[3]][[2]]\n#> tensor([5.5000])\n#> \n#> \n#> [[4]]\n#> [[4]][[1]]\n#> [1] 3\n#> \n#> [[4]][[2]]\n#> tensor([6.7100])\n#> \n#> \n#> [[5]]\n#> [[5]][[1]]\n#> [1] 4\n#> \n#> [[5]][[2]]\n#> tensor([6.9300])\n#> \n#> \n#> [[6]]\n#> [[6]][[1]]\n#> [1] 5\n#> \n#> [[6]][[2]]\n#> tensor([4.1680])\n#> \n#> \n#> [[7]]\n#> [[7]][[1]]\n#> [1] 6\n#> \n#> [[7]][[2]]\n#> tensor([9.7790])\n#> \n#> \n#> [[8]]\n#> [[8]][[1]]\n#> [1] 7\n#> \n#> [[8]][[2]]\n#> tensor([6.1820])\n#> \n#> \n#> [[9]]\n#> [[9]][[1]]\n#> [1] 8\n#> \n#> [[9]][[2]]\n#> tensor([7.5900])\n#> \n#> \n#> [[10]]\n#> [[10]][[1]]\n#> [1] 9\n#> \n#> [[10]][[2]]\n#> tensor([2.1670])\n#> \n#> \n#> [[11]]\n#> [[11]][[1]]\n#> [1] 10\n#> \n#> [[11]][[2]]\n#> tensor([7.0420])\n#> \n#> \n#> [[12]]\n#> [[12]][[1]]\n#> [1] 11\n#> \n#> [[12]][[2]]\n#> tensor([10.7910])\n#> \n#> \n#> [[13]]\n#> [[13]][[1]]\n#> [1] 12\n#> \n#> [[13]][[2]]\n#> tensor([5.3130])\n#> \n#> \n#> [[14]]\n#> [[14]][[1]]\n#> [1] 13\n#> \n#> [[14]][[2]]\n#> tensor([7.9970])\n#> \n#> \n#> [[15]]\n#> [[15]][[1]]\n#> [1] 14\n#> \n#> [[15]][[2]]\n#> tensor([3.1000])"},{"path":"rtorch-vs-pytorch.html","id":"for-loop-for-iteration","chapter":"3 rTorch vs PyTorch","heading":"3.5.3 for-loop for iteration","text":"Another way iterating dataset see lot PyTorch tutorials loop length dataset. case, x_train. using cat() index (integer), print() tensor, since cat doesn’t know deal tensors:Similarly, want scalar values tensor, need use item().find frequently kind iterators read dataset read torchvision. several different ways iterate objects find.","code":"\n# reset the iterator\nenum_x_train = py$enumerate(x_train)\n\nfor (i in 1:py$len(x_train)) {\n    obj <- iter_next(enum_x_train)    # next item\n    cat(obj[[1]], \"\\t\")     # 1st part or index\n    print(obj[[2]])         # 2nd part or tensor\n}#> 0    tensor([3.3000])\n#> 1    tensor([4.4000])\n#> 2    tensor([5.5000])\n#> 3    tensor([6.7100])\n#> 4    tensor([6.9300])\n#> 5    tensor([4.1680])\n#> 6    tensor([9.7790])\n#> 7    tensor([6.1820])\n#> 8    tensor([7.5900])\n#> 9    tensor([2.1670])\n#> 10   tensor([7.0420])\n#> 11   tensor([10.7910])\n#> 12   tensor([5.3130])\n#> 13   tensor([7.9970])\n#> 14   tensor([3.1000])\n# reset the iterator\nenum_x_train = py$enumerate(x_train)\n\nfor (i in 1:py$len(x_train)) {\n    obj <- iter_next(enum_x_train)    # next item\n    cat(obj[[1]], \"\\t\")               # 1st part or index\n    print(obj[[2]]$item())            # 2nd part or tensor\n}#> 0    [1] 3.3\n#> 1    [1] 4.4\n#> 2    [1] 5.5\n#> 3    [1] 6.71\n#> 4    [1] 6.93\n#> 5    [1] 4.17\n#> 6    [1] 9.78\n#> 7    [1] 6.18\n#> 8    [1] 7.59\n#> 9    [1] 2.17\n#> 10   [1] 7.04\n#> 11   [1] 10.8\n#> 12   [1] 5.31\n#> 13   [1] 8\n#> 14   [1] 3.1"},{"path":"rtorch-vs-pytorch.html","id":"zero-gradient","chapter":"3 rTorch vs PyTorch","heading":"3.6 Zero gradient","text":"zero gradient one difficult implement R don’t pay attention content objects carrying weights biases. happens algorithm written PyTorch immediately translatable rTorch. can appreciated example.using seed PyTorch rTorch versions, , compare results.","code":""},{"path":"rtorch-vs-pytorch.html","id":"code-version-in-python","chapter":"3 rTorch vs PyTorch","heading":"3.6.1 Code version in Python","text":"","code":"import numpy as np\nimport torch\n\ntorch.manual_seed(0)  # reproducible\n\n# Input (temp, rainfall, humidity)#> <torch._C.Generator object at 0x7f95eb593250>inputs = np.array([[73, 67, 43],\n                   [91, 88, 64],\n                   [87, 134, 58],\n                   [102, 43, 37],\n                   [69, 96, 70]], dtype='float32')\n\n# Targets (apples, oranges)\ntargets = np.array([[56, 70],\n                    [81, 101],\n                    [119, 133],\n                    [22, 37],\n                    [103, 119]], dtype='float32')\n                    \n\n# Convert inputs and targets to tensors\ninputs  = torch.from_numpy(inputs)\ntargets = torch.from_numpy(targets)\n\n# random weights and biases\nw = torch.randn(2, 3, requires_grad=True)\nb = torch.randn(2, requires_grad=True)\n\n# function for the model\ndef model(x):\n  wt = w.t()\n  mm = x @ w.t()\n  return x @ w.t() + b       # @ represents matrix multiplication in PyTorch\n\n# MSE loss function\ndef mse(t1, t2):\n  diff = t1 - t2\n  return torch.sum(diff * diff) / diff.numel()\n\n# Running all together\n# Train for 100 epochs\nfor i in range(100):\n  preds = model(inputs)\n  loss = mse(preds, targets)\n  loss.backward()\n  with torch.no_grad():\n    w -= w.grad * 0.00001\n    b -= b.grad * 0.00001\n    w_gz = w.grad.zero_()\n    b_gz = b.grad.zero_()\n    \n# Calculate loss\npreds = model(inputs)\nloss = mse(preds, targets)\nprint(\"Loss: \", loss)    \n\n# predictions#> Loss:  tensor(1270.1233, grad_fn=<DivBackward0>)print(\"\\nPredictions:\")#> \n#> Predictions:preds\n\n# Targets#> tensor([[ 69.3122,  80.2639],\n#>         [ 73.7528,  97.2381],\n#>         [118.3933, 124.7628],\n#>         [ 89.6111,  93.0286],\n#>         [ 47.3014,  80.6467]], grad_fn=<AddBackward0>)print(\"\\nTargets:\")#> \n#> Targets:targets#> tensor([[ 56.,  70.],\n#>         [ 81., 101.],\n#>         [119., 133.],\n#>         [ 22.,  37.],\n#>         [103., 119.]])"},{"path":"rtorch-vs-pytorch.html","id":"code-version-in-r","chapter":"3 rTorch vs PyTorch","heading":"3.6.2 Code version in R","text":"Notice Python, tensor operation, gradient (\\(\\nabla\\)) weights \\(w\\) times Learning Rate \\(\\alpha\\), :\\[w = -w + \\nabla w \\; \\alpha\\]Python, straight forwward clean code:R, without generics, shows little bit convoluted:","code":"\nlibrary(rTorch)\n\ntorch$manual_seed(0)\n\ndevice = torch$device('cpu')\n# Input (temp, rainfall, humidity)\ninputs = np$array(list(list(73, 67, 43),\n                   list(91, 88, 64),\n                   list(87, 134, 58),\n                   list(102, 43, 37),\n                   list(69, 96, 70)), dtype='float32')\n\n# Targets (apples, oranges)\ntargets = np$array(list(list(56, 70), \n                    list(81, 101),\n                    list(119, 133),\n                    list(22, 37), \n                    list(103, 119)), dtype='float32')\n\n\n# Convert inputs and targets to tensors\ninputs = torch$from_numpy(inputs)\ntargets = torch$from_numpy(targets)\n\n# random numbers for weights and biases. Then convert to double()\ntorch$set_default_dtype(torch$float64)\n\nw = torch$randn(2L, 3L, requires_grad=TRUE) #$double()\nb = torch$randn(2L, requires_grad=TRUE) #$double()\n\nmodel <- function(x) {\n  wt <- w$t()\n  return(torch$add(torch$mm(x, wt), b))\n}\n\n# MSE loss\nmse = function(t1, t2) {\n  diff <- torch$sub(t1, t2)\n  mul <- torch$sum(torch$mul(diff, diff))\n  return(torch$div(mul, diff$numel()))\n}\n\n# Running all together\n# Adjust weights and reset gradients\nfor (i in 1:100) {\n  preds = model(inputs)\n  loss = mse(preds, targets)\n  loss$backward()\n  with(torch$no_grad(), {\n    w$data <- torch$sub(w$data, torch$mul(w$grad, torch$scalar_tensor(1e-5)))\n    b$data <- torch$sub(b$data, torch$mul(b$grad, torch$scalar_tensor(1e-5)))\n    \n    w$grad$zero_()\n    b$grad$zero_()\n  })\n}\n\n# Calculate loss\npreds = model(inputs)\nloss = mse(preds, targets)\ncat(\"Loss: \"); print(loss)\n\n# predictions\ncat(\"\\nPredictions:\\n\")\npreds\n\n# Targets\ncat(\"\\nTargets:\\n\")\ntargets#> <torch._C.Generator>\n#> Loss: tensor(1270.1237, grad_fn=<DivBackward0>)\n#> \n#> Predictions:\n#> tensor([[ 69.3122,  80.2639],\n#>         [ 73.7528,  97.2381],\n#>         [118.3933, 124.7628],\n#>         [ 89.6111,  93.0286],\n#>         [ 47.3013,  80.6467]], grad_fn=<AddBackward0>)\n#> \n#> Targets:\n#> tensor([[ 56.,  70.],\n#>         [ 81., 101.],\n#>         [119., 133.],\n#>         [ 22.,  37.],\n#>         [103., 119.]])w -= w.grad * 1e-5\nw$data <- torch$sub(w$data, torch$mul(w$grad, torch$scalar_tensor(1e-5)))"},{"path":"rtorch-vs-pytorch.html","id":"r-generic-functions","chapter":"3 rTorch vs PyTorch","heading":"3.7 R generic functions","text":"simplified common operations using R generic function. use generic methods rTorch operation looks much neater.following two expressions equivalent, first long version natural way PyTorch. second using generics R subtraction, multiplication scalar conversion.","code":"\nw$data <- w$data - w$grad * 1e-5param$data <- torch$sub(param$data,\n                        torch$mul(param$grad$float(),\n                          torch$scalar_tensor(learning_rate)))\n}\nparam$data <- param$data - param$grad * learning_rate"},{"path":"converting-tensors.html","id":"converting-tensors","chapter":"4 Converting tensors","heading":"4 Converting tensors","text":"Last update: Sun Oct 25 13:00:09 2020 -0500 (f5e8a1973)","code":"\nlibrary(rTorch)"},{"path":"converting-tensors.html","id":"tensor-to-numpy-array","chapter":"4 Converting tensors","heading":"4.1 Tensor to numpy array","text":"frequent operation. found necessary :numpy function implemented PyTorchWe need convert tensor RPerform boolean operation directly available PyTorchIf attempt plot two tensors get error:need converted numpy, R (happens background):","code":"\nx <- torch$arange(1, 10)\ny <- x^2\nplot(x, y)#> Error in as.double(x): cannot coerce type 'environment' to vector of type 'double'\nplot(x$numpy(), y$numpy())"},{"path":"converting-tensors.html","id":"numpy-array-to-tensor","chapter":"4 Converting tensors","heading":"4.2 numpy array to tensor","text":"Explain transform tensor back forth numpy.important?cases necessary?","code":"\np <- np$arange(1, 10)\nclass(p)#> [1] \"array\"\n(pt <- torch$as_tensor(p))#> tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\nclass(pt)#> [1] \"torch.Tensor\"          \"torch._C._TensorBase\"  \"python.builtin.object\""},{"path":"converting-tensors.html","id":"numpy-array-to-r","chapter":"4 Converting tensors","heading":"4.2.1 numpy array to R","text":"mainly required reasons:Create data structure RPlot using r-base ggplot2Perform analysis parts tensorUse R statistical functions available PyTorch","code":""},{"path":"converting-tensors.html","id":"r-objects-to-numpy-objects","chapter":"4 Converting tensors","heading":"4.3 R objects to numpy objects","text":"Given R matrix \\(m\\):explicitly convert numpy object function r_to_py():","code":"\nm <- matrix(seq(1,10), nrow = 2)\nm#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    3    5    7    9\n#> [2,]    2    4    6    8   10\n(mp <- r_to_py(m))#> [[ 1  3  5  7  9]\n#>  [ 2  4  6  8 10]]\nclass(mp)#> [1] \"numpy.ndarray\"         \"python.builtin.object\"\nclass(mp)#> [1] \"numpy.ndarray\"         \"python.builtin.object\""},{"path":"tensors.html","id":"tensors","chapter":"5 Tensors","heading":"5 Tensors","text":"Last update: Sun Oct 25 13:00:41 2020 -0500 (265c0b3c1)chapter, describe important PyTorch methods.","code":"\nlibrary(rTorch)"},{"path":"tensors.html","id":"tensor-data-types","chapter":"5 Tensors","heading":"5.1 Tensor data types","text":"","code":"\n# Default data type\ntorch$tensor(list(1.2, 3))$dtype  # default for floating point is torch.float32#> torch.float32\n# change default data type to float64\ntorch$set_default_dtype(torch$float64)\ntorch$tensor(list(1.2, 3))$dtype         # a new floating point tensor#> torch.float64"},{"path":"tensors.html","id":"major-tensor-types","chapter":"5 Tensors","heading":"5.1.1 Major tensor types","text":"five major type tensors PyTorch: byte, float, double, long, boolean.","code":"\nlibrary(rTorch)\n\nbyte    <- torch$ByteTensor(3L, 3L)\nfloat   <- torch$FloatTensor(3L, 3L)\ndouble  <- torch$DoubleTensor(3L, 3L)\nlong    <- torch$LongTensor(3L, 3L)\nboolean <- torch$BoolTensor(5L, 5L)\nmessage(\"byte tensor\")\n#> byte tensor\nbyte\n#> tensor([[ 32,  61, 207],\n#>         [238, 114, 127],\n#>         [  0,   0,  32]], dtype=torch.uint8)\nmessage(\"float tensor\")\n#> float tensor\nfloat\n#> tensor([[0., 0., 0.],\n#>         [0., 0., 0.],\n#>         [0., 0., 0.]], dtype=torch.float32)\nmessage(\"double\")\n#> double\ndouble\n#> tensor([[ 0.0000e+00,  0.0000e+00, 9.5490e-313],\n#>         [4.6782e-310, 4.9407e-324, 4.6782e-310],\n#>         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\nmessage(\"long\")\n#> long\nlong\n#> tensor([[             1, 94687710309152,              0],\n#>         [             0,              0,              0],\n#>         [             0,              0,              0]])\nmessage(\"boolean\")\n#> boolean\nboolean\n#> tensor([[False, False, False, False, False],\n#>         [False, False, False, False, False],\n#>         [False, False, False, False, False],\n#>         [False, False, False, False, False],\n#>         [False, False, False, False,  True]])"},{"path":"tensors.html","id":"example-a-4d-tensor","chapter":"5 Tensors","heading":"5.1.2 Example: A 4D tensor","text":"4D tensor like MNIST hand-written digits recognition dataset:","code":"\nmnist_4d <- torch$FloatTensor(60000L, 3L, 28L, 28L)\nmessage(\"size\")\n#> size\nmnist_4d$size()\n#> torch.Size([60000, 3, 28, 28])\n\nmessage(\"length\")\n#> length\nlength(mnist_4d)\n#> [1] 141120000\n\nmessage(\"shape, like in numpy\")\n#> shape, like in numpy\nmnist_4d$shape\n#> torch.Size([60000, 3, 28, 28])\n\nmessage(\"number of elements\")\n#> number of elements\nmnist_4d$numel()\n#> [1] 141120000"},{"path":"tensors.html","id":"example-a-3d-tensor","chapter":"5 Tensors","heading":"5.1.3 Example: A 3D tensor","text":"Given 3D tensor:","code":"\nft3d <- torch$FloatTensor(4L, 3L, 2L)\nft3d#> tensor([[[-3.2069e+28,  4.5719e-41],\n#>          [ 4.4665e-11,  3.0893e-41],\n#>          [ 1.4668e-10,  3.0893e-41]],\n#> \n#>         [[-4.2374e+28,  4.5719e-41],\n#>          [ 5.6052e-44,  0.0000e+00],\n#>          [ 0.0000e+00,  0.0000e+00]],\n#> \n#>         [[ 1.4013e-45,  2.8026e-45],\n#>          [ 4.2039e-45,  5.6052e-45],\n#>          [ 7.0065e-45,  8.4078e-45]],\n#> \n#>         [[ 9.8091e-45,  1.1210e-44],\n#>          [ 1.2612e-44,  1.4013e-44],\n#>          [ 1.5414e-44,  1.6816e-44]]], dtype=torch.float32)\nft3d$size()\n#> torch.Size([4, 3, 2])\nlength(ft3d)\n#> [1] 24\nft3d$shape\n#> torch.Size([4, 3, 2])\nft3d$numel\n#> <built-in method numel of Tensor>"},{"path":"tensors.html","id":"arithmetic-of-tensors","chapter":"5 Tensors","heading":"5.2 Arithmetic of tensors","text":"","code":""},{"path":"tensors.html","id":"add-tensors","chapter":"5 Tensors","heading":"5.2.1 Add tensors","text":"","code":"\n# add a scalar to a tensor\n# 3x5 matrix uniformly distributed between 0 and 1\nmat0 <- torch$FloatTensor(3L, 5L)$uniform_(0L, 1L)\nmat0 + 0.1#> tensor([[0.3650, 0.7111, 0.5408, 0.3499, 0.6317],\n#>         [0.4526, 1.0476, 0.4710, 0.2819, 1.0654],\n#>         [1.0387, 0.8991, 0.8999, 1.0869, 0.3825]], dtype=torch.float32)"},{"path":"tensors.html","id":"add-tensor-elements","chapter":"5 Tensors","heading":"5.2.2 Add tensor elements","text":"Add two tensors using function add():Add two tensors using generic +:","code":"\n# fill a 3x5 matrix with 0.1\nmat1 <- torch$FloatTensor(3L, 5L)$uniform_(0.1, 0.1)\nprint(mat1)\n#> tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n#>         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n#>         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]], dtype=torch.float32)\n\n# a vector with all ones\nmat2 <- torch$FloatTensor(5L)$uniform_(1, 1)\nprint(mat2)\n#> tensor([1., 1., 1., 1., 1.], dtype=torch.float32)\n\n# add element (1,1) to another tensor\nmat1[1, 1] + mat2\n#> tensor([1.1000, 1.1000, 1.1000, 1.1000, 1.1000], dtype=torch.float32)\n# PyTorch add two tensors\nx = torch$rand(5L, 4L)\ny = torch$rand(5L, 4L)\n\nprint(x$add(y))#> tensor([[0.7098, 1.0429, 0.7067, 0.3477],\n#>         [1.4853, 1.2497, 0.6409, 1.7089],\n#>         [0.8443, 1.4717, 1.3448, 1.0267],\n#>         [1.4407, 1.0881, 0.2117, 1.3567],\n#>         [0.6607, 1.0855, 0.8206, 0.8289]])\nprint(x + y)#> tensor([[0.7098, 1.0429, 0.7067, 0.3477],\n#>         [1.4853, 1.2497, 0.6409, 1.7089],\n#>         [0.8443, 1.4717, 1.3448, 1.0267],\n#>         [1.4407, 1.0881, 0.2117, 1.3567],\n#>         [0.6607, 1.0855, 0.8206, 0.8289]])"},{"path":"tensors.html","id":"multiply-a-tensor-by-a-scalar","chapter":"5 Tensors","heading":"5.2.3 Multiply a tensor by a scalar","text":"Notice used NumPy function create scalar object np$float64().Multiply two tensors using function mul:Short version using R generics:","code":"\n# Multiply tensor by scalar\ntensor = torch$ones(4L, dtype=torch$float64)\nscalar = np$float64(4.321)\nprint(scalar)\nprint(torch$scalar_tensor(scalar))#> [1] 4.32\n#> tensor(4.3210)\n(prod = torch$mul(tensor, torch$scalar_tensor(scalar)))#> tensor([4.3210, 4.3210, 4.3210, 4.3210])\n(prod = tensor * scalar)#> tensor([4.3210, 4.3210, 4.3210, 4.3210])"},{"path":"tensors.html","id":"numpy-and-pytorch","chapter":"5 Tensors","heading":"5.3 NumPy and PyTorch","text":"numpy made available module rTorch, means soon rTorch loaded, also get numpy functions available . can call functions numpy referring np$_a_function. Examples:dot product :","code":"\n# a 2D numpy array  \nsyn0 <- np$random$rand(3L, 5L)\nprint(syn0)#>       [,1]  [,2]   [,3]  [,4]   [,5]\n#> [1,] 0.120 0.304 0.7796 0.303 0.7737\n#> [2,] 0.197 0.893 0.0919 0.455 0.0865\n#> [3,] 0.606 0.979 0.1491 0.896 0.3152\n# numpy arrays of zeros\nsyn1 <- np$zeros(c(5L, 10L))\nprint(syn1)#>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#> [1,]    0    0    0    0    0    0    0    0    0     0\n#> [2,]    0    0    0    0    0    0    0    0    0     0\n#> [3,]    0    0    0    0    0    0    0    0    0     0\n#> [4,]    0    0    0    0    0    0    0    0    0     0\n#> [5,]    0    0    0    0    0    0    0    0    0     0\n# add a scalar to a numpy array\nsyn1 = syn1 + 0.1\nprint(syn1)#>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#> [1,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1\n#> [2,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1\n#> [3,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1\n#> [4,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1\n#> [5,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1\nnp$dot(syn0, syn1)#>       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]\n#> [1,] 0.228 0.228 0.228 0.228 0.228 0.228 0.228 0.228 0.228 0.228\n#> [2,] 0.172 0.172 0.172 0.172 0.172 0.172 0.172 0.172 0.172 0.172\n#> [3,] 0.295 0.295 0.295 0.295 0.295 0.295 0.295 0.295 0.295 0.295"},{"path":"tensors.html","id":"python-tuples-and-r-vectors","chapter":"5 Tensors","heading":"5.3.1 Python tuples and R vectors","text":"numpy shape multidimensional array needs defined using tuple. R instead vector. tuples R.Python, use tuple, (5, 5) indicate shape array:R, use vector c(5L, 5L). L indicates integer.","code":"import numpy as np\nprint(np.ones((5, 5)))#> [[1. 1. 1. 1. 1.]\n#>  [1. 1. 1. 1. 1.]\n#>  [1. 1. 1. 1. 1.]\n#>  [1. 1. 1. 1. 1.]\n#>  [1. 1. 1. 1. 1.]]\nl1 <- np$ones(c(5L, 5L))\nprint(l1)#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    1    1    1    1\n#> [2,]    1    1    1    1    1\n#> [3,]    1    1    1    1    1\n#> [4,]    1    1    1    1    1\n#> [5,]    1    1    1    1    1"},{"path":"tensors.html","id":"a-numpy-array-from-r-vectors","chapter":"5 Tensors","heading":"5.3.2 A numpy array from R vectors","text":"matrix, 2D tensor, use three R vectors:transpose array using numpy well:","code":"\nX <- np$array(rbind(c(1,2,3), c(4,5,6), c(7,8,9)))\nprint(X)#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\nnp$transpose(X)#>      [,1] [,2] [,3]\n#> [1,]    1    4    7\n#> [2,]    2    5    8\n#> [3,]    3    6    9"},{"path":"tensors.html","id":"numpy-arrays-to-tensors","chapter":"5 Tensors","heading":"5.3.3 numpy arrays to tensors","text":"","code":"\na = np$array(list(1, 2, 3))   # a numpy array\nt = torch$as_tensor(a)        # convert it to tensor\nprint(t)#> tensor([1., 2., 3.])"},{"path":"tensors.html","id":"create-and-fill-a-tensor","chapter":"5 Tensors","heading":"5.3.4 Create and fill a tensor","text":"can create tensor directly R using tensor():","code":"\ntorch$tensor(list( 1,  2,  3))   # create a tensor\nt[1L]$fill_(-1)                  # fill element with -1\nprint(a)#> tensor([1., 2., 3.])\n#> tensor(-1.)\n#> [1] -1  2  3"},{"path":"tensors.html","id":"tensor-to-array-and-viceversa","chapter":"5 Tensors","heading":"5.3.5 Tensor to array, and viceversa","text":"common operation machine learning:","code":"\n# convert tensor to a numpy array\na = torch$rand(5L, 4L)\nb = a$numpy()\nprint(b)#>        [,1]   [,2]  [,3]   [,4]\n#> [1,] 0.0496 0.0971 0.321 0.0836\n#> [2,] 0.0963 0.3515 0.180 0.4117\n#> [3,] 0.9172 0.6132 0.459 0.3886\n#> [4,] 0.4897 0.6488 0.252 0.1562\n#> [5,] 0.7528 0.0970 0.860 0.0822\n# convert a numpy array to a tensor\nnp_a = np$array(c(c(3, 4), c(3, 6)))\nt_a = torch$from_numpy(np_a)\nprint(t_a)#> tensor([3., 4., 3., 6.])"},{"path":"tensors.html","id":"create-tensors","chapter":"5 Tensors","heading":"5.4 Create tensors","text":"random 1D tensor:Force tensor float 64-bits:Convert tensor float 16-bits:Create tensor size (5 x 7) uninitialized memory:Using arange create tensor. arange starts 0.","code":"\nft1 <- torch$FloatTensor(np$random$rand(5L))\nprint(ft1)#> tensor([0.8830, 0.2745, 0.8810, 0.3567, 0.0459], dtype=torch.float32)\nft2 <- torch$as_tensor(np$random$rand(5L), dtype= torch$float64)\nprint(ft2)#> tensor([0.8784, 0.2209, 0.8844, 0.1705, 0.9309])\nft2_dbl <- torch$as_tensor(ft2, dtype = torch$float16)\nft2_dbl#> tensor([0.8784, 0.2208, 0.8843, 0.1704, 0.9312], dtype=torch.float16)\na <- torch$FloatTensor(5L, 7L)\nprint(a)#> tensor([[7.5670e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n#>          0.0000e+00],\n#>         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n#>          0.0000e+00],\n#>         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n#>          0.0000e+00],\n#>         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n#>          0.0000e+00],\n#>         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n#>          0.0000e+00]], dtype=torch.float32)\nv = torch$arange(9L)\nprint(v)#> tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n# reshape\n(v = v$view(3L, 3L))#> tensor([[0, 1, 2],\n#>         [3, 4, 5],\n#>         [6, 7, 8]])"},{"path":"tensors.html","id":"tensor-fill","chapter":"5 Tensors","heading":"5.4.1 Tensor fill","text":"tensor:Fill row 1 2s:Fill row 2 3s:Fill column 3 fours (4):","code":"\n(v = torch$ones(3L, 3L))#> tensor([[1., 1., 1.],\n#>         [1., 1., 1.],\n#>         [1., 1., 1.]])\ninvisible(v[1L, ]$fill_(2L))\nprint(v)#> tensor([[2., 2., 2.],\n#>         [1., 1., 1.],\n#>         [1., 1., 1.]])\ninvisible(v[2L, ]$fill_(3L))\nprint(v)#> tensor([[2., 2., 2.],\n#>         [3., 3., 3.],\n#>         [1., 1., 1.]])\ninvisible(v[, 3]$fill_(4L))\nprint(v)#> tensor([[2., 2., 4.],\n#>         [3., 3., 4.],\n#>         [1., 1., 4.]])"},{"path":"tensors.html","id":"tensor-with-a-range-of-values","chapter":"5 Tensors","heading":"5.4.2 Tensor with a range of values","text":"","code":"\n# Initialize Tensor with a range of value\nv = torch$arange(10L)             # similar to range(5) but creating a Tensor\n(v = torch$arange(0L, 10L, step = 1L))  # Size 5. Similar to range(0, 5, 1)#> tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"},{"path":"tensors.html","id":"linear-or-log-scale-tensor","chapter":"5 Tensors","heading":"5.4.3 Linear or log scale Tensor","text":"Create tensor 10 linear points (1, 10) inclusive:Create tensor 10 logarithmic points (1, 10) inclusive:","code":"\n(v = torch$linspace(1L, 10L, steps = 10L)) #> tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n(v = torch$logspace(start=-10L, end = 10L, steps = 5L)) #> tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"},{"path":"tensors.html","id":"in-place-out-of-place-fill","chapter":"5 Tensors","heading":"5.4.4 In-place / Out-of-place fill","text":"uninitialized tensor:Fill tensor value 3.5:Add scalar tensor:tensor still filled 3.5. new tensor b returned values 3.5 + 4.0 = 7.5","code":"\n(a <- torch$FloatTensor(5L, 7L))#> tensor([[-3.2069e+28,  4.5719e-41,  4.5986e-10,  3.0893e-41,  0.0000e+00,\n#>           0.0000e+00,  0.0000e+00],\n#>         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n#>           5.6723e-11,  3.0893e-41],\n#>         [ 0.0000e+00,  0.0000e+00,  2.2390e-11,  3.0893e-41,  2.2390e-11,\n#>           3.0893e-41,  2.2390e-11],\n#>         [ 3.0893e-41,  7.0065e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n#>           0.0000e+00,  0.0000e+00],\n#>         [-3.0322e+14,  4.5719e-41,  0.0000e+00,  0.0000e+00,  2.2390e-11,\n#>           3.0893e-41,  2.2390e-11]], dtype=torch.float32)\na$fill_(3.5)#> tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]],\n#>        dtype=torch.float32)\nb <- a$add(4.0)\nprint(a)\nprint(b)#> tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n#>         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]],\n#>        dtype=torch.float32)\n#> tensor([[7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],\n#>         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],\n#>         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],\n#>         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],\n#>         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000]],\n#>        dtype=torch.float32)"},{"path":"tensors.html","id":"tensor-resizing","chapter":"5 Tensors","heading":"5.5 Tensor resizing","text":"","code":"\nx = torch$randn(2L, 3L)            # Size 2x3\nprint(x)\n#> tensor([[-0.0999, -0.0920,  1.8464],\n#>         [ 2.7680, -0.9260, -1.0860]])\n\ny = x$view(6L)                     # Resize x to size 6\nprint(y)\n#> tensor([-0.0999, -0.0920,  1.8464,  2.7680, -0.9260, -1.0860])\n\nz = x$view(-1L, 2L)                # Size 3x2\nprint(z)\n#> tensor([[-0.0999, -0.0920],\n#>         [ 1.8464,  2.7680],\n#>         [-0.9260, -1.0860]])\nprint(z$shape)\n#> torch.Size([3, 2])"},{"path":"tensors.html","id":"exercise","chapter":"5 Tensors","heading":"5.5.1 Exercise","text":"Reproduce tensor:","code":" 0 1 2\n 3 4 5\n 6 7 8\n# create a vector with the number of elements\nv = torch$arange(9L)\n\n# resize to a 3x3 tensor\n(v = v$view(3L, 3L))#> tensor([[0, 1, 2],\n#>         [3, 4, 5],\n#>         [6, 7, 8]])"},{"path":"tensors.html","id":"concatenate-tensors","chapter":"5 Tensors","heading":"5.6 Concatenate tensors","text":"","code":"\nx = torch$randn(2L, 3L)\nprint(x)\nprint(x$shape)#> tensor([[ 0.8657, -0.1748, -0.9896],\n#>         [ 0.2095, -0.1623,  1.1728]])\n#> torch.Size([2, 3])"},{"path":"tensors.html","id":"concatenate-by-rows","chapter":"5 Tensors","heading":"5.6.1 Concatenate by rows","text":"","code":"\n(x0 <- torch$cat(list(x, x, x), 0L))\nprint(x0$shape)#> tensor([[ 0.8657, -0.1748, -0.9896],\n#>         [ 0.2095, -0.1623,  1.1728],\n#>         [ 0.8657, -0.1748, -0.9896],\n#>         [ 0.2095, -0.1623,  1.1728],\n#>         [ 0.8657, -0.1748, -0.9896],\n#>         [ 0.2095, -0.1623,  1.1728]])\n#> torch.Size([6, 3])"},{"path":"tensors.html","id":"concatenate-by-columns","chapter":"5 Tensors","heading":"5.6.2 Concatenate by columns","text":"","code":"\n(x1 <- torch$cat(list(x, x, x), 1L))\nprint(x1$shape)#> tensor([[ 0.8657, -0.1748, -0.9896,  0.8657, -0.1748, -0.9896,  0.8657, -0.1748,\n#>          -0.9896],\n#>         [ 0.2095, -0.1623,  1.1728,  0.2095, -0.1623,  1.1728,  0.2095, -0.1623,\n#>           1.1728]])\n#> torch.Size([2, 9])"},{"path":"tensors.html","id":"reshape-tensors","chapter":"5 Tensors","heading":"5.7 Reshape tensors","text":"","code":""},{"path":"tensors.html","id":"with-chunk","chapter":"5 Tensors","heading":"5.7.1 With chunk():","text":"Let’s say image tensor 3-channels 28x28 pixelsOn first dimension dim = 0L, reshape tensor:img_chunks list three members.first chunk member:second chunk member:","code":"\n# ----- Reshape tensors -----\nimg <- torch$ones(3L, 28L, 28L)  # Create the tensor of ones\nprint(img$size())#> torch.Size([3, 28, 28])\nimg_chunks <- torch$chunk(img, chunks = 3L, dim = 0L)\nprint(length(img_chunks))\nprint(class(img_chunks))#> [1] 3\n#> [1] \"list\"\n# 1st chunk member\nimg_chunk <- img_chunks[[1]]\nprint(img_chunk$size())\nprint(img_chunk$sum())      # if the tensor had all ones, what is the sum?#> torch.Size([1, 28, 28])\n#> tensor(784.)\n# 2nd chunk member\nimg_chunk <- img_chunks[[2]]\nprint(img_chunk$size())\nprint(img_chunk$sum())        # if the tensor had all ones, what is the sum?#> torch.Size([1, 28, 28])\n#> tensor(784.)\n# 3rd chunk member\nimg_chunk <- img_chunks[[3]]\nprint(img_chunk$size())\nprint(img_chunk$sum())        # if the tensor had all ones, what is the sum?#> torch.Size([1, 28, 28])\n#> tensor(784.)"},{"path":"tensors.html","id":"exercise-1","chapter":"5 Tensors","heading":"5.7.1.1 Exercise","text":"Create tensor shape 3x28x28 filled values 0.25 first channelThe second channel 0.5The third chanel 0.75Find sum ecah separate channelFind sum channels","code":""},{"path":"tensors.html","id":"with-index_select","chapter":"5 Tensors","heading":"5.7.2 With index_select():","text":"layer 1:size layer:sum elements layer:layer 2:layer 3:","code":"\nimg <- torch$ones(3L, 28L, 28L)  # Create the tensor of ones\nimg$size()#> torch.Size([3, 28, 28])\n# index_select. get layer 1\nindices = torch$tensor(c(0L))\nimg_layer_1 <- torch$index_select(img, dim = 0L, index = indices)\nprint(img_layer_1$size())#> torch.Size([1, 28, 28])\nprint(img_layer_1$sum())#> tensor(784.)\n# index_select. get layer 2\nindices = torch$tensor(c(1L))\nimg_layer_2 <- torch$index_select(img, dim = 0L, index = indices)\nprint(img_layer_2$size())\nprint(img_layer_2$sum())#> torch.Size([1, 28, 28])\n#> tensor(784.)\n# index_select. get layer 3\nindices = torch$tensor(c(2L))\nimg_layer_3 <- torch$index_select(img, dim = 0L, index = indices)\nprint(img_layer_3$size())\nprint(img_layer_3$sum())#> torch.Size([1, 28, 28])\n#> tensor(784.)"},{"path":"tensors.html","id":"special-tensors","chapter":"5 Tensors","heading":"5.8 Special tensors","text":"","code":""},{"path":"tensors.html","id":"identity-matrix","chapter":"5 Tensors","heading":"5.8.1 Identity matrix","text":"","code":"\n# identity matrix\neye = torch$eye(3L)              # Create an identity 3x3 tensor\nprint(eye)#> tensor([[1., 0., 0.],\n#>         [0., 1., 0.],\n#>         [0., 0., 1.]])\n# a 5x5 identity or unit matrix\ntorch$eye(5L)#> tensor([[1., 0., 0., 0., 0.],\n#>         [0., 1., 0., 0., 0.],\n#>         [0., 0., 1., 0., 0.],\n#>         [0., 0., 0., 1., 0.],\n#>         [0., 0., 0., 0., 1.]])"},{"path":"tensors.html","id":"ones","chapter":"5 Tensors","heading":"5.8.2 Ones","text":"matrix ones also called `unitary matrix. 4x4 unitary matrix.","code":"\n(v = torch$ones(10L))               # A tensor of size 10 containing all ones\n\n# reshape\n(v = torch$ones(2L, 1L, 2L, 1L))     # Size 2x1x2x1, a 4D tensor#> tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n#> tensor([[[[1.],\n#>           [1.]]],\n#> \n#> \n#>         [[[1.],\n#>           [1.]]]])\ntorch$ones(c(4L, 4L))#> tensor([[1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.]])\n# eye tensor\neye = torch$eye(3L)\nprint(eye)\n# like eye tensor\nv = torch$ones_like(eye)     # A tensor with same shape as eye. Fill it with 1.\nv#> tensor([[1., 0., 0.],\n#>         [0., 1., 0.],\n#>         [0., 0., 1.]])\n#> tensor([[1., 1., 1.],\n#>         [1., 1., 1.],\n#>         [1., 1., 1.]])"},{"path":"tensors.html","id":"zeros","chapter":"5 Tensors","heading":"5.8.3 Zeros","text":"","code":"\n(z = torch$zeros(10L))             # A tensor of size 10 containing all zeros#> tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n# matrix of zeros\ntorch$zeros(c(4L, 4L))#> tensor([[0., 0., 0., 0.],\n#>         [0., 0., 0., 0.],\n#>         [0., 0., 0., 0.],\n#>         [0., 0., 0., 0.]])\n# a 3D tensor of zeros\ntorch$zeros(c(3L, 4L, 2L))#> tensor([[[0., 0.],\n#>          [0., 0.],\n#>          [0., 0.],\n#>          [0., 0.]],\n#> \n#>         [[0., 0.],\n#>          [0., 0.],\n#>          [0., 0.],\n#>          [0., 0.]],\n#> \n#>         [[0., 0.],\n#>          [0., 0.],\n#>          [0., 0.],\n#>          [0., 0.]]])"},{"path":"tensors.html","id":"diagonal-operations","chapter":"5 Tensors","heading":"5.8.4 Diagonal operations","text":"Given 1D tensor","code":"\na <- torch$tensor(c(1L, 2L, 3L))\na#> tensor([1, 2, 3])"},{"path":"tensors.html","id":"diagonal-matrix","chapter":"5 Tensors","heading":"5.8.4.1 Diagonal matrix","text":"want fill main diagonal vector:filling diagonal main:diagonal main:","code":"\ntorch$diag(a)#> tensor([[1, 0, 0],\n#>         [0, 2, 0],\n#>         [0, 0, 3]])\ntorch$diag(a, 1L)#> tensor([[0, 1, 0, 0],\n#>         [0, 0, 2, 0],\n#>         [0, 0, 0, 3],\n#>         [0, 0, 0, 0]])\ntorch$diag(a, -1L)#> tensor([[0, 0, 0, 0],\n#>         [1, 0, 0, 0],\n#>         [0, 2, 0, 0],\n#>         [0, 0, 3, 0]])"},{"path":"tensors.html","id":"access-to-tensor-elements","chapter":"5 Tensors","heading":"5.9 Access to tensor elements","text":"Print element position 1,1:Fill element position 1,1 5:Show modified tensor:Access element position 1, 0:","code":"\n# replace an element at position 0, 0\n(new_tensor = torch$Tensor(list(list(1, 2), list(3, 4))))#> tensor([[1., 2.],\n#>         [3., 4.]])\nprint(new_tensor[1L, 1L])#> tensor(1.)\nnew_tensor[1L, 1L]$fill_(5)#> tensor(5.)\nprint(new_tensor)   # tensor([[ 5.,  2.],[ 3.,  4.]])#> tensor([[5., 2.],\n#>         [3., 4.]])\nprint(new_tensor[2L, 1L])           # tensor([ 3.])\nprint(new_tensor[2L, 1L]$item())    # 3.#> tensor(3.)\n#> [1] 3"},{"path":"tensors.html","id":"indices-to-tensor-elements","chapter":"5 Tensors","heading":"5.9.1 Indices to tensor elements","text":"tensor:Select indices, dim=0:Select indices, dim=1:","code":"\nx = torch$randn(3L, 4L)\nprint(x)#> tensor([[-0.0156, -1.8155,  1.2381,  0.1425],\n#>         [-0.4337, -2.4449, -1.3382, -1.5677],\n#>         [ 1.9066, -0.4448,  0.5842,  0.0369]])\nindices = torch$tensor(list(0L, 2L))\ntorch$index_select(x, 0L, indices)#> tensor([[-0.0156, -1.8155,  1.2381,  0.1425],\n#>         [ 1.9066, -0.4448,  0.5842,  0.0369]])\ntorch$index_select(x, 1L, indices)#> tensor([[-0.0156,  1.2381],\n#>         [-0.4337, -1.3382],\n#>         [ 1.9066,  0.5842]])"},{"path":"tensors.html","id":"using-the-take-function","chapter":"5 Tensors","heading":"5.9.2 Using the take function","text":"","code":"\n# Take by indices\nsrc = torch$tensor(list(list(4, 3, 5),\n                        list(6, 7, 8)) )\nprint(src)\nprint( torch$take(src, torch$tensor(list(0L, 2L, 5L))) )#> tensor([[4., 3., 5.],\n#>         [6., 7., 8.]])\n#> tensor([4., 5., 8.])"},{"path":"tensors.html","id":"other-tensor-operations","chapter":"5 Tensors","heading":"5.10 Other tensor operations","text":"","code":""},{"path":"tensors.html","id":"cross-product","chapter":"5 Tensors","heading":"5.10.1 Cross product","text":"","code":"\nm1 = torch$ones(3L, 5L)\nm2 = torch$ones(3L, 5L)\nv1 = torch$ones(3L)\n# Cross product\n# Size 3x5\n(r = torch$cross(m1, m2))#> tensor([[0., 0., 0., 0., 0.],\n#>         [0., 0., 0., 0., 0.],\n#>         [0., 0., 0., 0., 0.]])"},{"path":"tensors.html","id":"dot-product","chapter":"5 Tensors","heading":"5.10.2 Dot product","text":"","code":"\n# Dot product of 2 tensors\n# Dot product of 2 tensors\n\np <- torch$Tensor(list(4L, 2L))\nq <- torch$Tensor(list(3L, 1L))                   \n\n(r = torch$dot(p, q))  # 14\n#> tensor(14.)\n(r <- p %.*% q)        # 14\n#> tensor(14.)"},{"path":"tensors.html","id":"logical-operations","chapter":"5 Tensors","heading":"5.11 Logical operations","text":"","code":"\nm0 = torch$zeros(3L, 5L)\nm1 = torch$ones(3L, 5L)\nm2 = torch$eye(3L, 5L)\n\nprint(m1 == m0)\n#> tensor([[False, False, False, False, False],\n#>         [False, False, False, False, False],\n#>         [False, False, False, False, False]])\nprint(m1 != m1)\n#> tensor([[False, False, False, False, False],\n#>         [False, False, False, False, False],\n#>         [False, False, False, False, False]])\nprint(m2 == m2)\n#> tensor([[True, True, True, True, True],\n#>         [True, True, True, True, True],\n#>         [True, True, True, True, True]])\n# AND\nm1 & m1\n#> tensor([[1, 1, 1, 1, 1],\n#>         [1, 1, 1, 1, 1],\n#>         [1, 1, 1, 1, 1]], dtype=torch.uint8)\n# OR\nm0 | m2\n#> tensor([[1, 0, 0, 0, 0],\n#>         [0, 1, 0, 0, 0],\n#>         [0, 0, 1, 0, 0]], dtype=torch.uint8)\n# OR\nm1 | m2\n#> tensor([[1, 1, 1, 1, 1],\n#>         [1, 1, 1, 1, 1],\n#>         [1, 1, 1, 1, 1]], dtype=torch.uint8)"},{"path":"tensors.html","id":"extract-a-unique-logical-result","chapter":"5 Tensors","heading":"5.11.1 Extract a unique logical result","text":":function all_boolean:","code":"\n# tensor is less than\nA <- torch$ones(60000L, 1L, 28L, 28L)\nC <- A * 0.5\n\n# is C < A\nall(torch$lt(C, A))\n#> tensor(1, dtype=torch.uint8)\nall(C < A)\n#> tensor(1, dtype=torch.uint8)\n# is A < C\nall(A < C)\n#> tensor(0, dtype=torch.uint8)\nall_boolean <- function(x) {\n  # convert tensor of 1s and 0s to a unique boolean\n  as.logical(torch$all(x)$numpy())\n}\n\n# is C < A\nall_boolean(torch$lt(C, A))\n#> [1] TRUE\nall_boolean(C < A)\n#> [1] TRUE\n\n# is A < C\nall_boolean(A < C)\n#> [1] FALSE"},{"path":"tensors.html","id":"greater-than-gt","chapter":"5 Tensors","heading":"5.11.2 Greater than (gt)","text":"","code":"\n# tensor is greater than\nA <- torch$ones(60000L, 1L, 28L, 28L)\nD <- A * 2.0\nall(torch$gt(D, A))\n#> tensor(1, dtype=torch.uint8)\nall(torch$gt(A, D))\n#> tensor(0, dtype=torch.uint8)"},{"path":"tensors.html","id":"less-than-or-equal-le","chapter":"5 Tensors","heading":"5.11.3 Less than or equal (le)","text":"","code":"\n# tensor is less than or equal\nA1 <- torch$ones(60000L, 1L, 28L, 28L)\nall(torch$le(A1, A1))\n#> tensor(1, dtype=torch.uint8)\nall(A1 <= A1)\n#> tensor(1, dtype=torch.uint8)\n\n# tensor is greater than or equal\nA0 <- torch$zeros(60000L, 1L, 28L, 28L)\nall(torch$ge(A0, A0))\n#> tensor(1, dtype=torch.uint8)\nall(A0 >= A0)\n#> tensor(1, dtype=torch.uint8)\n\nall(A1 >= A0)\n#> tensor(1, dtype=torch.uint8)\nall(A1 <= A0)\n#> tensor(0, dtype=torch.uint8)"},{"path":"tensors.html","id":"logical-not","chapter":"5 Tensors","heading":"5.11.4 Logical NOT (!)","text":"","code":"\nall_true <- torch$BoolTensor(list(TRUE, TRUE, TRUE, TRUE))\nall_true\n#> tensor([True, True, True, True])\n\n# logical NOT\nnot_all_true <- !all_true\nnot_all_true\n#> tensor([False, False, False, False])\ndiag <- torch$eye(5L)\ndiag\n#> tensor([[1., 0., 0., 0., 0.],\n#>         [0., 1., 0., 0., 0.],\n#>         [0., 0., 1., 0., 0.],\n#>         [0., 0., 0., 1., 0.],\n#>         [0., 0., 0., 0., 1.]])\n\n# logical NOT\nnot_diag <- !diag\n\n# convert to integer\nnot_diag$to(dtype=torch$uint8)\n#> tensor([[0, 1, 1, 1, 1],\n#>         [1, 0, 1, 1, 1],\n#>         [1, 1, 0, 1, 1],\n#>         [1, 1, 1, 0, 1],\n#>         [1, 1, 1, 1, 0]], dtype=torch.uint8)"},{"path":"tensors.html","id":"distributions","chapter":"5 Tensors","heading":"5.12 Distributions","text":"Initialize tensor randomized normal distribution mean=0, var=1:","code":"\nn <- torch$randn(3500L)\nn\n#> tensor([ 0.1694,  0.5110, -0.6642,  ...,  1.0746,  0.5686,  0.5774])\nplot(n$numpy())\nhist(n$numpy())\na  <- torch$randn(8L, 5L, 6L)\n# print(a)\nprint(a$size())\n#> torch.Size([8, 5, 6])\n\nplot(a$flatten()$numpy())\nhist(a$flatten()$numpy())"},{"path":"tensors.html","id":"uniform-matrix","chapter":"5 Tensors","heading":"5.12.1 Uniform matrix","text":"","code":"\nlibrary(rTorch)\n\n# 3x5 matrix uniformly distributed between 0 and 1\nmat0 <- torch$FloatTensor(13L, 15L)$uniform_(0L, 1L)\nplot(mat0$flatten()$numpy())\nhist(mat0$flatten()$numpy())\n# fill a 3x5 matrix with 0.1\nmat1 <- torch$FloatTensor(30L, 50L)$uniform_(0.1, 0.2)\nplot(mat1$flatten()$numpy())\nhist(mat1$flatten()$numpy())\n# a vector with all ones\nmat2 <- torch$FloatTensor(500L)$uniform_(1, 2)\nplot(mat2$flatten()$numpy())\nhist(mat2$flatten()$numpy())"},{"path":"tensors.html","id":"binomial-distribution","chapter":"5 Tensors","heading":"5.12.2 Binomial distribution","text":"","code":"\nBinomial <- torch$distributions$binomial$Binomial\n\nm = Binomial(100, torch$tensor(list(0 , .2, .8, 1)))\n(x = m$sample())\n#> tensor([  0.,  20.,  83., 100.])\nm = Binomial(torch$tensor(list(list(5.), list(10.))), \n             torch$tensor(list(0.5, 0.8)))\n(x = m$sample())\n#> tensor([[2., 5.],\n#>         [3., 8.]])\nbinom <- Binomial(100, torch$FloatTensor(5L, 10L))\nprint(binom)\n#> Binomial(total_count: torch.Size([5, 10]), probs: torch.Size([5, 10]), logits: torch.Size([5, 10]))\nprint(binom$sample_n(100L)$shape)\n#> torch.Size([100, 5, 10])\nplot(binom$sample_n(100L)$flatten()$numpy())\nhist(binom$sample_n(100L)$flatten()$numpy())"},{"path":"tensors.html","id":"exponential-distribution","chapter":"5 Tensors","heading":"5.12.3 Exponential distribution","text":"","code":"\nExponential <- torch$distributions$exponential$Exponential\n\nm = Exponential(torch$tensor(list(1.0)))\nm\n#> Exponential(rate: tensor([1.]))\nm$sample()  # Exponential distributed with rate=1\n#> tensor([0.5603])\nexpo <- Exponential(rate=0.25)\nexpo_sample <- expo$sample_n(250L)   # generate 250 samples\nprint(expo_sample$shape)\n#> torch.Size([250])\nplot(expo_sample$flatten()$numpy())\nhist(expo_sample$flatten()$numpy())"},{"path":"tensors.html","id":"weibull-distribution","chapter":"5 Tensors","heading":"5.12.4 Weibull distribution","text":"","code":"\nWeibull <- torch$distributions$weibull$Weibull\n\nm = Weibull(torch$tensor(list(1.0)), torch$tensor(list(1.0)))\nm$sample()  # sample from a Weibull distribution with scale=1, concentration=1\n#> tensor([0.5130])"},{"path":"tensors.html","id":"constant-scale","chapter":"5 Tensors","heading":"5.12.4.1 Constant scale","text":"","code":"\n# constant scale\nfor (k in 1:10) {\n    wei <- Weibull(scale=100, concentration=k)\n    wei_sample <- wei$sample_n(500L)\n    # plot(wei_sample$flatten()$numpy())\n    hist(main=paste0(\"Scale=100; Concentration=\", k),\n        wei_sample$flatten()$numpy())\n}"},{"path":"tensors.html","id":"constant-concentration","chapter":"5 Tensors","heading":"5.12.4.2 Constant concentration","text":"","code":"\n# constant concentration\nfor (s in seq(100, 1000, 100)) {\n    wei <- Weibull(scale=s, concentration=1)\n    wei_sample <- wei$sample_n(500L)\n    # plot(wei_sample$flatten()$numpy())\n    hist(main=paste0(\"Concentration=1; Scale=\", s),\n        wei_sample$flatten()$numpy())\n}"},{"path":"linearalgebra.html","id":"linearalgebra","chapter":"6 Linear Algebra with Torch","heading":"6 Linear Algebra with Torch","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)following basic operations Linear Algebra using PyTorch.","code":"\nlibrary(rTorch)"},{"path":"linearalgebra.html","id":"scalars","chapter":"6 Linear Algebra with Torch","heading":"6.1 Scalars","text":"","code":"\ntorch$scalar_tensor(2.78654)\n\ntorch$scalar_tensor(0L)\n\ntorch$scalar_tensor(1L)\n\ntorch$scalar_tensor(TRUE)\n\ntorch$scalar_tensor(FALSE)#> tensor(2.7865)\n#> tensor(0.)\n#> tensor(1.)\n#> tensor(1.)\n#> tensor(0.)"},{"path":"linearalgebra.html","id":"vectors","chapter":"6 Linear Algebra with Torch","heading":"6.2 Vectors","text":"","code":"\nv <- c(0, 1, 2, 3, 4, 5)\ntorch$as_tensor(v)#> tensor([0., 1., 2., 3., 4., 5.])"},{"path":"linearalgebra.html","id":"vector-to-matrix","chapter":"6 Linear Algebra with Torch","heading":"6.2.1 Vector to matrix","text":"","code":"\n# row-vector\nmessage(\"R matrix\")#> R matrix\n(mr <- matrix(1:10, nrow=1))\nmessage(\"as_tensor\")#> as_tensor\ntorch$as_tensor(mr)\nmessage(\"shape_of_tensor\")#> shape_of_tensor\ntorch$as_tensor(mr)$shape#>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#> [1,]    1    2    3    4    5    6    7    8    9    10\n#> tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]], dtype=torch.int32)\n#> torch.Size([1, 10])"},{"path":"linearalgebra.html","id":"matrix-to-tensor","chapter":"6 Linear Algebra with Torch","heading":"6.2.2 Matrix to tensor","text":"","code":"\n# column-vector\nmessage(\"R matrix, one column\")#> R matrix, one column\n(mc <- matrix(1:10, ncol=1))\nmessage(\"as_tensor\")#> as_tensor\ntorch$as_tensor(mc)\nmessage(\"size of tensor\")#> size of tensor\ntorch$as_tensor(mc)$shape#>       [,1]\n#>  [1,]    1\n#>  [2,]    2\n#>  [3,]    3\n#>  [4,]    4\n#>  [5,]    5\n#>  [6,]    6\n#>  [7,]    7\n#>  [8,]    8\n#>  [9,]    9\n#> [10,]   10\n#> tensor([[ 1],\n#>         [ 2],\n#>         [ 3],\n#>         [ 4],\n#>         [ 5],\n#>         [ 6],\n#>         [ 7],\n#>         [ 8],\n#>         [ 9],\n#>         [10]], dtype=torch.int32)\n#> torch.Size([10, 1])"},{"path":"linearalgebra.html","id":"matrices","chapter":"6 Linear Algebra with Torch","heading":"6.3 Matrices","text":"","code":"\nmessage(\"R matrix\")#> R matrix\n(m1 <- matrix(1:24, nrow = 3, byrow = TRUE))\nmessage(\"as_tensor\")#> as_tensor\n(t1 <- torch$as_tensor(m1))\nmessage(\"shape\")#> shape\ntorch$as_tensor(m1)$shape\nmessage(\"size\")#> size\ntorch$as_tensor(m1)$size()\nmessage(\"dim\")#> dim\ndim(torch$as_tensor(m1))\nmessage(\"length\")#> length\nlength(torch$as_tensor(m1))#>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n#> [1,]    1    2    3    4    5    6    7    8\n#> [2,]    9   10   11   12   13   14   15   16\n#> [3,]   17   18   19   20   21   22   23   24\n#> tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n#>         [ 9, 10, 11, 12, 13, 14, 15, 16],\n#>         [17, 18, 19, 20, 21, 22, 23, 24]], dtype=torch.int32)\n#> torch.Size([3, 8])\n#> torch.Size([3, 8])\n#> [1] 3 8\n#> [1] 24\nmessage(\"R matrix\")#> R matrix\n(m2 <- matrix(0:99, ncol = 10))\nmessage(\"as_tensor\")#> as_tensor\n(t2 <- torch$as_tensor(m2))\nmessage(\"shape\")#> shape\nt2$shape\nmessage(\"dim\")#> dim\ndim(torch$as_tensor(m2))#>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#>  [1,]    0   10   20   30   40   50   60   70   80    90\n#>  [2,]    1   11   21   31   41   51   61   71   81    91\n#>  [3,]    2   12   22   32   42   52   62   72   82    92\n#>  [4,]    3   13   23   33   43   53   63   73   83    93\n#>  [5,]    4   14   24   34   44   54   64   74   84    94\n#>  [6,]    5   15   25   35   45   55   65   75   85    95\n#>  [7,]    6   16   26   36   46   56   66   76   86    96\n#>  [8,]    7   17   27   37   47   57   67   77   87    97\n#>  [9,]    8   18   28   38   48   58   68   78   88    98\n#> [10,]    9   19   29   39   49   59   69   79   89    99\n#> tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n#>         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n#>         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],\n#>         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],\n#>         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],\n#>         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],\n#>         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],\n#>         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],\n#>         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],\n#>         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)\n#> torch.Size([10, 10])\n#> [1] 10 10\nm1[1, 1]\nm2[1, 1]#> [1] 1\n#> [1] 0\nt1[1, 1]\nt2[1, 1]#> tensor(1, dtype=torch.int32)\n#> tensor(0, dtype=torch.int32)"},{"path":"linearalgebra.html","id":"d-tensors","chapter":"6 Linear Algebra with Torch","heading":"6.4 3D+ tensors","text":"","code":"\n# RGB color image has three axes \n(img <- torch$rand(3L, 28L, 28L))\nimg$shape#> tensor([[[0.6341, 0.5920, 0.6003,  ..., 0.9758, 0.2164, 0.6316],\n#>          [0.8920, 0.0740, 0.1266,  ..., 0.3907, 0.5435, 0.3925],\n#>          [0.0695, 0.8386, 0.1557,  ..., 0.6110, 0.5068, 0.1111],\n#>          ...,\n#>          [0.1582, 0.3610, 0.8429,  ..., 0.1779, 0.1330, 0.9461],\n#>          [0.0939, 0.7597, 0.9472,  ..., 0.9175, 0.9918, 0.9697],\n#>          [0.0577, 0.4356, 0.2992,  ..., 0.8638, 0.8456, 0.3352]],\n#> \n#>         [[0.7245, 0.0744, 0.1111,  ..., 0.8855, 0.9211, 0.6035],\n#>          [0.7404, 0.7883, 0.8771,  ..., 0.4846, 0.4590, 0.6854],\n#>          [0.8251, 0.3678, 0.4783,  ..., 0.5484, 0.9145, 0.1276],\n#>          ...,\n#>          [0.2297, 0.4909, 0.7920,  ..., 0.1959, 0.3530, 0.2758],\n#>          [0.1391, 0.1094, 0.2221,  ..., 0.4741, 0.2116, 0.5700],\n#>          [0.0783, 0.7481, 0.0070,  ..., 0.3016, 0.6118, 0.8827]],\n#> \n#>         [[0.3405, 0.4951, 0.7876,  ..., 0.7430, 0.1276, 0.9603],\n#>          [0.0443, 0.2199, 0.8553,  ..., 0.4035, 0.6884, 0.2706],\n#>          [0.7959, 0.4825, 0.2325,  ..., 0.0549, 0.1653, 0.5574],\n#>          ...,\n#>          [0.9410, 0.7691, 0.7558,  ..., 0.7513, 0.3087, 0.8388],\n#>          [0.0214, 0.8669, 0.6679,  ..., 0.0397, 0.4893, 0.3146],\n#>          [0.7291, 0.0037, 0.8167,  ..., 0.0461, 0.8514, 0.3013]]])\n#> torch.Size([3, 28, 28])\nimg[1, 1, 1]\nimg[3, 28, 28]#> tensor(0.6341)\n#> tensor(0.3013)"},{"path":"linearalgebra.html","id":"transpose-of-a-matrix","chapter":"6 Linear Algebra with Torch","heading":"6.5 Transpose of a matrix","text":"","code":"\n(m3 <- matrix(1:25, ncol = 5))\n\n# transpose\nmessage(\"transpose\")#> transpose\ntm3 <- t(m3)\ntm3#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    6   11   16   21\n#> [2,]    2    7   12   17   22\n#> [3,]    3    8   13   18   23\n#> [4,]    4    9   14   19   24\n#> [5,]    5   10   15   20   25\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    2    3    4    5\n#> [2,]    6    7    8    9   10\n#> [3,]   11   12   13   14   15\n#> [4,]   16   17   18   19   20\n#> [5,]   21   22   23   24   25\nmessage(\"as_tensor\")#> as_tensor\n(t3 <- torch$as_tensor(m3))\nmessage(\"transpose\")#> transpose\ntt3 <- t3$transpose(dim0 = 0L, dim1 = 1L)\ntt3#> tensor([[ 1,  6, 11, 16, 21],\n#>         [ 2,  7, 12, 17, 22],\n#>         [ 3,  8, 13, 18, 23],\n#>         [ 4,  9, 14, 19, 24],\n#>         [ 5, 10, 15, 20, 25]], dtype=torch.int32)\n#> tensor([[ 1,  2,  3,  4,  5],\n#>         [ 6,  7,  8,  9, 10],\n#>         [11, 12, 13, 14, 15],\n#>         [16, 17, 18, 19, 20],\n#>         [21, 22, 23, 24, 25]], dtype=torch.int32)\ntm3 == tt3$numpy()   # convert first the tensor to numpy#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,] TRUE TRUE TRUE TRUE TRUE\n#> [2,] TRUE TRUE TRUE TRUE TRUE\n#> [3,] TRUE TRUE TRUE TRUE TRUE\n#> [4,] TRUE TRUE TRUE TRUE TRUE\n#> [5,] TRUE TRUE TRUE TRUE TRUE"},{"path":"linearalgebra.html","id":"vectors-special-case-of-a-matrix","chapter":"6 Linear Algebra with Torch","heading":"6.6 Vectors, special case of a matrix","text":"vectors, vector transpose equal.","code":"\nmessage(\"R matrix\")#> R matrix\nm2 <- matrix(0:99, ncol = 10)\nmessage(\"as_tensor\")#> as_tensor\n(t2 <- torch$as_tensor(m2))\n\n# in R\nmessage(\"select column of matrix\")#> select column of matrix\n(v1 <- m2[, 1])\nmessage(\"select row of matrix\")#> select row of matrix\n(v2 <- m2[10, ])#> tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n#>         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n#>         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],\n#>         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],\n#>         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],\n#>         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],\n#>         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],\n#>         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],\n#>         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],\n#>         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)\n#>  [1] 0 1 2 3 4 5 6 7 8 9\n#>  [1]  9 19 29 39 49 59 69 79 89 99\n# PyTorch\nmessage()#> \nt2c <- t2[, 1]\nt2r <- t2[10, ]\n\nt2c\nt2r#> tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)\n#> tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)\ntt2r <- t2r$transpose(dim0 = 0L, dim1 = 0L)\ntt2r#> tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)\n# a tensor of booleans. is vector equal to its transposed?\nt2r == tt2r#> tensor([True, True, True, True, True, True, True, True, True, True])"},{"path":"linearalgebra.html","id":"tensor-arithmetic","chapter":"6 Linear Algebra with Torch","heading":"6.7 Tensor arithmetic","text":"\\[+ B = B + \\]","code":"\nmessage(\"x\")#> x\n(x = torch$ones(5L, 4L))\nmessage(\"y\")#> y\n(y = torch$ones(5L, 4L))\nmessage(\"x+y\")#> x+y\nx + y#> tensor([[1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.]])\n#> tensor([[1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.]])\n#> tensor([[2., 2., 2., 2.],\n#>         [2., 2., 2., 2.],\n#>         [2., 2., 2., 2.],\n#>         [2., 2., 2., 2.],\n#>         [2., 2., 2., 2.]])\nx + y == y + x#> tensor([[True, True, True, True],\n#>         [True, True, True, True],\n#>         [True, True, True, True],\n#>         [True, True, True, True],\n#>         [True, True, True, True]])"},{"path":"linearalgebra.html","id":"add-a-scalar-to-a-tensor","chapter":"6 Linear Algebra with Torch","heading":"6.8 Add a scalar to a tensor","text":"","code":"\ns <- 0.5    # scalar\nx + s#> tensor([[1.5000, 1.5000, 1.5000, 1.5000],\n#>         [1.5000, 1.5000, 1.5000, 1.5000],\n#>         [1.5000, 1.5000, 1.5000, 1.5000],\n#>         [1.5000, 1.5000, 1.5000, 1.5000],\n#>         [1.5000, 1.5000, 1.5000, 1.5000]])\n# scalar multiplying two tensors\ns * (x + y)#> tensor([[1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.]])"},{"path":"linearalgebra.html","id":"multiplying-tensors","chapter":"6 Linear Algebra with Torch","heading":"6.9 Multiplying tensors","text":"\\[* B = B * \\]","code":"\nmessage(\"x\")#> x\n(x = torch$ones(5L, 4L))\nmessage(\"y\")#> y\n(y = torch$ones(5L, 4L))\nmessage(\"2x+4y\")#> 2x+4y\n(z = 2 * x + 4 * y)#> tensor([[1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.]])\n#> tensor([[1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.],\n#>         [1., 1., 1., 1.]])\n#> tensor([[6., 6., 6., 6.],\n#>         [6., 6., 6., 6.],\n#>         [6., 6., 6., 6.],\n#>         [6., 6., 6., 6.],\n#>         [6., 6., 6., 6.]])\nx * y == y * x#> tensor([[True, True, True, True],\n#>         [True, True, True, True],\n#>         [True, True, True, True],\n#>         [True, True, True, True],\n#>         [True, True, True, True]])"},{"path":"linearalgebra.html","id":"dot-product-1","chapter":"6 Linear Algebra with Torch","heading":"6.10 Dot product","text":"\\[dot(,b)_{,j,k,,b,c} = \\sum_m a_{,j,k,m}b_{,b,m,c}\\]","code":"\ntorch$dot(torch$tensor(c(2, 3)), torch$tensor(c(2, 1)))#> tensor(7.)"},{"path":"linearalgebra.html","id":"d-array-using-python","chapter":"6 Linear Algebra with Torch","heading":"6.10.1 2D array using Python","text":"","code":"import numpy as np\n\na = np.array([[1, 2], [3, 4]])\nb = np.array([[1, 2], [3, 4]])\nprint(a)#> [[1 2]\n#>  [3 4]]print(b)#> [[1 2]\n#>  [3 4]]np.dot(a, b)#> array([[ 7, 10],\n#>        [15, 22]])"},{"path":"linearalgebra.html","id":"d-array-using-r","chapter":"6 Linear Algebra with Torch","heading":"6.10.2 2D array using R","text":"torch.dot() treats \\(\\) \\(b\\) 1D vectors (irrespective original shape) computes inner product.perform dot product operation Python, get error:","code":"\na <- np$array(list(list(1, 2), list(3, 4)))\na\nb <- np$array(list(list(1, 2), list(3, 4)))\nb\n\nnp$dot(a, b)#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#>      [,1] [,2]\n#> [1,]    7   10\n#> [2,]   15   22\nat <- torch$as_tensor(a)\nbt <- torch$as_tensor(b)\n\n# torch$dot(at, bt)  <- RuntimeError: dot: Expected 1-D argument self, but got 2-D\n# at %.*% btimport torch\nimport numpy as np\n\na = np.array([[1, 2], [3, 4]])\na#> array([[1, 2],\n#>        [3, 4]])b = np.array([[1, 2], [3, 4]])\nb#> array([[1, 2],\n#>        [3, 4]])np.dot(a, b)#> array([[ 7, 10],\n#>        [15, 22]])at = torch.as_tensor(a)\nbt = torch.as_tensor(b)\n\nat#> tensor([[1, 2],\n#>         [3, 4]])bt#> tensor([[1, 2],\n#>         [3, 4]])torch.dot(at, bt)#> Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83\n#> \n#> Detailed traceback: \n#>   File \"<string>\", line 1, in <module>\na <- torch$Tensor(list(list(1, 2), list(3, 4)))\nb <- torch$Tensor(c(c(1, 2), c(3, 4)))\nc <- torch$Tensor(list(list(11, 12), list(13, 14)))\n\na\nb\ntorch$dot(a, b)#> Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 1D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83\n# this is another way of performing dot product in PyTorch\n# a$dot(a)#> tensor([[1., 2.],\n#>         [3., 4.]])\n#> tensor([1., 2., 3., 4.])\no1 <- torch$ones(2L, 2L)\no2 <- torch$ones(2L, 2L)\n\no1\no2\n\ntorch$dot(o1, o2)#> Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83\no1$dot(o2)#> Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83#> tensor([[1., 1.],\n#>         [1., 1.]])\n#> tensor([[1., 1.],\n#>         [1., 1.]])\n# 1D tensors work fine\nr = torch$dot(torch$Tensor(list(4L, 2L, 4L)), torch$Tensor(list(3L, 4L, 1L)))\nr#> tensor(24.)"},{"path":"linearalgebra.html","id":"mm-and-matmul-functions","chapter":"6 Linear Algebra with Torch","heading":"6.10.3 mm and matmul functions","text":", cannor perform 2D tensor operations dot product, manage ?good explanation: https://stackoverflow.com//44525687/5270873Let’s now prove associative property tensors:\\[(B)^T = B^T ^T\\]unit test results nearly allclose():","code":"\n## mm and matmul seem to address the dot product we are looking for in tensors\na = torch$randn(2L, 3L)\nb = torch$randn(3L, 4L)\n\na$mm(b)\na$matmul(b)#> tensor([[-0.1476,  2.8686, -2.3848, -1.0852],\n#>         [-1.3499,  6.5145, -0.1689, -1.4048]])\n#> tensor([[-0.1476,  2.8686, -2.3848, -1.0852],\n#>         [-1.3499,  6.5145, -0.1689, -1.4048]])\nabt <- torch$mm(a, b)$transpose(dim0=0L, dim1=1L)\nabt#> tensor([[-0.1476, -1.3499],\n#>         [ 2.8686,  6.5145],\n#>         [-2.3848, -0.1689],\n#>         [-1.0852, -1.4048]])\nat <- a$transpose(dim0=0L, dim1=1L)\nbt <- b$transpose(dim0=0L, dim1=1L)\n\nbtat <- torch$matmul(bt, at)\nbtat#> tensor([[-0.1476, -1.3499],\n#>         [ 2.8686,  6.5145],\n#>         [-2.3848, -0.1689],\n#>         [-1.0852, -1.4048]])\n# tolerance\ntorch$allclose(abt, btat, rtol=0.0001)#> [1] TRUE"},{"path":"creating-pytorch-classes.html","id":"creating-pytorch-classes","chapter":"7 Creating PyTorch classes","heading":"7 Creating PyTorch classes","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"creating-pytorch-classes.html","id":"build-a-pytorch-model-class","chapter":"7 Creating PyTorch classes","heading":"7.1 Build a PyTorch model class","text":"PyTorch classes directly instantiated R. Yet. need intermediate step create class. , use reticulate functions like py_run_string() read class implementation Python code, assign R object.","code":""},{"path":"creating-pytorch-classes.html","id":"example-1-one-layer-nn","chapter":"7 Creating PyTorch classes","heading":"7.1.1 Example 1: One layer NN","text":"R object net now contains object PyTorch class Net.","code":"\npy_run_string(\"import torch\")\nmain = py_run_string(\n\"\nimport torch.nn as nn\n\nclass Net(nn.Module):\n   def __init__(self):\n       super(Net, self).__init__()\n       self.layer = torch.nn.Linear(1, 1)\n\n   def forward(self, x):\n       x = self.layer(x)      \n       return x\n\")\n\n\n# build a Linear Rgression model\nnet <- main$Net()"},{"path":"creating-pytorch-classes.html","id":"example-2-logistic-regression","chapter":"7 Creating PyTorch classes","heading":"7.1.2 Example 2: Logistic Regression","text":"R object LogisticRegressionModel now contains objects PyTorch class LogisticRegressionModel.","code":"\nmain <- py_run_string(\n\"\nimport torch.nn as nn\n\nclass LogisticRegressionModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LogisticRegressionModel, self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\")\n\n# build a Logistic Rgression model\nLogisticRegressionModel <- main$LogisticRegressionModel"},{"path":"example-1-a-classification-problem.html","id":"example-1-a-classification-problem","chapter":"8 Example 1: A classification problem","heading":"8 Example 1: A classification problem","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"example-1-a-classification-problem.html","id":"code-in-python","chapter":"8 Example 1: A classification problem","heading":"8.1 Code in Python","text":"combine R Python code just show easy integrating R Python. First thing loading package rTorch. chunk:, proceed copy standard Python code Python chunks. nice example found web. explains classic challenge classification.rTorch loaded, number Python libraries also loaded, enable us immediate use numpy, torch matplotlib.next thing setting seed make example repeatable, machine .generate random samples.plot original data reference.follows definition model using neural network train model. set model:Train model:Finally, plot results, tracing line separates two classes, 0 1, colored plot.","code":"\nlibrary(rTorch)# Logistic Regression\n# https://m-alcu.github.io/blog/2018/02/10/logit-pytorch/\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as pltnp.random.seed(2048)N = 100\nD = 2\nX = np.random.randn(N, D) * 2\nctr = int(N/2)\n# center the first N/2 points at (-2,-2)\nX[:ctr,:] = X[:ctr,:] - 2 * np.ones((ctr, D))\n# center the last N/2 points at (2, 2)\nX[ctr:,:] = X[ctr:,:] + 2 * np.ones((ctr, D))\n\n# labels: first N/2 are 0, last N/2 are 1\n# mark the first half with 0 and the sceond half with 1\nT = np.array([0] * ctr + [1] * ctr).reshape(100, 1)# plot the data. color the dots using T\nplt.scatter(X[:,0], X[:,1], c=T.reshape(N), s=100, alpha=0.5)\nplt.xlabel('X(1)')\nplt.ylabel('X(2)')class Model(torch.nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.linear = torch.nn.Linear(2, 1) # 2 in and 1 out\n        \n    def forward(self, x):\n        y_pred = torch.sigmoid(self.linear(x))\n        return y_pred\n    \n# Our model    \nmodel = Model()\n\ncriterion = torch.nn.BCELoss(reduction='mean')\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)x_data = Variable(torch.Tensor(X))\ny_data = Variable(torch.Tensor(T))\n\n# Training loop\nfor epoch in range(1000):\n    # Forward pass: Compute predicted y by passing x to the model\n    y_pred = model(x_data)\n    \n    # Compute and print loss\n    loss = criterion(y_pred, y_data)\n    # print(epoch, loss.data[0])\n    \n    # Zero gradients, perform a backward pass, and update the weights.\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \nw = list(model.parameters())\nw0 = w[0].data.numpy()\nw1 = w[1].data.numpy()    print(\"Final gradient descend:\", w)\n# plot the data and separating line#> Final gradient descend: [Parameter containing:\n#> tensor([[1.0802, 1.1165]], requires_grad=True), Parameter containing:\n#> tensor([0.0561], requires_grad=True)]plt.scatter(X[:,0], X[:,1], c=T.reshape(N), s=100, alpha=0.5)\nx_axis = np.linspace(-6, 6, 100)\ny_axis = -(w1[0] + x_axis * w0[0][0]) / w0[0][1]\nline_up, = plt.plot(x_axis, y_axis,'r--', label='gradient descent')\nplt.legend(handles=[line_up])\nplt.xlabel('X(1)')\nplt.ylabel('X(2)')\nplt.show()"},{"path":"mnistdigits.html","id":"mnistdigits","chapter":"9 Example 2: MNIST handwritten digits","heading":"9 Example 2: MNIST handwritten digits","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"mnistdigits.html","id":"code-in-r","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1 Code in R","text":"Source: https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/logistic_regression/main.py","code":"\nlibrary(rTorch)\n\nnn          <- torch$nn\ntransforms  <- torchvision$transforms\n\ntorch$set_default_dtype(torch$float)"},{"path":"mnistdigits.html","id":"hyperparameters","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1.1 Hyperparameters","text":"","code":"\n# Hyper-parameters \ninput_size    <- 784L\nnum_classes   <- 10L\nnum_epochs    <- 5L\nbatch_size    <- 100L\nlearning_rate <- 0.001"},{"path":"mnistdigits.html","id":"read-datasets","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1.2 Read datasets","text":"","code":"\n# MNIST dataset (images and labels)\n# IDX format\nlocal_folder <- './datasets/raw_data'\ntrain_dataset = torchvision$datasets$MNIST(root=local_folder, \n                                           train=TRUE, \n                                           transform=transforms$ToTensor(),\n                                           download=TRUE)\n\ntest_dataset = torchvision$datasets$MNIST(root=local_folder, \n                                          train=FALSE, \n                                          transform=transforms$ToTensor())\n\n# Data loader (input pipeline). Make the datasets iteratble\ntrain_loader = torch$utils$data$DataLoader(dataset=train_dataset, \n                                           batch_size=batch_size, \n                                           shuffle=TRUE)\n\ntest_loader = torch$utils$data$DataLoader(dataset=test_dataset, \n                                          batch_size=batch_size, \n                                          shuffle=FALSE)\nclass(train_loader)\nlength(train_loader)#> [1] \"torch.utils.data.dataloader.DataLoader\"\n#> [2] \"python.builtin.object\"                 \n#> [1] 2"},{"path":"mnistdigits.html","id":"define-the-model","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1.3 Define the model","text":"","code":"\n# Logistic regression model\nmodel = nn$Linear(input_size, num_classes)\n\n# Loss and optimizer\n# nn.CrossEntropyLoss() computes softmax internally\ncriterion = nn$CrossEntropyLoss()  \noptimizer = torch$optim$SGD(model$parameters(), lr=learning_rate)  \nprint(model)#> Linear(in_features=784, out_features=10, bias=True)"},{"path":"mnistdigits.html","id":"training","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1.4 Training","text":"","code":"\n# Train the model\niter_train_loader <- iterate(train_loader)\ntotal_step <-length(iter_train_loader)\nfor (epoch in 1:num_epochs) {\n    i <-  0\n    for (obj in iter_train_loader) {\n        \n        images <- obj[[1]]   # tensor torch.Size([64, 3, 28, 28])\n        labels <- obj[[2]]   # tensor torch.Size([64]), labels from 0 to 9\n        # cat(i, \"\\t\"); print(images$shape)\n\n        # Reshape images to (batch_size, input_size)\n        images <- images$reshape(-1L, 28L*28L)\n        # images <- torch$as_tensor(images$reshape(-1L, 28L*28L), dtype=torch$double)\n\n        # Forward pass\n        outputs <- model(images)\n        loss <- criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer$zero_grad()\n        loss$backward()\n        optimizer$step()\n\n        if ((i+1) %% 100 == 0) {\n            cat(sprintf('Epoch [%d/%d], Step [%d/%d], Loss: %f \\n',\n                epoch+1, num_epochs, i+1, total_step, loss$item()))\n        }\n        i <-  i + 1\n    }\n}  #> Epoch [2/5], Step [100/600], Loss: 2.196726 \n#> Epoch [2/5], Step [200/600], Loss: 2.135936 \n#> Epoch [2/5], Step [300/600], Loss: 1.990720 \n#> Epoch [2/5], Step [400/600], Loss: 1.922827 \n#> Epoch [2/5], Step [500/600], Loss: 1.848446 \n#> Epoch [2/5], Step [600/600], Loss: 1.757766 \n#> Epoch [3/5], Step [100/600], Loss: 1.724688 \n#> Epoch [3/5], Step [200/600], Loss: 1.701552 \n#> Epoch [3/5], Step [300/600], Loss: 1.610819 \n#> Epoch [3/5], Step [400/600], Loss: 1.544488 \n#> Epoch [3/5], Step [500/600], Loss: 1.509791 \n#> Epoch [3/5], Step [600/600], Loss: 1.436208 \n#> Epoch [4/5], Step [100/600], Loss: 1.428548 \n#> Epoch [4/5], Step [200/600], Loss: 1.424234 \n#> Epoch [4/5], Step [300/600], Loss: 1.366401 \n#> Epoch [4/5], Step [400/600], Loss: 1.297404 \n#> Epoch [4/5], Step [500/600], Loss: 1.289374 \n#> Epoch [4/5], Step [600/600], Loss: 1.227070 \n#> Epoch [5/5], Step [100/600], Loss: 1.229486 \n#> Epoch [5/5], Step [200/600], Loss: 1.239951 \n#> Epoch [5/5], Step [300/600], Loss: 1.203019 \n#> Epoch [5/5], Step [400/600], Loss: 1.130131 \n#> Epoch [5/5], Step [500/600], Loss: 1.139081 \n#> Epoch [5/5], Step [600/600], Loss: 1.084565 \n#> Epoch [6/5], Step [100/600], Loss: 1.089344 \n#> Epoch [6/5], Step [200/600], Loss: 1.111693 \n#> Epoch [6/5], Step [300/600], Loss: 1.088470 \n#> Epoch [6/5], Step [400/600], Loss: 1.011441 \n#> Epoch [6/5], Step [500/600], Loss: 1.031296 \n#> Epoch [6/5], Step [600/600], Loss: 0.982671"},{"path":"mnistdigits.html","id":"prediction","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1.5 Prediction","text":"","code":"\n# Adjust weights and reset gradients\niter_test_loader <- iterate(test_loader)\n\nwith(torch$no_grad(), {\n    correct <-  0\n    total <-  0\n    for (obj in iter_test_loader) {\n        images <- obj[[1]]   # tensor torch.Size([64, 3, 28, 28])\n        labels <- obj[[2]]   # tensor torch.Size([64]), labels from 0 to 9\n        images = images$reshape(-1L, 28L*28L)\n        # images <- torch$as_tensor(images$reshape(-1L, 28L*28L), dtype=torch$double)\n        outputs = model(images)\n        .predicted = torch$max(outputs$data, 1L)\n        predicted <- .predicted[1L]\n        total = total + labels$size(0L)\n        correct = correct + sum((predicted$numpy() == labels$numpy()))\n    }\n    cat(sprintf('Accuracy of the model on the 10000 test images: %f %%', (100 * correct / total)))\n  \n})#> Accuracy of the model on the 10000 test images: 82.930000 %"},{"path":"mnistdigits.html","id":"save-the-model","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.1.6 Save the model","text":"","code":"\n# Save the model checkpoint\ntorch$save(model$state_dict(), 'model.ckpt')"},{"path":"mnistdigits.html","id":"code-in-python-1","chapter":"9 Example 2: MNIST handwritten digits","heading":"9.2 Code in Python","text":"","code":"import torch\nimport torchvision\n\nimport torch.nn as nn\nimport torchvision.transforms as transforms\n\n\n# Hyper-parameters\ninput_size    = 784\nnum_classes   = 10\nnum_epochs    = 5\nbatch_size    = 100\nlearning_rate = 0.001\n\n\n# MNIST dataset (images and labels)\n# IDX format\nlocal_folder = './datasets/raw_data'\ntrain_dataset = torchvision.datasets.MNIST(root=local_folder,\n                                           train=True,\n                                           transform=transforms.ToTensor(),\n                                           download=True)\n\ntest_dataset = torchvision.datasets.MNIST(root=local_folder,\n                                          train=False,\n                                          transform=transforms.ToTensor())\n\n# Data loader (input pipeline). Make the datasets iteratble\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False)"},{"path":"linear-regression.html","id":"linear-regression","chapter":"10 Linear Regression","heading":"10 Linear Regression","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"linear-regression.html","id":"introduction","chapter":"10 Linear Regression","heading":"10.1 Introduction","text":"Source: https://www.guru99.com/pytorch-tutorial.html","code":"\nlibrary(rTorch)\n\nnn       <- torch$nn\nVariable <- torch$autograd$Variable\n\ninvisible(torch$manual_seed(123))"},{"path":"linear-regression.html","id":"generate-the-dataset","chapter":"10 Linear Regression","heading":"10.2 Generate the dataset","text":"start training process, need know data. make random function test model. \\(Y = x3 sin(x)+ 3x+0.8 rand(100)\\)","code":"\nnp$random$seed(123L)\n\nx = np$random$rand(100L)\ny = np$sin(x) * np$power(x, 3L) + 3L * x + np$random$rand(100L) * 0.8\n\nplot(x, y)"},{"path":"linear-regression.html","id":"convert-arrays-to-tensors","chapter":"10 Linear Regression","heading":"10.3 Convert arrays to tensors","text":"start training process, need convert numpy array Variables supported Torch autograd.","code":""},{"path":"linear-regression.html","id":"numpy-array-to-tensor-1","chapter":"10 Linear Regression","heading":"10.4 numpy array to tensor","text":"Notice converting Torch tensor, need first convert R numeric vector numpy array:","code":"\n# convert numpy array to tensor in shape of input size\nx <- r_to_py(x)\ny <- r_to_py(y)\nx = torch$from_numpy(x$reshape(-1L, 1L))$float()\ny = torch$from_numpy(y$reshape(-1L, 1L))$float()\nprint(x, y)#> tensor([[0.6965],\n#>         [0.2861],\n#>         [0.2269],\n#>         [0.5513],\n#>         [0.7195],\n#>         [0.4231],\n#>         [0.9808],\n#>         [0.6848],\n#>         [0.4809],\n#>         [0.3921],\n#>         [0.3432],\n#>         [0.7290],\n#>         [0.4386],\n#>         [0.0597],\n#>         [0.3980],\n#>         [0.7380],\n#>         [0.1825],\n#>         [0.1755],\n#>         [0.5316],\n#>         [0.5318],\n#>         [0.6344],\n#>         [0.8494],\n#>         [0.7245],\n#>         [0.6110],\n#>         [0.7224],\n#>         [0.3230],\n#>         [0.3618],\n#>         [0.2283],\n#>         [0.2937],\n#>         [0.6310],\n#>         [0.0921],\n#>         [0.4337],\n#>         [0.4309],\n#>         [0.4937],\n#>         [0.4258],\n#>         [0.3123],\n#>         [0.4264],\n#>         [0.8934],\n#>         [0.9442],\n#>         [0.5018],\n#>         [0.6240],\n#>         [0.1156],\n#>         [0.3173],\n#>         [0.4148],\n#>         [0.8663],\n#>         [0.2505],\n#>         [0.4830],\n#>         [0.9856],\n#>         [0.5195],\n#>         [0.6129],\n#>         [0.1206],\n#>         [0.8263],\n#>         [0.6031],\n#>         [0.5451],\n#>         [0.3428],\n#>         [0.3041],\n#>         [0.4170],\n#>         [0.6813],\n#>         [0.8755],\n#>         [0.5104],\n#>         [0.6693],\n#>         [0.5859],\n#>         [0.6249],\n#>         [0.6747],\n#>         [0.8423],\n#>         [0.0832],\n#>         [0.7637],\n#>         [0.2437],\n#>         [0.1942],\n#>         [0.5725],\n#>         [0.0957],\n#>         [0.8853],\n#>         [0.6272],\n#>         [0.7234],\n#>         [0.0161],\n#>         [0.5944],\n#>         [0.5568],\n#>         [0.1590],\n#>         [0.1531],\n#>         [0.6955],\n#>         [0.3188],\n#>         [0.6920],\n#>         [0.5544],\n#>         [0.3890],\n#>         [0.9251],\n#>         [0.8417],\n#>         [0.3574],\n#>         [0.0436],\n#>         [0.3048],\n#>         [0.3982],\n#>         [0.7050],\n#>         [0.9954],\n#>         [0.3559],\n#>         [0.7625],\n#>         [0.5932],\n#>         [0.6917],\n#>         [0.1511],\n#>         [0.3989],\n#>         [0.2409],\n#>         [0.3435]])"},{"path":"linear-regression.html","id":"creating-the-network-model","chapter":"10 Linear Regression","heading":"10.5 Creating the network model","text":"network model simple Linear layer input output shape one.network output like ","code":"Net(\n  (hidden): Linear(in_features=1, out_features=1, bias=True)\n)\npy_run_string(\"import torch\")\nmain = py_run_string(\n\"\nimport torch.nn as nn\n\nclass Net(nn.Module):\n   def __init__(self):\n       super(Net, self).__init__()\n       self.layer = torch.nn.Linear(1, 1)\n\n   def forward(self, x):\n       x = self.layer(x)      \n       return x\n\")\n\n\n# build a Linear Rgression model\nnet <- main$Net()\n\nprint(net)#> Net(\n#>   (layer): Linear(in_features=1, out_features=1, bias=True)\n#> )"},{"path":"linear-regression.html","id":"optimizer-and-loss","chapter":"10 Linear Regression","heading":"10.6 Optimizer and Loss","text":"Next, define Optimizer Loss Function training process.","code":"\n# Define Optimizer and Loss Function\noptimizer <- torch$optim$SGD(net$parameters(), lr=0.2)\nloss_func <- torch$nn$MSELoss()\nprint(optimizer)\nprint(loss_func)#> SGD (\n#> Parameter Group 0\n#>     dampening: 0\n#>     lr: 0.2\n#>     momentum: 0\n#>     nesterov: False\n#>     weight_decay: 0\n#> )\n#> MSELoss()"},{"path":"linear-regression.html","id":"training-1","chapter":"10 Linear Regression","heading":"10.7 Training","text":"Now let’s start training process. epoch 250, iterate data find best value hyperparameters.","code":"\n# x = x$type(torch$float)   # make it a a FloatTensor\n# y = y$type(torch$float)\n\n# x <- torch$as_tensor(x, dtype = torch$float)\n# y <- torch$as_tensor(y, dtype = torch$float)\n\ninputs  = Variable(x)\noutputs = Variable(y)\n\n# base plot\nplot(x$data$numpy(), y$data$numpy(), col = \"blue\")\nfor (i in 1:250) {\n   prediction = net(inputs)\n   loss = loss_func(prediction, outputs)\n   optimizer$zero_grad()\n   loss$backward()\n   optimizer$step()\n   \n   if (i > 1) break\n\n   if (i %% 10 == 0) {\n       # plot and show learning process\n      # points(x$data$numpy(), y$data$numpy())\n      points(x$data$numpy(), prediction$data$numpy(), col=\"red\")\n       # cat(i, loss$data$numpy(), \"\\n\")\n   }\n}"},{"path":"linear-regression.html","id":"results","chapter":"10 Linear Regression","heading":"10.8 Results","text":"can see, successfully performed regression neural network. Actually, every iteration, red line plot update change position fit data. picture, show final result.","code":""},{"path":"linear-regression-1.html","id":"linear-regression-1","chapter":"11 Linear Regression","heading":"11 Linear Regression","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"linear-regression-1.html","id":"rainfall-prediction","chapter":"11 Linear Regression","heading":"11.1 Rainfall prediction","text":"Select device: CPU GPU","code":"\nlibrary(rTorch)\ninvisible(torch$manual_seed(0))\ndevice = torch$device('cpu')"},{"path":"linear-regression-1.html","id":"training-data","chapter":"11 Linear Regression","heading":"11.2 Training data","text":"training data can represented using 2 matrices (inputs targets), one row per observation, one column per variable.","code":"\n# Input (temp, rainfall, humidity)\ninputs = np$array(list(list(73, 67, 43),\n                   list(91, 88, 64),\n                   list(87, 134, 58),\n                   list(102, 43, 37),\n                   list(69, 96, 70)), dtype='float32')\n\n# Targets (apples, oranges)\ntargets = np$array(list(list(56, 70), \n                    list(81, 101),\n                    list(119, 133),\n                    list(22, 37), \n                    list(103, 119)), dtype='float32')"},{"path":"linear-regression-1.html","id":"convert-arrays-to-tensors-1","chapter":"11 Linear Regression","heading":"11.3 Convert arrays to tensors","text":"build model, need convert inputs targets PyTorch tensors.weights biases can also represented matrices, initialized random values. first row \\(w\\) first element \\(b\\) used predict first target variable, .e. yield apples, , similarly, second oranges.","code":"\n# Convert inputs and targets to tensors\ninputs = torch$from_numpy(inputs)\ntargets = torch$from_numpy(targets)\n\nprint(inputs)\nprint(targets)#> tensor([[ 73.,  67.,  43.],\n#>         [ 91.,  88.,  64.],\n#>         [ 87., 134.,  58.],\n#>         [102.,  43.,  37.],\n#>         [ 69.,  96.,  70.]], dtype=torch.float64)\n#> tensor([[ 56.,  70.],\n#>         [ 81., 101.],\n#>         [119., 133.],\n#>         [ 22.,  37.],\n#>         [103., 119.]], dtype=torch.float64)\n# random numbers for weights and biases. Then convert to double()\ntorch$set_default_dtype(torch$double)\n\nw = torch$randn(2L, 3L, requires_grad=TRUE)  #$double()\nb = torch$randn(2L, requires_grad=TRUE)      #$double()\n\nprint(w)\nprint(b)#> tensor([[ 1.5410, -0.2934, -2.1788],\n#>         [ 0.5684, -1.0845, -1.3986]], requires_grad=True)\n#> tensor([0.4033, 0.8380], requires_grad=True)"},{"path":"linear-regression-1.html","id":"build-the-model","chapter":"11 Linear Regression","heading":"11.4 Build the model","text":"model simply function performs matrix multiplication input \\(x\\) weights \\(w\\) (transposed), adds bias \\(b\\) (replicated observation).","code":"\nmodel <- function(x) {\n  wt <- w$t()\n  return(torch$add(torch$mm(x, wt), b))\n}"},{"path":"linear-regression-1.html","id":"generate-predictions","chapter":"11 Linear Regression","heading":"11.5 Generate predictions","text":"matrix obtained passing input data model set predictions target variables.’ve started random weights biases, model good job predicting target variables.","code":"\n# Generate predictions\npreds = model(inputs)\nprint(preds)#> tensor([[  -0.4516,  -90.4691],\n#>         [ -24.6303, -132.3828],\n#>         [ -31.2192, -176.1530],\n#>         [  64.3523,  -39.5645],\n#>         [ -73.9524, -161.9560]], grad_fn=<AddBackward0>)\n# Compare with targets\nprint(targets)#> tensor([[ 56.,  70.],\n#>         [ 81., 101.],\n#>         [119., 133.],\n#>         [ 22.,  37.],\n#>         [103., 119.]])"},{"path":"linear-regression-1.html","id":"loss-function","chapter":"11 Linear Regression","heading":"11.6 Loss Function","text":"can compare predictions actual targets, using following method:Calculate difference two matrices (preds targets).Square elements difference matrix remove negative values.Calculate average elements resulting matrix.result single number, known mean squared error (MSE).","code":"\n# MSE loss\nmse = function(t1, t2) {\n  diff <- torch$sub(t1, t2)\n  mul <- torch$sum(torch$mul(diff, diff))\n  return(torch$div(mul, diff$numel()))\n}\nprint(mse)#> function(t1, t2) {\n#>   diff <- torch$sub(t1, t2)\n#>   mul <- torch$sum(torch$mul(diff, diff))\n#>   return(torch$div(mul, diff$numel()))\n#> }"},{"path":"linear-regression-1.html","id":"step-by-step-process","chapter":"11 Linear Regression","heading":"11.7 Step by step process","text":"","code":""},{"path":"linear-regression-1.html","id":"compute-the-losses","chapter":"11 Linear Regression","heading":"11.7.1 Compute the losses","text":"resulting number called loss, indicates bad model predicting target variables. Lower loss, better model.","code":"\n# Compute loss\nloss = mse(preds, targets)\nprint(loss)\n# 46194\n# 33060.8070#> tensor(33060.8053, grad_fn=<DivBackward0>)"},{"path":"linear-regression-1.html","id":"compute-gradients","chapter":"11 Linear Regression","heading":"11.7.2 Compute Gradients","text":"PyTorch, can automatically compute gradient derivative loss w.r.t. weights biases, requires_grad set True.gradients stored .grad property respective tensors.key insight calculus gradient indicates rate change loss, slope loss function w.r.t. weights biases.gradient element positive:\nincreasing element’s value slightly increase loss.\ndecreasing element’s value slightly decrease loss.\nincreasing element’s value slightly increase loss.decreasing element’s value slightly decrease loss.gradient element negative,\nincreasing element’s value slightly decrease loss.\ndecreasing element’s value slightly increase loss.\nincreasing element’s value slightly decrease loss.decreasing element’s value slightly increase loss.increase decrease proportional value gradient.","code":"\n# Compute gradients\nloss$backward()\n# Gradients for weights\nprint(w)\nprint(w$grad)#> tensor([[ 1.5410, -0.2934, -2.1788],\n#>         [ 0.5684, -1.0845, -1.3986]], requires_grad=True)\n#> tensor([[ -6938.4351,  -9674.6757,  -5744.0206],\n#>         [-17408.7861, -20595.9333, -12453.4702]])\n# Gradients for bias\nprint(b)\nprint(b$grad)#> tensor([0.4033, 0.8380], requires_grad=True)\n#> tensor([ -89.3802, -212.1051])"},{"path":"linear-regression-1.html","id":"reset-the-gradients","chapter":"11 Linear Regression","heading":"11.7.3 Reset the gradients","text":"Finally, ’ll reset gradients zero moving forward, PyTorch accumulates gradients.","code":"\n# Reset the gradients\nw$grad$zero_()\nb$grad$zero_()\n\nprint(w$grad)\nprint(b$grad)#> tensor([[0., 0., 0.],\n#>         [0., 0., 0.]])\n#> tensor([0., 0.])\n#> tensor([[0., 0., 0.],\n#>         [0., 0., 0.]])\n#> tensor([0., 0.])"},{"path":"linear-regression-1.html","id":"adjust-weights-and-biases","chapter":"11 Linear Regression","heading":"11.7.3.1 Adjust weights and biases","text":"’ll reduce loss improve model using gradient descent algorithm, following steps:Generate predictionsCalculate lossCompute gradients w.r.t weights biasesAdjust weights subtracting small quantity proportional gradientReset gradients zeroWith new weights biases, model lower loss.","code":"\n# Generate predictions\npreds = model(inputs)\nprint(preds)#> tensor([[  -0.4516,  -90.4691],\n#>         [ -24.6303, -132.3828],\n#>         [ -31.2192, -176.1530],\n#>         [  64.3523,  -39.5645],\n#>         [ -73.9524, -161.9560]], grad_fn=<AddBackward0>)\n# Calculate the loss\nloss = mse(preds, targets)\nprint(loss)#> tensor(33060.8053, grad_fn=<DivBackward0>)\n# Compute gradients\nloss$backward()\n\nprint(w$grad)\nprint(b$grad)#> tensor([[ -6938.4351,  -9674.6757,  -5744.0206],\n#>         [-17408.7861, -20595.9333, -12453.4702]])\n#> tensor([ -89.3802, -212.1051])\n# Adjust weights and reset gradients\nwith(torch$no_grad(), {\n  print(w); print(b)    # requires_grad attribute remains\n  w$data <- torch$sub(w$data, torch$mul(w$grad$data, torch$scalar_tensor(1e-5)))\n  b$data <- torch$sub(b$data, torch$mul(b$grad$data, torch$scalar_tensor(1e-5)))\n\n  print(w$grad$data$zero_())\n  print(b$grad$data$zero_())\n})\n\nprint(w)\nprint(b)#> tensor([[ 1.5410, -0.2934, -2.1788],\n#>         [ 0.5684, -1.0845, -1.3986]], requires_grad=True)\n#> tensor([0.4033, 0.8380], requires_grad=True)\n#> tensor([[0., 0., 0.],\n#>         [0., 0., 0.]])\n#> tensor([0., 0.])\n#> tensor([[ 1.6104, -0.1967, -2.1213],\n#>         [ 0.7425, -0.8786, -1.2741]], requires_grad=True)\n#> tensor([0.4042, 0.8401], requires_grad=True)\n# Calculate loss\npreds = model(inputs)\nloss = mse(preds, targets)\nprint(loss)#> tensor(23432.4894, grad_fn=<DivBackward0>)"},{"path":"linear-regression-1.html","id":"all-together","chapter":"11 Linear Regression","heading":"11.8 All together","text":"###T Training multiple epochs\nreduce loss , repeat process adjusting weights biases using gradients multiple times. iteration called epoch.","code":"\n# Running all together\n# Adjust weights and reset gradients\nnum_epochs <- 100\n\nfor (i in 1:num_epochs) {\n  preds = model(inputs)\n  loss = mse(preds, targets)\n  loss$backward()\n  with(torch$no_grad(), {\n    w$data <- torch$sub(w$data, torch$mul(w$grad, torch$scalar_tensor(1e-5)))\n    b$data <- torch$sub(b$data, torch$mul(b$grad, torch$scalar_tensor(1e-5)))\n    \n    w$grad$zero_()\n    b$grad$zero_()\n  })\n}\n\n# Calculate loss\npreds = model(inputs)\nloss = mse(preds, targets)\nprint(loss)\n\n# predictions\npreds\n\n# Targets\ntargets#> tensor(1258.0216, grad_fn=<DivBackward0>)\n#> tensor([[ 69.2462,  80.2082],\n#>         [ 73.7183,  97.2052],\n#>         [118.5780, 124.9272],\n#>         [ 89.2282,  92.7052],\n#>         [ 47.4648,  80.7782]], grad_fn=<AddBackward0>)\n#> tensor([[ 56.,  70.],\n#>         [ 81., 101.],\n#>         [119., 133.],\n#>         [ 22.,  37.],\n#>         [103., 119.]])"},{"path":"neural-networks.html","id":"neural-networks","chapter":"12 Neural Networks","heading":"12 Neural Networks","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"neural-networks.html","id":"rtorch-and-pytorch","chapter":"12 Neural Networks","heading":"12.1 rTorch and PyTorch","text":"compare three neural networks:neural network written numpya neural network written numpya neural network written r-basea neural network written r-basea neural network written PyTorcha neural network written PyTorcha neural network written rTorcha neural network written rTorch","code":""},{"path":"neural-networks.html","id":"a-neural-network-with-numpy","chapter":"12 Neural Networks","heading":"12.2 A neural network with numpy","text":"start neural network simply using numpy:","code":"\nlibrary(rTorch)# A simple neural network using NumPy\n# Code in file tensor/two_layer_net_numpy.py\nimport time\nimport numpy as np\n\ntic = time.process_time()\n\nnp.random.seed(123)   # set a seed for reproducibility\n# N is batch size; D_in is input dimension;\n# H is hidden dimension; D_out is output dimension.\nN, D_in, H, D_out = 64, 1000, 100, 10\n\n# Create random input and output data\nx = np.random.randn(N, D_in)\ny = np.random.randn(N, D_out)\n# print(x.shape)\n# print(y.shape)\n\nw1 = np.random.randn(D_in, H)\nw2 = np.random.randn(H, D_out)\n# print(w1.shape)\n# print(w2.shape)\n\nlearning_rate = 1e-6\nfor t in range(500):\n  # Forward pass: compute predicted y\n  h = x.dot(w1)\n  # print(t, h.max())\n  h_relu = np.maximum(h, 0)\n  y_pred = h_relu.dot(w2)\n  \n  # Compute and print loss\n  sq = np.square(y_pred - y)\n  loss = sq.sum()\n  print(t, loss)\n  \n  # Backprop to compute gradients of w1 and w2 with respect to loss\n  grad_y_pred = 2.0 * (y_pred - y)\n  grad_w2 = h_relu.T.dot(grad_y_pred)\n  grad_h_relu = grad_y_pred.dot(w2.T)\n  grad_h = grad_h_relu.copy()\n  grad_h[h < 0] = 0\n  grad_w1 = x.T.dot(grad_h)\n \n  # Update weights\n  w1 -= learning_rate * grad_w1\n  w2 -= learning_rate * grad_w2\n# processing time  #> 0 28624200.800938517\n#> 1 24402861.381040636\n#> 2 23157437.29147552\n#> 3 21617191.63397175\n#> 4 18598190.361558598\n#> 5 14198211.419692844\n#> 6 9786244.45261814\n#> 7 6233451.217340663\n#> 8 3862647.267829599\n#> 9 2412366.632764836\n#> 10 1569915.4392193707\n#> 11 1078501.3381487518\n#> 12 785163.9233288621\n#> 13 601495.2825043725\n#> 14 479906.0403613456\n#> 15 394555.19331746205\n#> 16 331438.6987273826\n#> 17 282679.6687873873\n#> 18 243807.84432087594\n#> 19 211970.18110708205\n#> 20 185451.6861514274\n#> 21 163078.20881862927\n#> 22 144011.80160918707\n#> 23 127662.96132466741\n#> 24 113546.29175681781\n#> 25 101291.55288493488\n#> 26 90623.20833654879\n#> 27 81307.32590692889\n#> 28 73135.24710426925\n#> 29 65937.50294095621\n#> 30 59570.26425368039\n#> 31 53923.82804264227\n#> 32 48909.69273028215\n#> 33 44438.89933807681\n#> 34 40445.34031569733\n#> 35 36873.30041989413\n#> 36 33664.990437423825\n#> 37 30781.198962949587\n#> 38 28184.24227268406\n#> 39 25843.99793108194\n#> 40 23727.282448406426\n#> 41 21810.062067327668\n#> 42 20071.326437572196\n#> 43 18492.63752543329\n#> 44 17056.72779714255\n#> 45 15749.299484025236\n#> 46 14557.324481207237\n#> 47 13468.469764338035\n#> 48 12473.575866914027\n#> 49 11562.485809665774\n#> 50 10727.865926563407\n#> 51 9962.411372816146\n#> 52 9259.619803682268\n#> 53 8613.269071227103\n#> 54 8018.523834750763\n#> 55 7471.080819104451\n#> 56 6966.00651845651\n#> 57 6499.96685422581\n#> 58 6069.576425345411\n#> 59 5671.2821228408475\n#> 60 5302.644980086279\n#> 61 4961.339043761728\n#> 62 4645.02541423451\n#> 63 4351.473575805103\n#> 64 4079.2165446062972\n#> 65 3826.1480820887655\n#> 66 3590.887308956795\n#> 67 3372.0103280622666\n#> 68 3168.173408650748\n#> 69 2978.362100081684\n#> 70 2801.302649097963\n#> 71 2636.037950790892\n#> 72 2481.7354010452655\n#> 73 2337.6093944873246\n#> 74 2202.8250425683987\n#> 75 2076.8872560589616\n#> 76 1958.9976460120263\n#> 77 1848.5060338548483\n#> 78 1744.9993380824799\n#> 79 1647.9807349258715\n#> 80 1556.9947585282196\n#> 81 1471.7081797400347\n#> 82 1391.6136870762566\n#> 83 1316.3329239757227\n#> 84 1245.5902641069824\n#> 85 1179.0691783286234\n#> 86 1116.5095209528572\n#> 87 1057.6662051951396\n#> 88 1002.2519686823666\n#> 89 950.0167505993219\n#> 90 900.7916929993518\n#> 91 854.3816389576979\n#> 92 810.6277767708903\n#> 93 769.3592041348505\n#> 94 730.3836012940042\n#> 95 693.5644048073411\n#> 96 658.7807027999521\n#> 97 625.9238747325827\n#> 98 594.8758111695068\n#> 99 565.4973547949257\n#> 100 537.7012178149556\n#> 101 511.3901106843991\n#> 102 486.4837276215478\n#> 103 462.90746955458474\n#> 104 440.5787622887435\n#> 105 419.4121231392399\n#> 106 399.34612374957226\n#> 107 380.3221777272873\n#> 108 362.2821345456067\n#> 109 345.18049757120184\n#> 110 328.94028615976936\n#> 111 313.5191206271147\n#> 112 298.8754770672758\n#> 113 284.96926791620496\n#> 114 271.7642984526849\n#> 115 259.2246266311472\n#> 116 247.30122156531897\n#> 117 235.96203976771662\n#> 118 225.17874184522793\n#> 119 214.9253969806085\n#> 120 205.16916168826197\n#> 121 195.88920014324063\n#> 122 187.0522150132689\n#> 123 178.6428873875804\n#> 124 170.63479897325027\n#> 125 163.00806018890546\n#> 126 155.7440191346056\n#> 127 148.83352898111042\n#> 128 142.2496666996878\n#> 129 135.97509122834504\n#> 130 129.98982612428355\n#> 131 124.28418865778005\n#> 132 118.84482149781273\n#> 133 113.65645952102406\n#> 134 108.7054397008061\n#> 135 103.98144604072209\n#> 136 99.47512083365962\n#> 137 95.17318303450762\n#> 138 91.06775169947714\n#> 139 87.14952592945869\n#> 140 83.4075554849774\n#> 141 79.8333553283839\n#> 142 76.41993249926654\n#> 143 73.159531678603\n#> 144 70.04535899921396\n#> 145 67.0700037713867\n#> 146 64.22536514818646\n#> 147 61.50715956099643\n#> 148 58.90970110703718\n#> 149 56.42818157298958\n#> 150 54.053456343974474\n#> 151 51.78409899250521\n#> 152 49.613042222061935\n#> 153 47.537088681832714\n#> 154 45.55073951374691\n#> 155 43.651385230775375\n#> 156 41.8333828820336\n#> 157 40.0944925576898\n#> 158 38.4304655768987\n#> 159 36.83773398481151\n#> 160 35.313368600585044\n#> 161 33.85436928433868\n#> 162 32.457997092726586\n#> 163 31.120973836567913\n#> 164 29.841057186484246\n#> 165 28.61536631365921\n#> 166 27.441646501921213\n#> 167 26.31767712811449\n#> 168 25.241065734351473\n#> 169 24.210568668753154\n#> 170 23.223366825888164\n#> 171 22.27691447596546\n#> 172 21.370561777029383\n#> 173 20.502013041055037\n#> 174 19.669605151002397\n#> 175 18.872156637147214\n#> 176 18.107932697664136\n#> 177 17.375347093063624\n#> 178 16.67329705241241\n#> 179 16.000313127916616\n#> 180 15.355056259809643\n#> 181 14.736642044314163\n#> 182 14.143657665391123\n#> 183 13.575482981169435\n#> 184 13.03055792072713\n#> 185 12.507813624903267\n#> 186 12.00650847964371\n#> 187 11.525873890625666\n#> 188 11.064924569594556\n#> 189 10.622845128602144\n#> 190 10.199224278747348\n#> 191 9.79248532294249\n#> 192 9.40221537769526\n#> 193 9.027996925837858\n#> 194 8.668895520243254\n#> 195 8.324385761675554\n#> 196 7.99390867066041\n#> 197 7.676665609325665\n#> 198 7.3722991001285685\n#> 199 7.080233920966563\n#> 200 6.7999405980009\n#> 201 6.530984430178585\n#> 202 6.2728878687947365\n#> 203 6.025197539285438\n#> 204 5.787473375780924\n#> 205 5.559253501791474\n#> 206 5.340172472449113\n#> 207 5.129896948041436\n#> 208 4.928007606815918\n#> 209 4.734225282679221\n#> 210 4.548186858907342\n#> 211 4.369651328446663\n#> 212 4.198236457646962\n#> 213 4.033565011138579\n#> 214 3.8754625080281464\n#> 215 3.7236914115521316\n#> 216 3.5779627242857224\n#> 217 3.4379821914239286\n#> 218 3.303565587540205\n#> 219 3.174454405800678\n#> 220 3.0504743070396323\n#> 221 2.931383709316906\n#> 222 2.8170418304762785\n#> 223 2.7072412196038553\n#> 224 2.6017277000868093\n#> 225 2.50040409121904\n#> 226 2.403078781570677\n#> 227 2.309594481835507\n#> 228 2.219794799730801\n#> 229 2.133526678637347\n#> 230 2.0506760423604566\n#> 231 1.9710453639295484\n#> 232 1.894559024310974\n#> 233 1.8211210547720629\n#> 234 1.7505340383436803\n#> 235 1.6826932948721067\n#> 236 1.6175070289508109\n#> 237 1.5549072300348752\n#> 238 1.4947316986695944\n#> 239 1.436912502600996\n#> 240 1.381372987946563\n#> 241 1.3279854205041584\n#> 242 1.2766884038688984\n#> 243 1.2273848146334094\n#> 244 1.1800217450316255\n#> 245 1.1344919105891025\n#> 246 1.0907369940975837\n#> 247 1.0486826235693274\n#> 248 1.0082656206399931\n#> 249 0.9694282665755529\n#> 250 0.9320976601575675\n#> 251 0.8962339607475229\n#> 252 0.8617533865905884\n#> 253 0.8286151485833971\n#> 254 0.7967578289852474\n#> 255 0.7661404678425654\n#> 256 0.7367202044072118\n#> 257 0.708422713667491\n#> 258 0.6812311487720265\n#> 259 0.6550822696783506\n#> 260 0.6299469090210432\n#> 261 0.605786995355434\n#> 262 0.5825650778276774\n#> 263 0.5602382140936045\n#> 264 0.5387735503110371\n#> 265 0.5181403816556053\n#> 266 0.49830590931295304\n#> 267 0.47922937308117297\n#> 268 0.46088901492620127\n#> 269 0.44325464817119054\n#> 270 0.42630408406116316\n#> 271 0.41000543380657917\n#> 272 0.39433673295843236\n#> 273 0.37927114581493265\n#> 274 0.36478176529460243\n#> 275 0.35085044445134994\n#> 276 0.3374578361158044\n#> 277 0.32457682402453136\n#> 278 0.31219123729919207\n#> 279 0.300296586147234\n#> 280 0.28884848624094894\n#> 281 0.27783526470539743\n#> 282 0.26724487697010957\n#> 283 0.2570618106928273\n#> 284 0.2472693951468085\n#> 285 0.23785306876436113\n#> 286 0.22879648231270536\n#> 287 0.22008909643106767\n#> 288 0.21171318526106842\n#> 289 0.2036578219834066\n#> 290 0.19591133993811427\n#> 291 0.18846041746510728\n#> 292 0.18129477007162065\n#> 293 0.174405315161736\n#> 294 0.16777998120837712\n#> 295 0.16140610523836268\n#> 296 0.1552756501716649\n#> 297 0.14937904644542377\n#> 298 0.14370793039467633\n#> 299 0.13825290527822973\n#> 300 0.13300640130439656\n#> 301 0.12796012311324031\n#> 302 0.12310750541656884\n#> 303 0.11844182274749851\n#> 304 0.11395158652041627\n#> 305 0.10963187686672912\n#> 306 0.10547640155933785\n#> 307 0.10148022089409026\n#> 308 0.0976363799328684\n#> 309 0.09393976586801374\n#> 310 0.09038186218007657\n#> 311 0.08696004033318867\n#> 312 0.08366808215670352\n#> 313 0.08050159133387036\n#> 314 0.0774556507265311\n#> 315 0.07452541616811464\n#> 316 0.07170677388789805\n#> 317 0.06899492388917926\n#> 318 0.06638632065320674\n#> 319 0.06387707772657374\n#> 320 0.06146291085125196\n#> 321 0.0591402294396231\n#> 322 0.05690662209831464\n#> 323 0.05475707395743591\n#> 324 0.05268944906989688\n#> 325 0.05069984545069233\n#> 326 0.048785688597973095\n#> 327 0.046944795197577285\n#> 328 0.045173966618895535\n#> 329 0.043469382749897256\n#> 330 0.04182932192085659\n#> 331 0.04025154186795582\n#> 332 0.038733588417595735\n#> 333 0.03727299017402862\n#> 334 0.03586799441058297\n#> 335 0.03451589218265247\n#> 336 0.03321501089199479\n#> 337 0.03196371785309425\n#> 338 0.030759357425241718\n#> 339 0.029600888472444742\n#> 340 0.028485919148238392\n#> 341 0.02741317225069457\n#> 342 0.026380963792005673\n#> 343 0.025387828276963217\n#> 344 0.02443225636975702\n#> 345 0.02351279471955997\n#> 346 0.02262815392798661\n#> 347 0.02177684408442846\n#> 348 0.02095765200803268\n#> 349 0.02016947466161515\n#> 350 0.019410962895712616\n#> 351 0.018681045066734122\n#> 352 0.017978879513468316\n#> 353 0.017303468563130222\n#> 354 0.016653437842251186\n#> 355 0.01602766278432409\n#> 356 0.015425464893044428\n#> 357 0.01484594678906112\n#> 358 0.014288249850265784\n#> 359 0.01375163575426638\n#> 360 0.01323528665049373\n#> 361 0.012738339025978556\n#> 362 0.012260186918304262\n#> 363 0.011799970856220952\n#> 364 0.011357085981162363\n#> 365 0.010930950268775873\n#> 366 0.010520842685022909\n#> 367 0.010126145830079638\n#> 368 0.009746393154855839\n#> 369 0.009380889339520658\n#> 370 0.009029161386689313\n#> 371 0.00869059833698051\n#> 372 0.00836477207696539\n#> 373 0.008051209390678065\n#> 374 0.0077494325069793705\n#> 375 0.007459023266150334\n#> 376 0.007179590434333104\n#> 377 0.006910623445853765\n#> 378 0.006651749941578513\n#> 379 0.006402648026678379\n#> 380 0.006162978285307884\n#> 381 0.005932194796367616\n#> 382 0.005710085052295781\n#> 383 0.005496310244895275\n#> 384 0.0052906289241425215\n#> 385 0.0050926241688279104\n#> 386 0.004902076613033862\n#> 387 0.004718638851167859\n#> 388 0.004542078962047164\n#> 389 0.004372164586665975\n#> 390 0.004208618626839021\n#> 391 0.004051226677923414\n#> 392 0.0038997374494828298\n#> 393 0.003753918301513866\n#> 394 0.003613561837935153\n#> 395 0.0034784786917529164\n#> 396 0.003348462575629662\n#> 397 0.003223327362263324\n#> 398 0.0031028635490837437\n#> 399 0.002986912218213565\n#> 400 0.002875348146367024\n#> 401 0.0027679524720207994\n#> 402 0.0026645903412969877\n#> 403 0.00256506728009952\n#> 404 0.0024692701898842025\n#> 405 0.0023770671718814063\n#> 406 0.0022883091777422303\n#> 407 0.0022029269889801703\n#> 408 0.0021207379368966914\n#> 409 0.0020415781423120893\n#> 410 0.001965380838191689\n#> 411 0.0018920388674650765\n#> 412 0.0018214489876606395\n#> 413 0.0017534990549357195\n#> 414 0.0016880979054376358\n#> 415 0.0016251364192863505\n#> 416 0.0015645343026947606\n#> 417 0.0015062064772070694\n#> 418 0.0014500530088225327\n#> 419 0.0013959868097274688\n#> 420 0.001343946421404061\n#> 421 0.0012938496041169677\n#> 422 0.001245622397754905\n#> 423 0.0011992050880615885\n#> 424 0.0011545283489900085\n#> 425 0.0011115075856686302\n#> 426 0.001070100670544413\n#> 427 0.0010302364937566674\n#> 428 0.0009918591300819473\n#> 429 0.000954924393232083\n#> 430 0.0009193639132775486\n#> 431 0.0008851308467932729\n#> 432 0.0008521777959560448\n#> 433 0.0008204570911784497\n#> 434 0.0007899223397731109\n#> 435 0.0007605278374214596\n#> 436 0.0007322343466954752\n#> 437 0.0007049830914115257\n#> 438 0.0006787512341473519\n#> 439 0.00065350212037464\n#> 440 0.0006291921955255096\n#> 441 0.0006057856348208776\n#> 442 0.0005832525024800561\n#> 443 0.0005615598539424442\n#> 444 0.0005406761235200468\n#> 445 0.0005205750249286578\n#> 446 0.0005012184845940066\n#> 447 0.0004825848028301716\n#> 448 0.0004646447575300741\n#> 449 0.0004473739461918762\n#> 450 0.0004307513759213604\n#> 451 0.00041474810355609723\n#> 452 0.00039933580480713945\n#> 453 0.0003844970781264902\n#> 454 0.0003702109250696993\n#> 455 0.00035645948619340297\n#> 456 0.0003432213223641764\n#> 457 0.0003304723731848576\n#> 458 0.00031819830164465815\n#> 459 0.00030638121798918724\n#> 460 0.0002950045353519474\n#> 461 0.0002840533130499193\n#> 462 0.00027350873727298176\n#> 463 0.00026335657398426546\n#> 464 0.000253581258369829\n#> 465 0.00024416913722126747\n#> 466 0.0002351142689424904\n#> 467 0.0002263919313737711\n#> 468 0.00021799257674327073\n#> 469 0.00020990427540056088\n#> 470 0.0002021174506938248\n#> 471 0.00019462054044199915\n#> 472 0.00018740325426984858\n#> 473 0.00018045252249983815\n#> 474 0.000173759960543912\n#> 475 0.00016731630060690805\n#> 476 0.0001611122710715995\n#> 477 0.00015513993832625702\n#> 478 0.00014938925941558148\n#> 479 0.00014385207870578823\n#> 480 0.00013852014130375656\n#> 481 0.00013338601187671428\n#> 482 0.000128442793294424\n#> 483 0.0001236841045646944\n#> 484 0.00011910150087090696\n#> 485 0.00011468967274610794\n#> 486 0.00011044058002490428\n#> 487 0.00010634983745106246\n#> 488 0.00010241132940006558\n#> 489 9.861901302344988e-05\n#> 490 9.496682985475842e-05\n#> 491 9.144989845880715e-05\n#> 492 8.806354488018214e-05\n#> 493 8.480312707749194e-05\n#> 494 8.166404591653792e-05\n#> 495 7.864135637113095e-05\n#> 496 7.573027443124469e-05\n#> 497 7.292787602990206e-05\n#> 498 7.023030228370285e-05\n#> 499 6.763183953445079e-05toc = time.process_time()\nprint(toc - tic, \"seconds\")#> 4.680384738000001 seconds"},{"path":"neural-networks.html","id":"a-neural-network-with-r-base","chapter":"12 Neural Networks","heading":"12.3 A neural network with r-base","text":"algorithm numpy written R base.","code":"\nlibrary(tictoc)\n\ntic()\nset.seed(123)\nN <- 64; D_in <- 1000; H <- 100; D_out <- 10;\n# Create random input and output data\nx <- array(rnorm(N * D_in),  dim = c(N, D_in))\ny <- array(rnorm(N * D_out), dim = c(N, D_out))\n# Randomly initialize weights\nw1 <- array(rnorm(D_in * H),  dim = c(D_in, H))\nw2 <- array(rnorm(H * D_out),  dim = c(H, D_out))\nlearning_rate <-  1e-6\n\nfor (t in seq(1, 500)) {\n  # Forward pass: compute predicted y\n  h = x %*% w1\n  h_relu = pmax(h, 0)\n  y_pred = h_relu %*% w2\n\n  # Compute and print loss\n  sq <- (y_pred - y)^2\n  loss = sum(sq)\n  cat(t, loss, \"\\n\")\n  \n  # Backprop to compute gradients of w1 and w2 with respect to loss\n  grad_y_pred = 2.0 * (y_pred - y)\n  grad_w2 = t(h_relu) %*% grad_y_pred\n  grad_h_relu = grad_y_pred %*% t(w2)\n  # grad_h <- sapply(grad_h_relu, function(i) i, simplify = FALSE )   # grad_h = grad_h_relu.copy()\n  grad_h <- rlang::duplicate(grad_h_relu)\n  grad_h[h < 0] <-  0\n  grad_w1 = t(x) %*% grad_h\n  \n  # Update weights\n  w1 = w1 - learning_rate * grad_w1\n  w2 = w2 - learning_rate * grad_w2\n}\ntoc()#> 1 2.8e+07 \n#> 2 25505803 \n#> 3 29441299 \n#> 4 35797650 \n#> 5 39517126 \n#> 6 34884942 \n#> 7 23333535 \n#> 8 11927525 \n#> 9 5352787 \n#> 10 2496984 \n#> 11 1379780 \n#> 12 918213 \n#> 13 695760 \n#> 14 564974 \n#> 15 474479 \n#> 16 405370 \n#> 17 349747 \n#> 18 303724 \n#> 19 265075 \n#> 20 232325 \n#> 21 204394 \n#> 22 180414 \n#> 23 159752 \n#> 24 141895 \n#> 25 126374 \n#> 26 112820 \n#> 27 100959 \n#> 28 90536 \n#> 29 81352 \n#> 30 73244 \n#> 31 66058 \n#> 32 59675 \n#> 33 53993 \n#> 34 48921 \n#> 35 44388 \n#> 36 40328 \n#> 37 36687 \n#> 38 33414 \n#> 39 30469 \n#> 40 27816 \n#> 41 25419 \n#> 42 23251 \n#> 43 21288 \n#> 44 19508 \n#> 45 17893 \n#> 46 16426 \n#> 47 15092 \n#> 48 13877 \n#> 49 12769 \n#> 50 11758 \n#> 51 10835 \n#> 52 9991 \n#> 53 9218 \n#> 54 8510 \n#> 55 7862 \n#> 56 7267 \n#> 57 6719 \n#> 58 6217 \n#> 59 5754 \n#> 60 5329 \n#> 61 4938 \n#> 62 4577 \n#> 63 4245 \n#> 64 3938 \n#> 65 3655 \n#> 66 3394 \n#> 67 3153 \n#> 68 2930 \n#> 69 2724 \n#> 70 2533 \n#> 71 2357 \n#> 72 2193 \n#> 73 2042 \n#> 74 1902 \n#> 75 1772 \n#> 76 1651 \n#> 77 1539 \n#> 78 1435 \n#> 79 1338 \n#> 80 1249 \n#> 81 1165 \n#> 82 1088 \n#> 83 1016 \n#> 84 949 \n#> 85 886 \n#> 86 828 \n#> 87 774 \n#> 88 724 \n#> 89 677 \n#> 90 633 \n#> 91 592 \n#> 92 554 \n#> 93 519 \n#> 94 486 \n#> 95 455 \n#> 96 426 \n#> 97 399 \n#> 98 374 \n#> 99 350 \n#> 100 328 \n#> 101 308 \n#> 102 289 \n#> 103 271 \n#> 104 254 \n#> 105 238 \n#> 106 224 \n#> 107 210 \n#> 108 197 \n#> 109 185 \n#> 110 174 \n#> 111 163 \n#> 112 153 \n#> 113 144 \n#> 114 135 \n#> 115 127 \n#> 116 119 \n#> 117 112 \n#> 118 106 \n#> 119 99.2 \n#> 120 93.3 \n#> 121 87.8 \n#> 122 82.6 \n#> 123 77.7 \n#> 124 73.1 \n#> 125 68.8 \n#> 126 64.7 \n#> 127 60.9 \n#> 128 57.4 \n#> 129 54 \n#> 130 50.9 \n#> 131 47.9 \n#> 132 45.1 \n#> 133 42.5 \n#> 134 40.1 \n#> 135 37.8 \n#> 136 35.6 \n#> 137 33.5 \n#> 138 31.6 \n#> 139 29.8 \n#> 140 28.1 \n#> 141 26.5 \n#> 142 25 \n#> 143 23.6 \n#> 144 22.2 \n#> 145 21 \n#> 146 19.8 \n#> 147 18.7 \n#> 148 17.6 \n#> 149 16.6 \n#> 150 15.7 \n#> 151 14.8 \n#> 152 14 \n#> 153 13.2 \n#> 154 12.5 \n#> 155 11.8 \n#> 156 11.1 \n#> 157 10.5 \n#> 158 9.94 \n#> 159 9.39 \n#> 160 8.87 \n#> 161 8.38 \n#> 162 7.92 \n#> 163 7.49 \n#> 164 7.08 \n#> 165 6.69 \n#> 166 6.32 \n#> 167 5.98 \n#> 168 5.65 \n#> 169 5.35 \n#> 170 5.06 \n#> 171 4.78 \n#> 172 4.52 \n#> 173 4.28 \n#> 174 4.05 \n#> 175 3.83 \n#> 176 3.62 \n#> 177 3.43 \n#> 178 3.25 \n#> 179 3.07 \n#> 180 2.91 \n#> 181 2.75 \n#> 182 2.6 \n#> 183 2.47 \n#> 184 2.33 \n#> 185 2.21 \n#> 186 2.09 \n#> 187 1.98 \n#> 188 1.88 \n#> 189 1.78 \n#> 190 1.68 \n#> 191 1.6 \n#> 192 1.51 \n#> 193 1.43 \n#> 194 1.36 \n#> 195 1.29 \n#> 196 1.22 \n#> 197 1.15 \n#> 198 1.09 \n#> 199 1.04 \n#> 200 0.983 \n#> 201 0.932 \n#> 202 0.883 \n#> 203 0.837 \n#> 204 0.794 \n#> 205 0.753 \n#> 206 0.714 \n#> 207 0.677 \n#> 208 0.642 \n#> 209 0.609 \n#> 210 0.577 \n#> 211 0.548 \n#> 212 0.519 \n#> 213 0.493 \n#> 214 0.467 \n#> 215 0.443 \n#> 216 0.421 \n#> 217 0.399 \n#> 218 0.379 \n#> 219 0.359 \n#> 220 0.341 \n#> 221 0.324 \n#> 222 0.307 \n#> 223 0.292 \n#> 224 0.277 \n#> 225 0.263 \n#> 226 0.249 \n#> 227 0.237 \n#> 228 0.225 \n#> 229 0.213 \n#> 230 0.203 \n#> 231 0.192 \n#> 232 0.183 \n#> 233 0.173 \n#> 234 0.165 \n#> 235 0.156 \n#> 236 0.149 \n#> 237 0.141 \n#> 238 0.134 \n#> 239 0.127 \n#> 240 0.121 \n#> 241 0.115 \n#> 242 0.109 \n#> 243 0.104 \n#> 244 0.0985 \n#> 245 0.0936 \n#> 246 0.0889 \n#> 247 0.0845 \n#> 248 0.0803 \n#> 249 0.0763 \n#> 250 0.0725 \n#> 251 0.0689 \n#> 252 0.0655 \n#> 253 0.0623 \n#> 254 0.0592 \n#> 255 0.0563 \n#> 256 0.0535 \n#> 257 0.0508 \n#> 258 0.0483 \n#> 259 0.0459 \n#> 260 0.0437 \n#> 261 0.0415 \n#> 262 0.0395 \n#> 263 0.0375 \n#> 264 0.0357 \n#> 265 0.0339 \n#> 266 0.0323 \n#> 267 0.0307 \n#> 268 0.0292 \n#> 269 0.0278 \n#> 270 0.0264 \n#> 271 0.0251 \n#> 272 0.0239 \n#> 273 0.0227 \n#> 274 0.0216 \n#> 275 0.0206 \n#> 276 0.0196 \n#> 277 0.0186 \n#> 278 0.0177 \n#> 279 0.0168 \n#> 280 0.016 \n#> 281 0.0152 \n#> 282 0.0145 \n#> 283 0.0138 \n#> 284 0.0131 \n#> 285 0.0125 \n#> 286 0.0119 \n#> 287 0.0113 \n#> 288 0.0108 \n#> 289 0.0102 \n#> 290 0.00975 \n#> 291 0.00927 \n#> 292 0.00883 \n#> 293 0.0084 \n#> 294 0.008 \n#> 295 0.00761 \n#> 296 0.00724 \n#> 297 0.0069 \n#> 298 0.00656 \n#> 299 0.00625 \n#> 300 0.00595 \n#> 301 0.00566 \n#> 302 0.00539 \n#> 303 0.00513 \n#> 304 0.00489 \n#> 305 0.00465 \n#> 306 0.00443 \n#> 307 0.00422 \n#> 308 0.00401 \n#> 309 0.00382 \n#> 310 0.00364 \n#> 311 0.00347 \n#> 312 0.0033 \n#> 313 0.00314 \n#> 314 0.00299 \n#> 315 0.00285 \n#> 316 0.00271 \n#> 317 0.00259 \n#> 318 0.00246 \n#> 319 0.00234 \n#> 320 0.00223 \n#> 321 0.00213 \n#> 322 0.00203 \n#> 323 0.00193 \n#> 324 0.00184 \n#> 325 0.00175 \n#> 326 0.00167 \n#> 327 0.00159 \n#> 328 0.00151 \n#> 329 0.00144 \n#> 330 0.00137 \n#> 331 0.00131 \n#> 332 0.00125 \n#> 333 0.00119 \n#> 334 0.00113 \n#> 335 0.00108 \n#> 336 0.00103 \n#> 337 0.000979 \n#> 338 0.000932 \n#> 339 0.000888 \n#> 340 0.000846 \n#> 341 0.000807 \n#> 342 0.000768 \n#> 343 0.000732 \n#> 344 0.000698 \n#> 345 0.000665 \n#> 346 0.000634 \n#> 347 0.000604 \n#> 348 0.000575 \n#> 349 0.000548 \n#> 350 0.000523 \n#> 351 0.000498 \n#> 352 0.000475 \n#> 353 0.000452 \n#> 354 0.000431 \n#> 355 0.000411 \n#> 356 0.000392 \n#> 357 0.000373 \n#> 358 0.000356 \n#> 359 0.000339 \n#> 360 0.000323 \n#> 361 0.000308 \n#> 362 0.000294 \n#> 363 0.00028 \n#> 364 0.000267 \n#> 365 0.000254 \n#> 366 0.000243 \n#> 367 0.000231 \n#> 368 0.00022 \n#> 369 0.00021 \n#> 370 2e-04 \n#> 371 0.000191 \n#> 372 0.000182 \n#> 373 0.000174 \n#> 374 0.000165 \n#> 375 0.000158 \n#> 376 0.00015 \n#> 377 0.000143 \n#> 378 0.000137 \n#> 379 0.00013 \n#> 380 0.000124 \n#> 381 0.000119 \n#> 382 0.000113 \n#> 383 0.000108 \n#> 384 0.000103 \n#> 385 9.8e-05 \n#> 386 9.34e-05 \n#> 387 8.91e-05 \n#> 388 8.49e-05 \n#> 389 8.1e-05 \n#> 390 7.72e-05 \n#> 391 7.37e-05 \n#> 392 7.02e-05 \n#> 393 6.7e-05 \n#> 394 6.39e-05 \n#> 395 6.09e-05 \n#> 396 5.81e-05 \n#> 397 5.54e-05 \n#> 398 5.28e-05 \n#> 399 5.04e-05 \n#> 400 4.81e-05 \n#> 401 4.58e-05 \n#> 402 4.37e-05 \n#> 403 4.17e-05 \n#> 404 3.98e-05 \n#> 405 3.79e-05 \n#> 406 3.62e-05 \n#> 407 3.45e-05 \n#> 408 3.29e-05 \n#> 409 3.14e-05 \n#> 410 2.99e-05 \n#> 411 2.86e-05 \n#> 412 2.72e-05 \n#> 413 2.6e-05 \n#> 414 2.48e-05 \n#> 415 2.36e-05 \n#> 416 2.25e-05 \n#> 417 2.15e-05 \n#> 418 2.05e-05 \n#> 419 1.96e-05 \n#> 420 1.87e-05 \n#> 421 1.78e-05 \n#> 422 1.7e-05 \n#> 423 1.62e-05 \n#> 424 1.55e-05 \n#> 425 1.48e-05 \n#> 426 1.41e-05 \n#> 427 1.34e-05 \n#> 428 1.28e-05 \n#> 429 1.22e-05 \n#> 430 1.17e-05 \n#> 431 1.11e-05 \n#> 432 1.06e-05 \n#> 433 1.01e-05 \n#> 434 9.66e-06 \n#> 435 9.22e-06 \n#> 436 8.79e-06 \n#> 437 8.39e-06 \n#> 438 8e-06 \n#> 439 7.64e-06 \n#> 440 7.29e-06 \n#> 441 6.95e-06 \n#> 442 6.63e-06 \n#> 443 6.33e-06 \n#> 444 6.04e-06 \n#> 445 5.76e-06 \n#> 446 5.5e-06 \n#> 447 5.25e-06 \n#> 448 5.01e-06 \n#> 449 4.78e-06 \n#> 450 4.56e-06 \n#> 451 4.35e-06 \n#> 452 4.15e-06 \n#> 453 3.96e-06 \n#> 454 3.78e-06 \n#> 455 3.61e-06 \n#> 456 3.44e-06 \n#> 457 3.28e-06 \n#> 458 3.13e-06 \n#> 459 2.99e-06 \n#> 460 2.85e-06 \n#> 461 2.72e-06 \n#> 462 2.6e-06 \n#> 463 2.48e-06 \n#> 464 2.37e-06 \n#> 465 2.26e-06 \n#> 466 2.15e-06 \n#> 467 2.06e-06 \n#> 468 1.96e-06 \n#> 469 1.87e-06 \n#> 470 1.79e-06 \n#> 471 1.71e-06 \n#> 472 1.63e-06 \n#> 473 1.55e-06 \n#> 474 1.48e-06 \n#> 475 1.42e-06 \n#> 476 1.35e-06 \n#> 477 1.29e-06 \n#> 478 1.23e-06 \n#> 479 1.17e-06 \n#> 480 1.12e-06 \n#> 481 1.07e-06 \n#> 482 1.02e-06 \n#> 483 9.74e-07 \n#> 484 9.3e-07 \n#> 485 8.88e-07 \n#> 486 8.47e-07 \n#> 487 8.09e-07 \n#> 488 7.72e-07 \n#> 489 7.37e-07 \n#> 490 7.03e-07 \n#> 491 6.71e-07 \n#> 492 6.41e-07 \n#> 493 6.12e-07 \n#> 494 5.84e-07 \n#> 495 5.57e-07 \n#> 496 5.32e-07 \n#> 497 5.08e-07 \n#> 498 4.85e-07 \n#> 499 4.63e-07 \n#> 500 4.42e-07 \n#> 2.066 sec elapsed"},{"path":"neural-networks.html","id":"a-pytorch-neural-network","chapter":"12 Neural Networks","heading":"12.4 A PyTorch neural network","text":"example used written PyTorch. Notice following differences numpy code:select computation device cpu gpuwe select computation device cpu gpuwhen building creating tensors, specify device want usewhen building creating tensors, specify device want usethe tensors torch methods properties. Example: mm(), clamp(), sum(), clone(), t(),tensors torch methods properties. Example: mm(), clamp(), sum(), clone(), t(),also notice use torch functions: device(), randn()also notice use torch functions: device(), randn()","code":"\nreticulate::use_condaenv(\"r-torch\")# Code in file tensor/two_layer_net_tensor.py\nimport torch\nimport time\n\nms = torch.manual_seed(0)\ntic = time.process_time()\ndevice = torch.device('cpu')\n# device = torch.device('cuda')  # Uncomment this to run on GPU\n\n# N is batch size; D_in is input dimension;\n# H is hidden dimension; D_out is output dimension.\nN, D_in, H, D_out = 64, 1000, 100, 10\n\n# Create random input and output data\nx = torch.randn(N, D_in, device=device)\ny = torch.randn(N, D_out, device=device)\n\n# Randomly initialize weights\nw1 = torch.randn(D_in, H, device=device)\nw2 = torch.randn(H, D_out, device=device)\n\nlearning_rate = 1e-6\nfor t in range(500):\n  # Forward pass: compute predicted y\n  h = x.mm(w1)\n  h_relu = h.clamp(min=0)\n  y_pred = h_relu.mm(w2)\n\n  # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n  # of shape (); we can get its value as a Python number with loss.item().\n  loss = (y_pred - y).pow(2).sum()\n  print(t, loss.item())\n\n  # Backprop to compute gradients of w1 and w2 with respect to loss\n  grad_y_pred = 2.0 * (y_pred - y)\n  grad_w2 = h_relu.t().mm(grad_y_pred)\n  grad_h_relu = grad_y_pred.mm(w2.t())\n  grad_h = grad_h_relu.clone()\n  grad_h[h < 0] = 0\n  grad_w1 = x.t().mm(grad_h)\n\n  # Update weights using gradient descent\n  w1 -= learning_rate * grad_w1\n  w2 -= learning_rate * grad_w2#> 0 29428664.0\n#> 1 22739448.0\n#> 2 20605260.0\n#> 3 19520372.0\n#> 4 17810224.0\n#> 5 14999204.0\n#> 6 11483334.0\n#> 7 8096649.0\n#> 8 5398717.5\n#> 9 3521559.75\n#> 10 2315861.5\n#> 11 1570273.5\n#> 12 1111700.375\n#> 13 825062.8125\n#> 14 639684.4375\n#> 15 514220.625\n#> 16 425155.3125\n#> 17 358904.5625\n#> 18 307636.71875\n#> 19 266625.90625\n#> 20 232998.625\n#> 21 204887.296875\n#> 22 181051.0625\n#> 23 160643.0\n#> 24 143036.09375\n#> 25 127729.578125\n#> 26 114360.25\n#> 27 102621.0234375\n#> 28 92276.9375\n#> 29 83144.0859375\n#> 30 75053.3984375\n#> 31 67870.3984375\n#> 32 61485.79296875\n#> 33 55786.6328125\n#> 34 50690.8515625\n#> 35 46128.6328125\n#> 36 42029.546875\n#> 37 38341.875\n#> 38 35017.33203125\n#> 39 32016.68359375\n#> 40 29303.43359375\n#> 41 26847.1484375\n#> 42 24620.376953125\n#> 43 22599.46875\n#> 44 20762.5625\n#> 45 19090.986328125\n#> 46 17568.359375\n#> 47 16180.1083984375\n#> 48 14911.99609375\n#> 49 13753.8525390625\n#> 50 12694.0205078125\n#> 51 11723.640625\n#> 52 10834.490234375\n#> 53 10019.25390625\n#> 54 9270.923828125\n#> 55 8583.36328125\n#> 56 7950.5625\n#> 57 7368.46875\n#> 58 6832.73779296875\n#> 59 6339.20703125\n#> 60 5884.1484375\n#> 61 5464.44384765625\n#> 62 5077.45849609375\n#> 63 4719.9833984375\n#> 64 4389.5400390625\n#> 65 4084.009765625\n#> 66 3801.313232421875\n#> 67 3539.627197265625\n#> 68 3297.266845703125\n#> 69 3072.8017578125\n#> 70 2864.869140625\n#> 71 2672.025390625\n#> 72 2493.096435546875\n#> 73 2326.89697265625\n#> 74 2172.523193359375\n#> 75 2029.1279296875\n#> 76 1895.768310546875\n#> 77 1771.71435546875\n#> 78 1656.3409423828125\n#> 79 1548.9505615234375\n#> 80 1448.9840087890625\n#> 81 1355.846923828125\n#> 82 1269.0556640625\n#> 83 1188.1507568359375\n#> 84 1112.7042236328125\n#> 85 1042.3167724609375\n#> 86 976.61328125\n#> 87 915.2999267578125\n#> 88 858.0404052734375\n#> 89 804.5496826171875\n#> 90 754.5780029296875\n#> 91 707.8599243164062\n#> 92 664.1988525390625\n#> 93 623.3640747070312\n#> 94 585.147216796875\n#> 95 549.3995971679688\n#> 96 515.9583740234375\n#> 97 484.6272277832031\n#> 98 455.28955078125\n#> 99 427.81829833984375\n#> 100 402.0847473144531\n#> 101 377.9535827636719\n#> 102 355.3477783203125\n#> 103 334.1396179199219\n#> 104 314.2633361816406\n#> 105 295.61749267578125\n#> 106 278.1217346191406\n#> 107 261.7001953125\n#> 108 246.2969512939453\n#> 109 231.8272247314453\n#> 110 218.24240112304688\n#> 111 205.48812866210938\n#> 112 193.5052490234375\n#> 113 182.24417114257812\n#> 114 171.66690063476562\n#> 115 161.72601318359375\n#> 116 152.3784942626953\n#> 117 143.59078979492188\n#> 118 135.32354736328125\n#> 119 127.55582427978516\n#> 120 120.24463653564453\n#> 121 113.36481475830078\n#> 122 106.89350128173828\n#> 123 100.80726623535156\n#> 124 95.07266998291016\n#> 125 89.6752700805664\n#> 126 84.59477233886719\n#> 127 79.80913543701172\n#> 128 75.30223083496094\n#> 129 71.0572509765625\n#> 130 67.05980682373047\n#> 131 63.292694091796875\n#> 132 59.7408447265625\n#> 133 56.394203186035156\n#> 134 53.243412017822266\n#> 135 50.2683219909668\n#> 136 47.46772003173828\n#> 137 44.82497787475586\n#> 138 42.33271408081055\n#> 139 39.983646392822266\n#> 140 37.76749801635742\n#> 141 35.67666244506836\n#> 142 33.70509338378906\n#> 143 31.84467124938965\n#> 144 30.089385986328125\n#> 145 28.432872772216797\n#> 146 26.869369506835938\n#> 147 25.39266586303711\n#> 148 23.999008178710938\n#> 149 22.684724807739258\n#> 150 21.4434757232666\n#> 151 20.270301818847656\n#> 152 19.164194107055664\n#> 153 18.11824607849121\n#> 154 17.131380081176758\n#> 155 16.199291229248047\n#> 156 15.318136215209961\n#> 157 14.486746788024902\n#> 158 13.700006484985352\n#> 159 12.957758903503418\n#> 160 12.256866455078125\n#> 161 11.593376159667969\n#> 162 10.96681022644043\n#> 163 10.374650955200195\n#> 164 9.815613746643066\n#> 165 9.286172866821289\n#> 166 8.78611946105957\n#> 167 8.313515663146973\n#> 168 7.866476058959961\n#> 169 7.443814754486084\n#> 170 7.044161319732666\n#> 171 6.666952133178711\n#> 172 6.309534072875977\n#> 173 5.9717559814453125\n#> 174 5.652008056640625\n#> 175 5.3500075340271\n#> 176 5.06421422958374\n#> 177 4.793882846832275\n#> 178 4.538228511810303\n#> 179 4.296501159667969\n#> 180 4.067446708679199\n#> 181 3.8510499000549316\n#> 182 3.6461739540100098\n#> 183 3.4524216651916504\n#> 184 3.2690694332122803\n#> 185 3.0956828594207764\n#> 186 2.9311866760253906\n#> 187 2.7758116722106934\n#> 188 2.628840684890747\n#> 189 2.4897918701171875\n#> 190 2.357895851135254\n#> 191 2.2333240509033203\n#> 192 2.1151578426361084\n#> 193 2.003354072570801\n#> 194 1.897698998451233\n#> 195 1.7976123094558716\n#> 196 1.7029246091842651\n#> 197 1.6131364107131958\n#> 198 1.5283033847808838\n#> 199 1.4478871822357178\n#> 200 1.371699333190918\n#> 201 1.2994897365570068\n#> 202 1.231500267982483\n#> 203 1.1667163372039795\n#> 204 1.1054186820983887\n#> 205 1.0472912788391113\n#> 206 0.9924129247665405\n#> 207 0.9405249953269958\n#> 208 0.8911417722702026\n#> 209 0.8445178866386414\n#> 210 0.8003085851669312\n#> 211 0.758423388004303\n#> 212 0.7187696099281311\n#> 213 0.6812056303024292\n#> 214 0.6455042362213135\n#> 215 0.6117878556251526\n#> 216 0.5798596739768982\n#> 217 0.5495442152023315\n#> 218 0.5209972858428955\n#> 219 0.4938827455043793\n#> 220 0.46809014678001404\n#> 221 0.4436979293823242\n#> 222 0.42065465450286865\n#> 223 0.3987467288970947\n#> 224 0.3779408633708954\n#> 225 0.35838788747787476\n#> 226 0.3397265076637268\n#> 227 0.3221140503883362\n#> 228 0.30536866188049316\n#> 229 0.2895379662513733\n#> 230 0.27451151609420776\n#> 231 0.2602919638156891\n#> 232 0.24681799113750458\n#> 233 0.23405984044075012\n#> 234 0.22187164425849915\n#> 235 0.2103630006313324\n#> 236 0.19945508241653442\n#> 237 0.18917179107666016\n#> 238 0.1794165074825287\n#> 239 0.1700771450996399\n#> 240 0.1613144725561142\n#> 241 0.152926966547966\n#> 242 0.14506009221076965\n#> 243 0.1375567466020584\n#> 244 0.13043273985385895\n#> 245 0.12370903044939041\n#> 246 0.11734490096569061\n#> 247 0.11129261553287506\n#> 248 0.10555146634578705\n#> 249 0.10010744631290436\n#> 250 0.09495128691196442\n#> 251 0.09006303548812866\n#> 252 0.08542166650295258\n#> 253 0.08105342835187912\n#> 254 0.07687549293041229\n#> 255 0.07293462008237839\n#> 256 0.06918356567621231\n#> 257 0.06564081460237503\n#> 258 0.062239713966846466\n#> 259 0.059055205434560776\n#> 260 0.05602336302399635\n#> 261 0.05314234644174576\n#> 262 0.05042209476232529\n#> 263 0.04785769432783127\n#> 264 0.045423999428749084\n#> 265 0.04309770092368126\n#> 266 0.04090772941708565\n#> 267 0.03880797326564789\n#> 268 0.03683297708630562\n#> 269 0.03495331108570099\n#> 270 0.03315659612417221\n#> 271 0.031475357711315155\n#> 272 0.029864072799682617\n#> 273 0.028345633298158646\n#> 274 0.026901375502347946\n#> 275 0.025526201352477074\n#> 276 0.024225471541285515\n#> 277 0.023021651431918144\n#> 278 0.021845556795597076\n#> 279 0.020738258957862854\n#> 280 0.01967737451195717\n#> 281 0.01868186891078949\n#> 282 0.017737826332449913\n#> 283 0.016843702644109726\n#> 284 0.015994098037481308\n#> 285 0.015187159180641174\n#> 286 0.014432456344366074\n#> 287 0.013691866770386696\n#> 288 0.013026118278503418\n#> 289 0.012365361675620079\n#> 290 0.011741021648049355\n#> 291 0.011153185740113258\n#> 292 0.010602883994579315\n#> 293 0.010070282965898514\n#> 294 0.009570850059390068\n#> 295 0.009099053218960762\n#> 296 0.008648849092423916\n#> 297 0.008217266760766506\n#> 298 0.007814647629857063\n#> 299 0.007436459884047508\n#> 300 0.007072300184518099\n#> 301 0.006720009259879589\n#> 302 0.006387100555002689\n#> 303 0.00608158390969038\n#> 304 0.00578821636736393\n#> 305 0.005504274740815163\n#> 306 0.005235536955296993\n#> 307 0.004986326675862074\n#> 308 0.004750200547277927\n#> 309 0.004520890768617392\n#> 310 0.004305804148316383\n#> 311 0.004104197025299072\n#> 312 0.003908107057213783\n#> 313 0.0037259890232235193\n#> 314 0.0035482768435031176\n#> 315 0.0033842488192021847\n#> 316 0.0032260832376778126\n#> 317 0.0030806262511759996\n#> 318 0.002938204212114215\n#> 319 0.002802144968882203\n#> 320 0.002674166578799486\n#> 321 0.0025522327050566673\n#> 322 0.0024338625371456146\n#> 323 0.002325983252376318\n#> 324 0.0022217126097530127\n#> 325 0.002122103003785014\n#> 326 0.0020273567643016577\n#> 327 0.0019368595676496625\n#> 328 0.0018519405275583267\n#> 329 0.0017723542405292392\n#> 330 0.0016958083724603057\n#> 331 0.00162519421428442\n#> 332 0.001555908122099936\n#> 333 0.0014901482500135899\n#> 334 0.0014247691724449396\n#> 335 0.0013653874630108476\n#> 336 0.001307258615270257\n#> 337 0.0012546550715342164\n#> 338 0.0012025412870571017\n#> 339 0.0011545777088031173\n#> 340 0.001107968739233911\n#> 341 0.0010642317356541753\n#> 342 0.0010200864635407925\n#> 343 0.0009793058270588517\n#> 344 0.0009410151396878064\n#> 345 0.0009048299980349839\n#> 346 0.0008693647105246782\n#> 347 0.000835308397654444\n#> 348 0.0008031500619836152\n#> 349 0.0007735351100564003\n#> 350 0.000744393328204751\n#> 351 0.00071698147803545\n#> 352 0.00069050322053954\n#> 353 0.0006645384710282087\n#> 354 0.0006397517863661051\n#> 355 0.0006177832838147879\n#> 356 0.0005949471960775554\n#> 357 0.0005744362715631723\n#> 358 0.0005537742399610579\n#> 359 0.0005348395789042115\n#> 360 0.0005162699380889535\n#> 361 0.000499469693750143\n#> 362 0.00048172459355555475\n#> 363 0.0004661969724111259\n#> 364 0.0004515194450505078\n#> 365 0.0004358708392828703\n#> 366 0.0004218583053443581\n#> 367 0.00040883725159801543\n#> 368 0.0003956131695304066\n#> 369 0.0003827497421298176\n#> 370 0.000370656605809927\n#> 371 0.00036004791036248207\n#> 372 0.0003480703162495047\n#> 373 0.0003388348559383303\n#> 374 0.000327684567309916\n#> 375 0.0003175089950673282\n#> 376 0.0003082627372350544\n#> 377 0.0002986858307849616\n#> 378 0.00028960598865523934\n#> 379 0.0002815576735883951\n#> 380 0.0002736181777436286\n#> 381 0.0002657140721566975\n#> 382 0.00025785667821764946\n#> 383 0.0002509196347091347\n#> 384 0.00024437913089059293\n#> 385 0.00023740741016808897\n#> 386 0.0002299495681654662\n#> 387 0.0002234804560430348\n#> 388 0.0002169939107261598\n#> 389 0.00021134663256816566\n#> 390 0.0002056143421214074\n#> 391 0.00020046206191182137\n#> 392 0.00019536828040145338\n#> 393 0.00019056514429394156\n#> 394 0.00018598540918901563\n#> 395 0.00018159380124416202\n#> 396 0.00017640764417592436\n#> 397 0.00017208821373060346\n#> 398 0.000168110869708471\n#> 399 0.00016350964142475277\n#> 400 0.00015964081103447825\n#> 401 0.00015596051525790244\n#> 402 0.00015269994037225842\n#> 403 0.00014866374840494245\n#> 404 0.00014477886725217104\n#> 405 0.00014148686022963375\n#> 406 0.00013842849875800312\n#> 407 0.00013507613039109856\n#> 408 0.0001322997995885089\n#> 409 0.00012896949192509055\n#> 410 0.00012618394976016134\n#> 411 0.00012356613297015429\n#> 412 0.00012060831068083644\n#> 413 0.00011798611376434565\n#> 414 0.0001152795521193184\n#> 415 0.00011272911069681868\n#> 416 0.00011033188638975844\n#> 417 0.00010773474059533328\n#> 418 0.00010584026313154027\n#> 419 0.00010329326323699206\n#> 420 0.00010140397353097796\n#> 421 9.970468090614304e-05\n#> 422 9.72362540778704e-05\n#> 423 9.54945498961024e-05\n#> 424 9.346337174065411e-05\n#> 425 9.128850797424093e-05\n#> 426 8.97917925613001e-05\n#> 427 8.779048221185803e-05\n#> 428 8.59305146150291e-05\n#> 429 8.416303899139166e-05\n#> 430 8.247063669841737e-05\n#> 431 8.109148620860651e-05\n#> 432 7.982019451446831e-05\n#> 433 7.818565791239962e-05\n#> 434 7.673520303796977e-05\n#> 435 7.54009815864265e-05\n#> 436 7.374506094492972e-05\n#> 437 7.267539331223816e-05\n#> 438 7.122510578483343e-05\n#> 439 6.98604853823781e-05\n#> 440 6.852982915006578e-05\n#> 441 6.75098126521334e-05\n#> 442 6.636354373767972e-05\n#> 443 6.522039620904252e-05\n#> 444 6.410140485968441e-05\n#> 445 6.307245348580182e-05\n#> 446 6.221079092938453e-05\n#> 447 6.089429371058941e-05\n#> 448 5.975936437607743e-05\n#> 449 5.893126945011318e-05\n#> 450 5.780566425528377e-05\n#> 451 5.694766514352523e-05\n#> 452 5.5986300139920786e-05\n#> 453 5.502309068106115e-05\n#> 454 5.420695379143581e-05\n#> 455 5.31858422618825e-05\n#> 456 5.239694655756466e-05\n#> 457 5.1775907195406035e-05\n#> 458 5.109262929181568e-05\n#> 459 5.0413200369803235e-05\n#> 460 4.956878183293156e-05\n#> 461 4.8856254579732195e-05\n#> 462 4.8221645556623116e-05\n#> 463 4.7429402911802754e-05\n#> 464 4.700458885054104e-05\n#> 465 4.615000216290355e-05\n#> 466 4.5314704038901255e-05\n#> 467 4.466490645427257e-05\n#> 468 4.406480729812756e-05\n#> 469 4.344138142187148e-05\n#> 470 4.302451270632446e-05\n#> 471 4.255307430867106e-05\n#> 472 4.1863419028231874e-05\n#> 473 4.148659354541451e-05\n#> 474 4.099802754353732e-05\n#> 475 4.034798257634975e-05\n#> 476 3.994005237473175e-05\n#> 477 3.94669477827847e-05\n#> 478 3.9117549022194e-05\n#> 479 3.8569156458834186e-05\n#> 480 3.8105612475192174e-05\n#> 481 3.753463170141913e-05\n#> 482 3.679965084302239e-05\n#> 483 3.646357436082326e-05\n#> 484 3.597680915845558e-05\n#> 485 3.555299190338701e-05\n#> 486 3.504360938677564e-05\n#> 487 3.449235737207346e-05\n#> 488 3.391931386431679e-05\n#> 489 3.374389780219644e-05\n#> 490 3.328040838823654e-05\n#> 491 3.31329574692063e-05\n#> 492 3.259751247242093e-05\n#> 493 3.2441555958939716e-05\n#> 494 3.1837684218771756e-05\n#> 495 3.1491359550273046e-05\n#> 496 3.120429755654186e-05\n#> 497 3.089967503910884e-05\n#> 498 3.059657319681719e-05\n#> 499 3.0050463465158828e-05toc = time.process_time()\nprint(toc - tic, \"seconds\")#> 43.14655777 seconds"},{"path":"neural-networks.html","id":"a-neural-network-in-rtorch","chapter":"12 Neural Networks","heading":"12.5 A neural network in rTorch","text":"example shows long manual way calculating forward backward passes using rTorch. objective getting familiarized rTorch tensor operations.following example converted PyTorch rTorch show differences similarities approaches. original source can found : Source.","code":""},{"path":"neural-networks.html","id":"load-the-libraries","chapter":"12 Neural Networks","heading":"12.5.1 Load the libraries","text":"N batch size;D_in input dimension;H hidden dimension;D_out output dimension.","code":"\nlibrary(rTorch)\nlibrary(ggplot2)\n\ndevice = torch$device('cpu')\n# device = torch.device('cuda')  # Uncomment this to run on GPU\ninvisible(torch$manual_seed(0))"},{"path":"neural-networks.html","id":"dataset","chapter":"12 Neural Networks","heading":"12.5.2 Dataset","text":"create random dataset two layer neural network.","code":"\nN <- 64L; D_in <- 1000L; H <- 100L; D_out <- 10L\n\n# Create random Tensors to hold inputs and outputs\nx <- torch$randn(N, D_in, device=device)\ny <- torch$randn(N, D_out, device=device)\n# dimensions of both tensors\ndim(x)\ndim(y)#> [1]   64 1000\n#> [1] 64 10"},{"path":"neural-networks.html","id":"initialize-the-weights","chapter":"12 Neural Networks","heading":"12.5.3 Initialize the weights","text":"","code":"\n# Randomly initialize weights\nw1 <- torch$randn(D_in, H, device=device)   # layer 1\nw2 <- torch$randn(H, D_out, device=device)  # layer 2\ndim(w1)\ndim(w2)#> [1] 1000  100\n#> [1] 100  10"},{"path":"neural-networks.html","id":"iterate-through-the-dataset","chapter":"12 Neural Networks","heading":"12.5.4 Iterate through the dataset","text":"Now, going train neural network training dataset. equestion : “many times expose training data algorithm?” looking graph loss may get idea stop.","code":""},{"path":"neural-networks.html","id":"iterate-50-times","chapter":"12 Neural Networks","heading":"12.5.4.1 Iterate 50 times","text":"Let’s say sake time select run 50 iterations loop training.see lot dispersion predicted values, \\(y_{pred}\\) real values, \\(y\\). far goal.Let’s take look dataframe:","code":"\nlearning_rate = 1e-6\n\n# loop\nfor (t in 1:50) {\n  # Forward pass: compute predicted y, y_pred\n  h <- x$mm(w1)              # matrix multiplication, x*w1\n  h_relu <- h$clamp(min=0)   # make elements greater than zero\n  y_pred <- h_relu$mm(w2)    # matrix multiplication, h_relu*w2\n\n  # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n  # of shape (); we can get its value as a Python number with loss.item().\n  loss <- (torch$sub(y_pred, y))$pow(2)$sum()   # sum((y_pred-y)^2)\n  # cat(t, \"\\t\")\n  # cat(loss$item(), \"\\n\")\n\n  # Backprop to compute gradients of w1 and w2 with respect to loss\n  grad_y_pred <- torch$mul(torch$scalar_tensor(2.0), torch$sub(y_pred, y))\n  grad_w2 <- h_relu$t()$mm(grad_y_pred)        # compute gradient of w2\n  grad_h_relu <- grad_y_pred$mm(w2$t())\n  grad_h <- grad_h_relu$clone()\n  mask <- grad_h$lt(0)                         # filter values lower than zero \n  torch$masked_select(grad_h, mask)$fill_(0.0) # make them equal to zero\n  grad_w1 <- x$t()$mm(grad_h)                  # compute gradient of w1\n   \n  # Update weights using gradient descent\n  w1 <- torch$sub(w1, torch$mul(learning_rate, grad_w1))\n  w2 <- torch$sub(w2, torch$mul(learning_rate, grad_w2))\n}\n# y vs predicted y\ndf_50 <- data.frame(y = y$flatten()$numpy(), \n                    y_pred = y_pred$flatten()$numpy(), iter = 50)\n\nggplot(df_50, aes(x = y, y = y_pred)) +\n    geom_point()\nlibrary('DT')\ndatatable(df_50, options = list(pageLength = 10))"},{"path":"neural-networks.html","id":"a-training-function","chapter":"12 Neural Networks","heading":"12.5.4.2 A training function","text":"Now, convert script function, reuse several times. want study effect iteration performance algorithm.time create function train input number iterations want run:","code":"\ntrain <- function(iterations) {\n    # Randomly initialize weights\n    w1 <- torch$randn(D_in, H, device=device)   # layer 1\n    w2 <- torch$randn(H, D_out, device=device)  # layer 2\n    \n    learning_rate = 1e-6\n    # loop\n    for (t in 1:iterations) {\n      # Forward pass: compute predicted y\n      h <- x$mm(w1)\n      h_relu <- h$clamp(min=0)\n      y_pred <- h_relu$mm(w2)\n    \n      # Compute and print loss; loss is a scalar stored in a PyTorch Tensor\n      # of shape (); we can get its value as a Python number with loss.item().\n      loss <- (torch$sub(y_pred, y))$pow(2)$sum()\n      # cat(t, \"\\t\"); cat(loss$item(), \"\\n\")\n    \n      # Backprop to compute gradients of w1 and w2 with respect to loss\n      grad_y_pred <- torch$mul(torch$scalar_tensor(2.0), torch$sub(y_pred, y))\n      grad_w2 <- h_relu$t()$mm(grad_y_pred)\n      grad_h_relu <- grad_y_pred$mm(w2$t())\n      grad_h <- grad_h_relu$clone()\n      mask <- grad_h$lt(0)\n      torch$masked_select(grad_h, mask)$fill_(0.0)\n      grad_w1 <- x$t()$mm(grad_h)\n       \n      # Update weights using gradient descent\n      w1 <- torch$sub(w1, torch$mul(learning_rate, grad_w1))\n      w2 <- torch$sub(w2, torch$mul(learning_rate, grad_w2))\n    }\n    data.frame(y = y$flatten()$numpy(), \n                        y_pred = y_pred$flatten()$numpy(), iter = iterations)\n}"},{"path":"neural-networks.html","id":"run-it-at-100-iterations","chapter":"12 Neural Networks","heading":"12.5.4.3 Run it at 100 iterations","text":"","code":"\n# retrieve the results and store them in a dataframe\ndf_100 <- train(iterations = 100)\ndatatable(df_100, options = list(pageLength = 10))\n# plot\nggplot(df_100, aes(x = y_pred, y = y)) +\n    geom_point()"},{"path":"neural-networks.html","id":"iterations","chapter":"12 Neural Networks","heading":"12.5.4.4 250 iterations","text":"Still differences value prediction. Let’s try iterations, like 250:see formation line values prediction, means getting closer finding right algorithm, particular case, weights bias.","code":"\ndf_250 <- train(iterations = 200)\ndatatable(df_250, options = list(pageLength = 25))\n# plot\nggplot(df_250, aes(x = y_pred, y = y)) +\n    geom_point()"},{"path":"neural-networks.html","id":"iterations-1","chapter":"12 Neural Networks","heading":"12.5.4.5 500 iterations","text":"Let’s try one time 500 iterations:","code":"\ndf_500 <- train(iterations = 500)\ndatatable(df_500, options = list(pageLength = 25))\nggplot(df_500, aes(x = y_pred, y = y)) +\n    geom_point()"},{"path":"neural-networks.html","id":"full-neural-network-in-rtorch","chapter":"12 Neural Networks","heading":"12.6 Full Neural Network in rTorch","text":"","code":"\nlibrary(rTorch)\nlibrary(ggplot2)\nlibrary(tictoc)\n\ntic()\ndevice = torch$device('cpu')\n# device = torch.device('cuda')  # Uncomment this to run on GPU\ninvisible(torch$manual_seed(0))\n\n# Properties of tensors and neural network\nN <- 64L; D_in <- 1000L; H <- 100L; D_out <- 10L\n\n# Create random Tensors to hold inputs and outputs\nx <- torch$randn(N, D_in, device=device)\ny <- torch$randn(N, D_out, device=device)\n# dimensions of both tensors\n\n# initialize the weights\nw1 <- torch$randn(D_in, H, device=device)   # layer 1\nw2 <- torch$randn(H, D_out, device=device)  # layer 2\n\nlearning_rate = 1e-6\n# loop\nfor (t in 1:500) {\n  # Forward pass: compute predicted y, y_pred\n  h <- x$mm(w1)              # matrix multiplication, x*w1\n  h_relu <- h$clamp(min=0)   # make elements greater than zero\n  y_pred <- h_relu$mm(w2)    # matrix multiplication, h_relu*w2\n\n  # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n  # of shape (); we can get its value as a Python number with loss.item().\n  loss <- (torch$sub(y_pred, y))$pow(2)$sum()   # sum((y_pred-y)^2)\n  # cat(t, \"\\t\")\n  # cat(loss$item(), \"\\n\")\n\n  # Backprop to compute gradients of w1 and w2 with respect to loss\n  grad_y_pred <- torch$mul(torch$scalar_tensor(2.0), torch$sub(y_pred, y))\n  grad_w2 <- h_relu$t()$mm(grad_y_pred)        # compute gradient of w2\n  grad_h_relu <- grad_y_pred$mm(w2$t())\n  grad_h <- grad_h_relu$clone()\n  mask <- grad_h$lt(0)                         # filter values lower than zero \n  torch$masked_select(grad_h, mask)$fill_(0.0) # make them equal to zero\n  grad_w1 <- x$t()$mm(grad_h)                  # compute gradient of w1\n   \n  # Update weights using gradient descent\n  w1 <- torch$sub(w1, torch$mul(learning_rate, grad_w1))\n  w2 <- torch$sub(w2, torch$mul(learning_rate, grad_w2))\n}\n# y vs predicted y\ndf<- data.frame(y = y$flatten()$numpy(), \n                    y_pred = y_pred$flatten()$numpy(), iter = 500)\ndatatable(df, options = list(pageLength = 25))\nggplot(df, aes(x = y_pred, y = y)) +\n    geom_point()\n\ntoc()#> 24.593 sec elapsed"},{"path":"neural-networks.html","id":"exercise-2","chapter":"12 Neural Networks","heading":"12.7 Exercise","text":"Rewrite code rTorch including plotting loss iterationRewrite code rTorch including plotting loss iterationOn neural network written PyTorch, code, instead printing long table, print table pages navigate using vertical horizontal bars. Tip: read PyThon data structure R plot ggplot2On neural network written PyTorch, code, instead printing long table, print table pages navigate using vertical horizontal bars. Tip: read PyThon data structure R plot ggplot2","code":""},{"path":"a-neural-network-step-by-step.html","id":"a-neural-network-step-by-step","chapter":"13 A neural network step-by-step","heading":"13 A neural network step-by-step","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"a-neural-network-step-by-step.html","id":"introduction-1","chapter":"13 A neural network step-by-step","heading":"13.1 Introduction","text":"Source: https://github.com/jcjohnson/pytorch-examples#pytorch-nnIn example use torch nn package implement two-layer network:","code":""},{"path":"a-neural-network-step-by-step.html","id":"select-device","chapter":"13 A neural network step-by-step","heading":"13.2 Select device","text":"N batch size;D_in input dimension;H hidden dimension;D_out output dimension.","code":"\nlibrary(rTorch)\n\ndevice = torch$device('cpu')\n# device = torch.device('cuda') # Uncomment this to run on GPU"},{"path":"a-neural-network-step-by-step.html","id":"create-the-dataset","chapter":"13 A neural network step-by-step","heading":"13.3 Create the dataset","text":"","code":"\ninvisible(torch$manual_seed(0))   # do not show the generator output\nN <- 64L; D_in <- 1000L; H <- 100L; D_out <- 10L\n\n# Create random Tensors to hold inputs and outputs\nx = torch$randn(N, D_in, device=device)\ny = torch$randn(N, D_out, device=device)"},{"path":"a-neural-network-step-by-step.html","id":"define-the-model-1","chapter":"13 A neural network step-by-step","heading":"13.4 Define the model","text":"use nn package define model sequence layers. nn.Sequential applies leayers sequence produce output. Linear Module computes output using linear function, holds also tensors weights biases. constructing model use .() method move desired device, CPU GPU. Remember selected CPU torch$device('cpu').","code":"\nmodel <- torch$nn$Sequential(\n  torch$nn$Linear(D_in, H),              # first layer\n  torch$nn$ReLU(),\n  torch$nn$Linear(H, D_out))$to(device)  # output layer\n\nprint(model)#> Sequential(\n#>   (0): Linear(in_features=1000, out_features=100, bias=True)\n#>   (1): ReLU()\n#>   (2): Linear(in_features=100, out_features=10, bias=True)\n#> )"},{"path":"a-neural-network-step-by-step.html","id":"the-loss-function","chapter":"13 A neural network step-by-step","heading":"13.5 The Loss function","text":"nn package also contains definitions several loss functions; case use Mean Squared Error (\\(MSE\\)) loss function. Setting reduction='sum' means computing sum squared errors rather mean; consistency examples manually compute loss, practice common use mean squared error loss setting reduction='elementwise_mean'.","code":"\nloss_fn = torch$nn$MSELoss(reduction = 'sum')"},{"path":"a-neural-network-step-by-step.html","id":"iterate-through-the-dataset-1","chapter":"13 A neural network step-by-step","heading":"13.6 Iterate through the dataset","text":"","code":"\nlearning_rate = 1e-4\n\nfor (t in 1:500) {\n  # Forward pass: compute predicted y by passing x to the model. Module objects\n  # override the __call__ operator so you can call them like functions. When\n  # doing so you pass a Tensor of input data to the Module and it produces\n  # a Tensor of output data.\n  y_pred = model(x)\n\n  # Compute and print loss. We pass Tensors containing the predicted and true\n  # values of y, and the loss function returns a Tensor containing the loss.\n  loss = loss_fn(y_pred, y)\n  cat(t, \"\\t\")\n  cat(loss$item(), \"\\n\")\n  \n  # Zero the gradients before running the backward pass.\n  model$zero_grad()\n\n  # Backward pass: compute gradient of the loss with respect to all the learnable\n  # parameters of the model. Internally, the parameters of each Module are stored\n  # in Tensors with requires_grad=True, so this call will compute gradients for\n  # all learnable parameters in the model.\n  loss$backward()\n\n  # Update the weights using gradient descent. Each parameter is a Tensor, so\n  # we can access its data and gradients like we did before.\n  with(torch$no_grad(), {\n      for (param in iterate(model$parameters())) {\n        # in Python this code is much simpler. In R we have to do some conversions\n        # param$data <- torch$sub(param$data,\n        #                         torch$mul(param$grad$float(),\n        #                           torch$scalar_tensor(learning_rate)))\n        param$data <- param$data - param$grad * learning_rate\n      }\n   })\n}  #> 1    628 \n#> 2    585 \n#> 3    547 \n#> 4    513 \n#> 5    482 \n#> 6    455 \n#> 7    430 \n#> 8    406 \n#> 9    385 \n#> 10   364 \n#> 11   345 \n#> 12   328 \n#> 13   311 \n#> 14   295 \n#> 15   280 \n#> 16   265 \n#> 17   252 \n#> 18   239 \n#> 19   226 \n#> 20   214 \n#> 21   203 \n#> 22   192 \n#> 23   181 \n#> 24   172 \n#> 25   162 \n#> 26   153 \n#> 27   145 \n#> 28   137 \n#> 29   129 \n#> 30   122 \n#> 31   115 \n#> 32   109 \n#> 33   103 \n#> 34   96.9 \n#> 35   91.5 \n#> 36   86.3 \n#> 37   81.5 \n#> 38   76.9 \n#> 39   72.6 \n#> 40   68.5 \n#> 41   64.6 \n#> 42   61 \n#> 43   57.6 \n#> 44   54.3 \n#> 45   51.3 \n#> 46   48.5 \n#> 47   45.8 \n#> 48   43.2 \n#> 49   40.9 \n#> 50   38.6 \n#> 51   36.5 \n#> 52   34.5 \n#> 53   32.7 \n#> 54   30.9 \n#> 55   29.3 \n#> 56   27.8 \n#> 57   26.3 \n#> 58   24.9 \n#> 59   23.7 \n#> 60   22.4 \n#> 61   21.3 \n#> 62   20.2 \n#> 63   19.2 \n#> 64   18.2 \n#> 65   17.3 \n#> 66   16.5 \n#> 67   15.7 \n#> 68   14.9 \n#> 69   14.2 \n#> 70   13.5 \n#> 71   12.9 \n#> 72   12.3 \n#> 73   11.7 \n#> 74   11.1 \n#> 75   10.6 \n#> 76   10.1 \n#> 77   9.67 \n#> 78   9.24 \n#> 79   8.82 \n#> 80   8.42 \n#> 81   8.05 \n#> 82   7.69 \n#> 83   7.35 \n#> 84   7.03 \n#> 85   6.72 \n#> 86   6.43 \n#> 87   6.16 \n#> 88   5.9 \n#> 89   5.65 \n#> 90   5.41 \n#> 91   5.18 \n#> 92   4.97 \n#> 93   4.76 \n#> 94   4.57 \n#> 95   4.38 \n#> 96   4.2 \n#> 97   4.03 \n#> 98   3.87 \n#> 99   3.72 \n#> 100  3.57 \n#> 101  3.43 \n#> 102  3.29 \n#> 103  3.17 \n#> 104  3.04 \n#> 105  2.92 \n#> 106  2.81 \n#> 107  2.7 \n#> 108  2.6 \n#> 109  2.5 \n#> 110  2.41 \n#> 111  2.31 \n#> 112  2.23 \n#> 113  2.14 \n#> 114  2.06 \n#> 115  1.99 \n#> 116  1.91 \n#> 117  1.84 \n#> 118  1.77 \n#> 119  1.71 \n#> 120  1.65 \n#> 121  1.59 \n#> 122  1.53 \n#> 123  1.47 \n#> 124  1.42 \n#> 125  1.37 \n#> 126  1.32 \n#> 127  1.27 \n#> 128  1.23 \n#> 129  1.18 \n#> 130  1.14 \n#> 131  1.1 \n#> 132  1.06 \n#> 133  1.02 \n#> 134  0.989 \n#> 135  0.954 \n#> 136  0.921 \n#> 137  0.889 \n#> 138  0.858 \n#> 139  0.828 \n#> 140  0.799 \n#> 141  0.772 \n#> 142  0.745 \n#> 143  0.719 \n#> 144  0.695 \n#> 145  0.671 \n#> 146  0.648 \n#> 147  0.626 \n#> 148  0.605 \n#> 149  0.584 \n#> 150  0.564 \n#> 151  0.545 \n#> 152  0.527 \n#> 153  0.509 \n#> 154  0.492 \n#> 155  0.476 \n#> 156  0.46 \n#> 157  0.444 \n#> 158  0.43 \n#> 159  0.415 \n#> 160  0.402 \n#> 161  0.388 \n#> 162  0.375 \n#> 163  0.363 \n#> 164  0.351 \n#> 165  0.339 \n#> 166  0.328 \n#> 167  0.318 \n#> 168  0.307 \n#> 169  0.297 \n#> 170  0.287 \n#> 171  0.278 \n#> 172  0.269 \n#> 173  0.26 \n#> 174  0.252 \n#> 175  0.244 \n#> 176  0.236 \n#> 177  0.228 \n#> 178  0.221 \n#> 179  0.214 \n#> 180  0.207 \n#> 181  0.2 \n#> 182  0.194 \n#> 183  0.187 \n#> 184  0.181 \n#> 185  0.176 \n#> 186  0.17 \n#> 187  0.165 \n#> 188  0.159 \n#> 189  0.154 \n#> 190  0.149 \n#> 191  0.145 \n#> 192  0.14 \n#> 193  0.136 \n#> 194  0.131 \n#> 195  0.127 \n#> 196  0.123 \n#> 197  0.119 \n#> 198  0.115 \n#> 199  0.112 \n#> 200  0.108 \n#> 201  0.105 \n#> 202  0.102 \n#> 203  0.0983 \n#> 204  0.0952 \n#> 205  0.0923 \n#> 206  0.0894 \n#> 207  0.0866 \n#> 208  0.0838 \n#> 209  0.0812 \n#> 210  0.0787 \n#> 211  0.0762 \n#> 212  0.0739 \n#> 213  0.0716 \n#> 214  0.0693 \n#> 215  0.0672 \n#> 216  0.0651 \n#> 217  0.0631 \n#> 218  0.0611 \n#> 219  0.0592 \n#> 220  0.0574 \n#> 221  0.0556 \n#> 222  0.0539 \n#> 223  0.0522 \n#> 224  0.0506 \n#> 225  0.0491 \n#> 226  0.0476 \n#> 227  0.0461 \n#> 228  0.0447 \n#> 229  0.0433 \n#> 230  0.042 \n#> 231  0.0407 \n#> 232  0.0394 \n#> 233  0.0382 \n#> 234  0.0371 \n#> 235  0.0359 \n#> 236  0.0348 \n#> 237  0.0338 \n#> 238  0.0327 \n#> 239  0.0317 \n#> 240  0.0308 \n#> 241  0.0298 \n#> 242  0.0289 \n#> 243  0.028 \n#> 244  0.0272 \n#> 245  0.0263 \n#> 246  0.0255 \n#> 247  0.0248 \n#> 248  0.024 \n#> 249  0.0233 \n#> 250  0.0226 \n#> 251  0.0219 \n#> 252  0.0212 \n#> 253  0.0206 \n#> 254  0.02 \n#> 255  0.0194 \n#> 256  0.0188 \n#> 257  0.0182 \n#> 258  0.0177 \n#> 259  0.0171 \n#> 260  0.0166 \n#> 261  0.0161 \n#> 262  0.0156 \n#> 263  0.0151 \n#> 264  0.0147 \n#> 265  0.0142 \n#> 266  0.0138 \n#> 267  0.0134 \n#> 268  0.013 \n#> 269  0.0126 \n#> 270  0.0122 \n#> 271  0.0119 \n#> 272  0.0115 \n#> 273  0.0112 \n#> 274  0.0108 \n#> 275  0.0105 \n#> 276  0.0102 \n#> 277  0.00988 \n#> 278  0.00959 \n#> 279  0.0093 \n#> 280  0.00902 \n#> 281  0.00875 \n#> 282  0.00849 \n#> 283  0.00824 \n#> 284  0.00799 \n#> 285  0.00775 \n#> 286  0.00752 \n#> 287  0.0073 \n#> 288  0.00708 \n#> 289  0.00687 \n#> 290  0.00666 \n#> 291  0.00647 \n#> 292  0.00627 \n#> 293  0.00609 \n#> 294  0.00591 \n#> 295  0.00573 \n#> 296  0.00556 \n#> 297  0.0054 \n#> 298  0.00524 \n#> 299  0.00508 \n#> 300  0.00493 \n#> 301  0.00478 \n#> 302  0.00464 \n#> 303  0.0045 \n#> 304  0.00437 \n#> 305  0.00424 \n#> 306  0.00412 \n#> 307  0.00399 \n#> 308  0.00388 \n#> 309  0.00376 \n#> 310  0.00365 \n#> 311  0.00354 \n#> 312  0.00344 \n#> 313  0.00334 \n#> 314  0.00324 \n#> 315  0.00314 \n#> 316  0.00305 \n#> 317  0.00296 \n#> 318  0.00287 \n#> 319  0.00279 \n#> 320  0.00271 \n#> 321  0.00263 \n#> 322  0.00255 \n#> 323  0.00248 \n#> 324  0.0024 \n#> 325  0.00233 \n#> 326  0.00226 \n#> 327  0.0022 \n#> 328  0.00213 \n#> 329  0.00207 \n#> 330  0.00201 \n#> 331  0.00195 \n#> 332  0.00189 \n#> 333  0.00184 \n#> 334  0.00178 \n#> 335  0.00173 \n#> 336  0.00168 \n#> 337  0.00163 \n#> 338  0.00158 \n#> 339  0.00154 \n#> 340  0.00149 \n#> 341  0.00145 \n#> 342  0.00141 \n#> 343  0.00137 \n#> 344  0.00133 \n#> 345  0.00129 \n#> 346  0.00125 \n#> 347  0.00121 \n#> 348  0.00118 \n#> 349  0.00114 \n#> 350  0.00111 \n#> 351  0.00108 \n#> 352  0.00105 \n#> 353  0.00102 \n#> 354  0.000987 \n#> 355  0.000958 \n#> 356  0.000931 \n#> 357  0.000904 \n#> 358  0.000877 \n#> 359  0.000852 \n#> 360  0.000827 \n#> 361  0.000803 \n#> 362  0.00078 \n#> 363  0.000757 \n#> 364  0.000735 \n#> 365  0.000714 \n#> 366  0.000693 \n#> 367  0.000673 \n#> 368  0.000654 \n#> 369  0.000635 \n#> 370  0.000617 \n#> 371  0.000599 \n#> 372  0.000581 \n#> 373  0.000565 \n#> 374  0.000548 \n#> 375  0.000532 \n#> 376  0.000517 \n#> 377  0.000502 \n#> 378  0.000488 \n#> 379  0.000474 \n#> 380  0.00046 \n#> 381  0.000447 \n#> 382  0.000434 \n#> 383  0.000421 \n#> 384  0.000409 \n#> 385  0.000397 \n#> 386  0.000386 \n#> 387  0.000375 \n#> 388  0.000364 \n#> 389  0.000354 \n#> 390  0.000343 \n#> 391  0.000334 \n#> 392  0.000324 \n#> 393  0.000315 \n#> 394  0.000306 \n#> 395  0.000297 \n#> 396  0.000288 \n#> 397  0.00028 \n#> 398  0.000272 \n#> 399  0.000264 \n#> 400  0.000257 \n#> 401  0.000249 \n#> 402  0.000242 \n#> 403  0.000235 \n#> 404  0.000228 \n#> 405  0.000222 \n#> 406  0.000216 \n#> 407  0.000209 \n#> 408  0.000203 \n#> 409  0.000198 \n#> 410  0.000192 \n#> 411  0.000186 \n#> 412  0.000181 \n#> 413  0.000176 \n#> 414  0.000171 \n#> 415  0.000166 \n#> 416  0.000161 \n#> 417  0.000157 \n#> 418  0.000152 \n#> 419  0.000148 \n#> 420  0.000144 \n#> 421  0.00014 \n#> 422  0.000136 \n#> 423  0.000132 \n#> 424  0.000128 \n#> 425  0.000124 \n#> 426  0.000121 \n#> 427  0.000117 \n#> 428  0.000114 \n#> 429  0.000111 \n#> 430  0.000108 \n#> 431  0.000105 \n#> 432  0.000102 \n#> 433  9.87e-05 \n#> 434  9.59e-05 \n#> 435  9.32e-05 \n#> 436  9.06e-05 \n#> 437  8.8e-05 \n#> 438  8.55e-05 \n#> 439  8.31e-05 \n#> 440  8.07e-05 \n#> 441  7.84e-05 \n#> 442  7.62e-05 \n#> 443  7.4e-05 \n#> 444  7.2e-05 \n#> 445  6.99e-05 \n#> 446  6.79e-05 \n#> 447  6.6e-05 \n#> 448  6.41e-05 \n#> 449  6.23e-05 \n#> 450  6.06e-05 \n#> 451  5.89e-05 \n#> 452  5.72e-05 \n#> 453  5.56e-05 \n#> 454  5.4e-05 \n#> 455  5.25e-05 \n#> 456  5.1e-05 \n#> 457  4.96e-05 \n#> 458  4.82e-05 \n#> 459  4.68e-05 \n#> 460  4.55e-05 \n#> 461  4.42e-05 \n#> 462  4.3e-05 \n#> 463  4.18e-05 \n#> 464  4.06e-05 \n#> 465  3.94e-05 \n#> 466  3.83e-05 \n#> 467  3.72e-05 \n#> 468  3.62e-05 \n#> 469  3.52e-05 \n#> 470  3.42e-05 \n#> 471  3.32e-05 \n#> 472  3.23e-05 \n#> 473  3.14e-05 \n#> 474  3.05e-05 \n#> 475  2.96e-05 \n#> 476  2.88e-05 \n#> 477  2.8e-05 \n#> 478  2.72e-05 \n#> 479  2.65e-05 \n#> 480  2.57e-05 \n#> 481  2.5e-05 \n#> 482  2.43e-05 \n#> 483  2.36e-05 \n#> 484  2.29e-05 \n#> 485  2.23e-05 \n#> 486  2.17e-05 \n#> 487  2.11e-05 \n#> 488  2.05e-05 \n#> 489  1.99e-05 \n#> 490  1.94e-05 \n#> 491  1.88e-05 \n#> 492  1.83e-05 \n#> 493  1.78e-05 \n#> 494  1.73e-05 \n#> 495  1.68e-05 \n#> 496  1.63e-05 \n#> 497  1.59e-05 \n#> 498  1.54e-05 \n#> 499  1.5e-05 \n#> 500  1.46e-05"},{"path":"a-neural-network-step-by-step.html","id":"using-r-generics","chapter":"13 A neural network step-by-step","heading":"13.7 Using R generics","text":"","code":""},{"path":"a-neural-network-step-by-step.html","id":"simplify-tensor-operations","chapter":"13 A neural network step-by-step","heading":"13.7.1 Simplify tensor operations","text":"following two expressions equivalent, first long version natural way PyTorch. second using generics R subtraction, multiplication scalar conversion.","code":"\nparam$data <- torch$sub(param$data,\n                        torch$mul(param$grad$float(),\n                          torch$scalar_tensor(learning_rate)))\nparam$data <- param$data - param$grad * learning_rate"},{"path":"a-neural-network-step-by-step.html","id":"an-elegant-neural-network","chapter":"13 A neural network step-by-step","heading":"13.8 An elegant neural network","text":"","code":"\ninvisible(torch$manual_seed(0))   # do not show the generator output\n# layer properties\nN <- 64L; D_in <- 1000L; H <- 100L; D_out <- 10L\n\n# Create random Tensors to hold inputs and outputs\nx = torch$randn(N, D_in, device=device)\ny = torch$randn(N, D_out, device=device)\n\n# set up the neural network\nmodel <- torch$nn$Sequential(\n  torch$nn$Linear(D_in, H),              # first layer\n  torch$nn$ReLU(),                       # activation\n  torch$nn$Linear(H, D_out))$to(device)  # output layer\n\n# specify how we will be computing the loss\nloss_fn = torch$nn$MSELoss(reduction = 'sum')\n\nlearning_rate = 1e-4\nloss_row <- list(vector())     # collect a list for the final dataframe\n\nfor (t in 1:500) {\n  # Forward pass: compute predicted y by passing x to the model. Module objects\n  # override the __call__ operator so you can call them like functions. When\n  # doing so you pass a Tensor of input data to the Module and it produces\n  # a Tensor of output data.\n  y_pred = model(x)\n\n  # Compute and print loss. We pass Tensors containing the predicted and true\n  # values of y, and the loss function returns a Tensor containing the loss.\n  loss = loss_fn(y_pred, y)  # (y_pred - y) is a tensor; loss_fn output is a scalar\n  loss_row[[t]] <- c(t, loss$item())\n  \n  # Zero the gradients before running the backward pass.\n  model$zero_grad()\n\n  # Backward pass: compute gradient of the loss with respect to all the learnable\n  # parameters of the model. Internally, the parameters of each module are stored\n  # in tensors with `requires_grad=True`, so this call will compute gradients for\n  # all learnable parameters in the model.\n  loss$backward()\n\n  # Update the weights using gradient descent. Each parameter is a tensor, so\n  # we can access its data and gradients like we did before.\n  with(torch$no_grad(), {\n      for (param in iterate(model$parameters())) {\n        # using R generics\n        param$data <- param$data - param$grad * learning_rate\n      }\n   })\n}  "},{"path":"a-neural-network-step-by-step.html","id":"a-browseable-dataframe","chapter":"13 A neural network step-by-step","heading":"13.9 A browseable dataframe","text":"","code":"\nlibrary(DT)\nloss_df <- data.frame(Reduce(rbind, loss_row), row.names = NULL)\nnames(loss_df)[1] <- \"iter\"\nnames(loss_df)[2] <- \"loss\"\nDT::datatable(loss_df)"},{"path":"a-neural-network-step-by-step.html","id":"plot-the-loss-at-each-iteration","chapter":"13 A neural network step-by-step","heading":"13.10 Plot the loss at each iteration","text":"","code":"\nlibrary(ggplot2)\n# plot\nggplot(loss_df, aes(x = iter, y = loss)) +\n    geom_point()"},{"path":"working-with-a-dataframe.html","id":"working-with-a-dataframe","chapter":"14 Working with a data●frame","heading":"14 Working with a data●frame","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"working-with-a-dataframe.html","id":"load-pytorch-libraries","chapter":"14 Working with a data●frame","heading":"14.1 Load PyTorch libraries","text":"","code":"\nlibrary(rTorch)\n\ntorch       <- import(\"torch\")\ntorchvision <- import(\"torchvision\")\nnn          <- import(\"torch.nn\")\ntransforms  <- import(\"torchvision.transforms\")\ndsets       <- import(\"torchvision.datasets\")\nbuiltins    <- import_builtins()\nnp          <- import(\"numpy\")"},{"path":"working-with-a-dataframe.html","id":"load-dataset","chapter":"14 Working with a data●frame","heading":"14.2 Load dataset","text":"","code":"\n# folders where the images are located\ntrain_data_path = './mnist_png_full/training/'\ntest_data_path  = './mnist_png_full/testing/'\n# read the datasets without normalization\ntrain_dataset = torchvision$datasets$ImageFolder(root = train_data_path, \n    transform = torchvision$transforms$ToTensor()\n)\n\nprint(train_dataset)#> Dataset ImageFolder\n#>     Number of datapoints: 60000\n#>     Root location: ./mnist_png_full/training/\n#>     StandardTransform\n#> Transform: ToTensor()"},{"path":"working-with-a-dataframe.html","id":"summary-statistics-for-tensors","chapter":"14 Working with a data●frame","heading":"14.3 Summary statistics for tensors","text":"","code":""},{"path":"working-with-a-dataframe.html","id":"using-data.frame","chapter":"14 Working with a data●frame","heading":"14.3.1 Using data.frame","text":"Summary statistics:Elapsed time per size sample:","code":"\nlibrary(tictoc)\ntic()\n\nfun_list <- list(\n    size  = c(\"size\"),\n    numel = c(\"numel\"),\n    sum   = c(\"sum\",    \"item\"),\n    mean  = c(\"mean\",   \"item\"),\n    std   = c(\"std\",    \"item\"),\n    med   = c(\"median\", \"item\"),\n    max   = c(\"max\",    \"item\"),\n    min   = c(\"min\",    \"item\")\n    )\n\nidx <- seq(0L, 599L)    # how many samples\n\nfun_get_tensor <- function(x) py_get_item(train_dataset, x)[[0]]\n\nstat_fun <- function(x, str_fun) {\n  fun_var <- paste0(\"fun_get_tensor(x)\", \"$\", str_fun, \"()\")\n  sapply(idx, function(x) \n    ifelse(is.numeric(eval(parse(text = fun_var))),  # size return chracater\n           eval(parse(text = fun_var)),              # all else are numeric\n           as.character(eval(parse(text = fun_var)))))\n}  \n\ndf <- data.frame(ridx = idx+1,      # index number for the sample\n  do.call(data.frame, \n          lapply(\n              sapply(fun_list, function(x) paste(x, collapse = \"()$\")), \n              function(y) stat_fun(1, y)\n          )\n  )\n)\nhead(df, 20)#>    ridx                    size numel sum  mean   std med   max min\n#> 1     1 torch.Size([3, 28, 28])  2352 366 0.156 0.329   0 1.000   0\n#> 2     2 torch.Size([3, 28, 28])  2352 284 0.121 0.297   0 1.000   0\n#> 3     3 torch.Size([3, 28, 28])  2352 645 0.274 0.420   0 1.000   0\n#> 4     4 torch.Size([3, 28, 28])  2352 410 0.174 0.355   0 1.000   0\n#> 5     5 torch.Size([3, 28, 28])  2352 321 0.137 0.312   0 1.000   0\n#> 6     6 torch.Size([3, 28, 28])  2352 654 0.278 0.421   0 1.000   0\n#> 7     7 torch.Size([3, 28, 28])  2352 496 0.211 0.374   0 1.000   0\n#> 8     8 torch.Size([3, 28, 28])  2352 549 0.233 0.399   0 1.000   0\n#> 9     9 torch.Size([3, 28, 28])  2352 449 0.191 0.365   0 1.000   0\n#> 10   10 torch.Size([3, 28, 28])  2352 465 0.198 0.367   0 1.000   0\n#> 11   11 torch.Size([3, 28, 28])  2352 383 0.163 0.338   0 1.000   0\n#> 12   12 torch.Size([3, 28, 28])  2352 499 0.212 0.378   0 1.000   0\n#> 13   13 torch.Size([3, 28, 28])  2352 313 0.133 0.309   0 0.996   0\n#> 14   14 torch.Size([3, 28, 28])  2352 360 0.153 0.325   0 1.000   0\n#> 15   15 torch.Size([3, 28, 28])  2352 435 0.185 0.358   0 0.996   0\n#> 16   16 torch.Size([3, 28, 28])  2352 429 0.182 0.358   0 1.000   0\n#> 17   17 torch.Size([3, 28, 28])  2352 596 0.254 0.408   0 1.000   0\n#> 18   18 torch.Size([3, 28, 28])  2352 527 0.224 0.392   0 1.000   0\n#> 19   19 torch.Size([3, 28, 28])  2352 303 0.129 0.301   0 1.000   0\n#> 20   20 torch.Size([3, 28, 28])  2352 458 0.195 0.364   0 1.000   0\ntoc()\n#    60   1.663s\n#   600  13.5s\n#  6000  54.321 sec;\n# 60000 553.489 sec elapsed#> 9.782 sec elapsed"},{"path":"working-with-datatable.html","id":"working-with-datatable","chapter":"15 Working with data●table","heading":"15 Working with data●table","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"working-with-datatable.html","id":"load-pytorch-libraries-1","chapter":"15 Working with data●table","heading":"15.1 Load PyTorch libraries","text":"","code":"\nlibrary(rTorch)\n\ntorch       <- import(\"torch\")\ntorchvision <- import(\"torchvision\")\nnn          <- import(\"torch.nn\")\ntransforms  <- import(\"torchvision.transforms\")\ndsets       <- import(\"torchvision.datasets\")\nbuiltins    <- import_builtins()\nnp          <- import(\"numpy\")"},{"path":"working-with-datatable.html","id":"load-dataset-1","chapter":"15 Working with data●table","heading":"15.2 Load dataset","text":"","code":"\n## Dataset iteration batch settings\n# folders where the images are located\ntrain_data_path = './mnist_png_full/training/'\ntest_data_path  = './mnist_png_full/testing/'"},{"path":"working-with-datatable.html","id":"datasets-without-normalization","chapter":"15 Working with data●table","heading":"15.3 Datasets without normalization","text":"","code":"\ntrain_dataset = torchvision$datasets$ImageFolder(root = train_data_path, \n    transform = torchvision$transforms$ToTensor()\n)\n\nprint(train_dataset)#> Dataset ImageFolder\n#>     Number of datapoints: 60000\n#>     Root location: ./mnist_png_full/training/\n#>     StandardTransform\n#> Transform: ToTensor()"},{"path":"working-with-datatable.html","id":"using-data.table","chapter":"15 Working with data●table","heading":"15.4 Using data.table","text":"Summary statistics:Elapsed time per size sample:","code":"\nlibrary(data.table)\nlibrary(tictoc)\n\n\ntic()\n\nfun_list <- list(\n    numel = c(\"numel\"),\n    sum   = c(\"sum\",    \"item\"),\n    mean  = c(\"mean\",   \"item\"),\n    std   = c(\"std\",    \"item\"),\n    med   = c(\"median\", \"item\"),\n    max   = c(\"max\",    \"item\"),\n    min   = c(\"min\",    \"item\")\n    )\n\nidx <- seq(0L, 599L)\n\nfun_get_tensor <- function(x) py_get_item(train_dataset, x)[[0]]\n\nstat_fun <- function(x, str_fun) {\n  fun_var <- paste0(\"fun_get_tensor(x)\", \"$\", str_fun, \"()\")\n  sapply(idx, function(x) \n    ifelse(is.numeric(eval(parse(text = fun_var))),  # size return character\n           eval(parse(text = fun_var)),              # all else are numeric\n           as.character(eval(parse(text = fun_var)))))\n}  \n\n\ndt <- data.table(ridx = idx+1,\n  do.call(data.table, \n          lapply(\n            sapply(fun_list, function(x) paste(x, collapse = \"()$\")), \n            function(y) stat_fun(1, y)\n          )\n  )\n)\nhead(dt)#>    ridx numel sum  mean   std med max min\n#> 1:    1  2352 366 0.156 0.329   0   1   0\n#> 2:    2  2352 284 0.121 0.297   0   1   0\n#> 3:    3  2352 645 0.274 0.420   0   1   0\n#> 4:    4  2352 410 0.174 0.355   0   1   0\n#> 5:    5  2352 321 0.137 0.312   0   1   0\n#> 6:    6  2352 654 0.278 0.421   0   1   0\ntoc()\n\n#    60    1.266 sec elapsed\n#   600   11.798 sec elapsed;\n#  6000  119.256 sec elapsed;\n# 60000 1117.619 sec elapsed#> 8.712 sec elapsed"},{"path":"appendixA.html","id":"appendixA","chapter":"A Statistical Background","heading":"A Statistical Background","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":""},{"path":"appendixA.html","id":"basic-statistical-terms","chapter":"A Statistical Background","heading":"A.1 Basic statistical terms","text":"","code":""},{"path":"appendixA.html","id":"five-number-summary","chapter":"A Statistical Background","heading":"A.1.1 Five-number summary","text":"five-number summary consists five values: minimum, first quantile, second quantile, third quantile, maximum. quantiles calculated :first quantile (\\(Q_1\\)): median first half sorted datathird quantile (\\(Q_3\\)): median second half sorted dataFirst quantile: 25th percentile.\nSecond quantile: 50th percentile.\nThird quantile: 75th percentile.interquartile range IQR defined \\(Q_3 - Q_1\\) measure spread middle 50% values .","code":""},{"path":"appendixB.html","id":"appendixB","chapter":"B Activation Functions","heading":"B Activation Functions","text":"Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)","code":"\nlibrary(rTorch)\nlibrary(ggplot2)"},{"path":"appendixB.html","id":"sigmoid","chapter":"B Activation Functions","heading":"B.1 Sigmoid","text":"Using PyTorch sigmoid() function:Plot sigmoid function using R custom-made function:","code":"\nx <- torch$range(-5., 5., 0.1)\ny <- torch$sigmoid(x)\n\ndf <- data.frame(x = x$numpy(), sx = y$numpy())\ndf\n\nggplot(df, aes(x = x, y = sx)) + \n    geom_point() +\n    ggtitle(\"Sigmoid\")#>        x      sx\n#> 1   -5.0 0.00669\n#> 2   -4.9 0.00739\n#> 3   -4.8 0.00816\n#> 4   -4.7 0.00901\n#> 5   -4.6 0.00995\n#> 6   -4.5 0.01099\n#> 7   -4.4 0.01213\n#> 8   -4.3 0.01339\n#> 9   -4.2 0.01477\n#> 10  -4.1 0.01630\n#> 11  -4.0 0.01799\n#> 12  -3.9 0.01984\n#> 13  -3.8 0.02188\n#> 14  -3.7 0.02413\n#> 15  -3.6 0.02660\n#> 16  -3.5 0.02931\n#> 17  -3.4 0.03230\n#> 18  -3.3 0.03557\n#> 19  -3.2 0.03917\n#> 20  -3.1 0.04311\n#> 21  -3.0 0.04743\n#> 22  -2.9 0.05215\n#> 23  -2.8 0.05732\n#> 24  -2.7 0.06297\n#> 25  -2.6 0.06914\n#> 26  -2.5 0.07586\n#> 27  -2.4 0.08317\n#> 28  -2.3 0.09112\n#> 29  -2.2 0.09975\n#> 30  -2.1 0.10910\n#> 31  -2.0 0.11920\n#> 32  -1.9 0.13011\n#> 33  -1.8 0.14185\n#> 34  -1.7 0.15447\n#> 35  -1.6 0.16798\n#> 36  -1.5 0.18243\n#> 37  -1.4 0.19782\n#> 38  -1.3 0.21417\n#> 39  -1.2 0.23148\n#> 40  -1.1 0.24974\n#> 41  -1.0 0.26894\n#> 42  -0.9 0.28905\n#> 43  -0.8 0.31003\n#> 44  -0.7 0.33181\n#> 45  -0.6 0.35434\n#> 46  -0.5 0.37754\n#> 47  -0.4 0.40131\n#> 48  -0.3 0.42556\n#> 49  -0.2 0.45017\n#> 50  -0.1 0.47502\n#> 51   0.0 0.50000\n#> 52   0.1 0.52498\n#> 53   0.2 0.54983\n#> 54   0.3 0.57444\n#> 55   0.4 0.59869\n#> 56   0.5 0.62246\n#> 57   0.6 0.64566\n#> 58   0.7 0.66819\n#> 59   0.8 0.68997\n#> 60   0.9 0.71095\n#> 61   1.0 0.73106\n#> 62   1.1 0.75026\n#> 63   1.2 0.76852\n#> 64   1.3 0.78584\n#> 65   1.4 0.80218\n#> 66   1.5 0.81757\n#> 67   1.6 0.83202\n#> 68   1.7 0.84553\n#> 69   1.8 0.85815\n#> 70   1.9 0.86989\n#> 71   2.0 0.88080\n#> 72   2.1 0.89090\n#> 73   2.2 0.90025\n#> 74   2.3 0.90888\n#> 75   2.4 0.91683\n#> 76   2.5 0.92414\n#> 77   2.6 0.93086\n#> 78   2.7 0.93703\n#> 79   2.8 0.94268\n#> 80   2.9 0.94785\n#> 81   3.0 0.95257\n#> 82   3.1 0.95689\n#> 83   3.2 0.96083\n#> 84   3.3 0.96443\n#> 85   3.4 0.96770\n#> 86   3.5 0.97069\n#> 87   3.6 0.97340\n#> 88   3.7 0.97587\n#> 89   3.8 0.97812\n#> 90   3.9 0.98016\n#> 91   4.0 0.98201\n#> 92   4.1 0.98370\n#> 93   4.2 0.98523\n#> 94   4.3 0.98661\n#> 95   4.4 0.98787\n#> 96   4.5 0.98901\n#> 97   4.6 0.99005\n#> 98   4.7 0.99099\n#> 99   4.8 0.99184\n#> 100  4.9 0.99261\n#> 101  5.0 0.99331\nsigmoid = function(x) {\n   1 / (1 + exp(-x))\n}\n\nx <- seq(-5, 5, 0.01)\nplot(x, sigmoid(x), col = 'blue', cex = 0.5, main = \"Sigmoid\")"},{"path":"appendixB.html","id":"relu","chapter":"B Activation Functions","heading":"B.2 ReLU","text":"Using PyTorch relu() function:","code":"\nx <- torch$range(-5., 5., 0.1)\ny <- torch$relu(x)\n\ndf <- data.frame(x = x$numpy(), sx = y$numpy())\ndf\n\nggplot(df, aes(x = x, y = sx)) + \n    geom_point() +\n    ggtitle(\"ReLU\")"},{"path":"appendixB.html","id":"tanh","chapter":"B Activation Functions","heading":"B.3 tanh","text":"Using PyTorch tanh() function:","code":"\nx <- torch$range(-5., 5., 0.1)\ny <- torch$tanh(x)\n\ndf <- data.frame(x = x$numpy(), sx = y$numpy())\ndf\n\nggplot(df, aes(x = x, y = sx)) + \n    geom_point() +\n    ggtitle(\"tanh\")"},{"path":"appendixB.html","id":"softmax","chapter":"B Activation Functions","heading":"B.4 Softmax","text":"Using PyTorch softmax() function:","code":"\nx <- torch$range(-5.0, 5.0, 0.1)\ny <- torch$softmax(x, dim=0L)\n\ndf <- data.frame(x = x$numpy(), sx = y$numpy())\n\nggplot(df, aes(x = x, y = sx)) + \n    geom_point() +\n    ggtitle(\"Softmax\")"},{"path":"appendixB.html","id":"activation-functions-in-python","chapter":"B Activation Functions","heading":"B.5 Activation functions in Python","text":"","code":"\nlibrary(rTorch)import numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(42)"},{"path":"appendixB.html","id":"linear-activation","chapter":"B Activation Functions","heading":"Linear activation","text":"","code":"def Linear(x, derivative=False):\n    \"\"\"\n    Computes the Linear activation function for array x\n    inputs:\n    x: array\n    derivative: if True, return the derivative else the forward pass\n    \"\"\"\n    \n    if derivative:              # Return derivative of the function at x\n        return np.ones_like(x)\n    else:                       # Return forward pass of the function at x\n        return x"},{"path":"appendixB.html","id":"sigmoid-activation","chapter":"B Activation Functions","heading":"Sigmoid activation","text":"","code":"def Sigmoid(x, derivative=False):\n    \"\"\"\n    Computes the Sigmoid activation function for array x\n    inputs:\n    x: array \n    derivative: if True, return the derivative else the forward pass\n    \"\"\"\n    f = 1/(1+np.exp(-x))\n    \n    if derivative:              # Return derivative of the function at x\n        return f*(1-f)\n    else:                       # Return forward pass of the function at x\n        return f"},{"path":"appendixB.html","id":"hyperbolic-tangent-activation","chapter":"B Activation Functions","heading":"Hyperbolic Tangent activation","text":"","code":"def Tanh(x, derivative=False):\n    \"\"\"\n    Computes the Hyperbolic Tangent activation function for array x\n    inputs:\n    x: array \n    derivative: if True, return the derivative else the forward pass\n    \"\"\"\n    f = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n    \n    if derivative:              # Return  derivative of the function at x\n        return 1-f**2\n    else:                       # Return the forward pass of the function at x\n        return f"},{"path":"appendixB.html","id":"rectifier-linear-unit-relu","chapter":"B Activation Functions","heading":"Rectifier linear unit (ReLU)","text":"","code":"def ReLU(x, derivative=False):\n    \"\"\"\n    Computes the Rectifier Linear Unit activation function for array x\n    inputs:\n    x: array\n    derivative: if True, return the derivative else the forward pass\n    \"\"\"\n    \n    if derivative:              # Return derivative of the function at x\n        return (x>0).astype(int)\n    else:                       # Return forward pass of the function at x\n        return np.maximum(x, 0)"},{"path":"appendixB.html","id":"visualization-with-matplotlib","chapter":"B Activation Functions","heading":"Visualization with matplotlib","text":"Plotting using matplotlib:","code":"x = np.linspace(-6, 6, 100)\nunits = {\n    \"Linear\": lambda x: Linear(x),\n    \"Sigmoid\": lambda x: Sigmoid(x),\n    \"ReLU\": lambda x: ReLU(x),\n    \"tanh\": lambda x: Tanh(x)\n}\n\nplt.figure(figsize=(5, 5))\n[plt.plot(x, unit(x), label=unit_name, lw=2) \n    for unit_name, unit in units.items()]plt.legend(loc=2, fontsize=16)\nplt.title('Activation functions', fontsize=20)\nplt.ylim([-2, 5])plt.xlim([-6, 6])plt.show()"},{"path":"appendixB.html","id":"softmax-code-in-python","chapter":"B Activation Functions","heading":"B.6 Softmax code in Python","text":"","code":"# Source: https://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/\nimport numpy as np\nimport matplotlib.pyplot as plt\n \n \ndef softmax(inputs):\n    \"\"\"\n    Calculate the softmax for the give inputs (array)\n    :param inputs:\n    :return:\n    \"\"\"\n    return np.exp(inputs) / float(sum(np.exp(inputs)))\n \n \ndef line_graph(x, y, x_title, y_title):\n    \"\"\"\n    Draw line graph with x and y values\n    :param x:\n    :param y:\n    :param x_title:\n    :param y_title:\n    :return:\n    \"\"\"\n    plt.plot(x, y)\n    plt.xlabel(x_title)\n    plt.ylabel(y_title)\n    plt.show()\n \n \ngraph_x = np.linspace(-6, 6, 100)\ngraph_y = softmax(graph_x)\n \nprint(\"Graph X readings: {}\".format(graph_x))print(\"Graph Y readings: {}\".format(graph_y))\n line_graph(graph_x, graph_y, \"Inputs\", \"Softmax Scores\")"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 A neural network step-by-step | A Minimal rTorch Book</title>
  <meta name="description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 A neural network step-by-step | A Minimal rTorch Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 A neural network step-by-step | A Minimal rTorch Book" />
  
  <meta name="twitter:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2020-10-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="neural-networks.html"/>
<link rel="next" href="working-with-a-data-frame.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.16/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
      // R show code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('show');
      });
      // Python show code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      // Bash show code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('show');
      }); 
      
  });
  $("#rmd-hide-all-code").click(function() {
      // close the dropdown menu when an option is clicked
      $("#allCodeButton").dropdown("toggle");
      // Hide R code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Python code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Bash code
      $('div.sh-code-collapse').each(function() {
        $(this).collapse('hide');
      });
  });


  // index for unique code element ids
  var r_currentIndex  = 1;   // for R code
  var py_currentIndex = 1;   // for Python code
  var sh_currentIndex  = 1;   // for shell code

  // select Python chunks
  var pyCodeBlocks = $('pre.python');
  pyCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse py-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'pycode-643E0F36' + py_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#ebfaeb');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Python code' : 'Python code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#009900');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Python code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Python code');
    });  
   });
  
  

  // select Bash shell chunks
  var shCodeBlocks = $('pre.bash');
  shCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse sh-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'shcode-643E0F36' + sh_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#A0A0A0');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Bash code' : 'Bash code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#cc7a00');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Bash code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Bash code');
    });  
   });  


  // select all R code blocks
  // var rCodeBlocks = $('pre.sourceCode, pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  // adding pre.sourceCode confuses the Python button
  var rCodeBlocks = $('pre.r, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + r_currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#e6faff'); // change color of chunk background

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide R code' : 'R code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);
    
    // change the background color of the button        
    showCodeButton.css('background-color','#0000ff');
    
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');
    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);
    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('R code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide R code');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  // show code by default. Use "show" === "hide" to hide
  window.initializeCodeFolding("show" === "show");
});
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The rTorch Minimal Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> Start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#get-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Get the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#getting-help"><i class="fa fa-check"></i><b>1.4</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html"><i class="fa fa-check"></i><b>2</b> PyTorch and NumPy</a><ul>
<li class="chapter" data-level="2.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#pytorch-modules-in-rtorch"><i class="fa fa-check"></i><b>2.1</b> PyTorch modules in <code>rTorch</code></a><ul>
<li class="chapter" data-level="2.1.1" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#torchvision"><i class="fa fa-check"></i><b>2.1.1</b> torchvision</a></li>
<li class="chapter" data-level="2.1.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#numpy"><i class="fa fa-check"></i><b>2.1.2</b> numpy</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#common-array-operations"><i class="fa fa-check"></i><b>2.2</b> Common array operations</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#create-an-array"><i class="fa fa-check"></i>Create an array</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#reshape-an-array"><i class="fa fa-check"></i>Reshape an array</a></li>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#generate-a-random-array-in-numpy"><i class="fa fa-check"></i>Generate a random array in NumPy</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#common-tensor-operations"><i class="fa fa-check"></i><b>2.3</b> Common tensor operations</a><ul>
<li class="chapter" data-level="" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#generate-random-tensors"><i class="fa fa-check"></i>Generate random tensors</a></li>
<li><a href="pytorch-and-numpy.html#numpy-array-to-pytorch-tensor"><code>numpy</code> array to PyTorch tensor</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pytorch-and-numpy.html"><a href="pytorch-and-numpy.html#python-built-in-functions"><i class="fa fa-check"></i><b>2.4</b> Python built-in functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html"><i class="fa fa-check"></i><b>3</b> rTorch vs PyTorch</a><ul>
<li class="chapter" data-level="3.1" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#whats-different"><i class="fa fa-check"></i><b>3.1</b> Whatâ€™s different</a></li>
<li class="chapter" data-level="3.2" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>3.2</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="3.3" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#call-functions-from-torch"><i class="fa fa-check"></i><b>3.3</b> Call functions from <code>torch</code></a></li>
<li class="chapter" data-level="3.4" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#python-objects"><i class="fa fa-check"></i><b>3.4</b> Python objects</a></li>
<li class="chapter" data-level="3.5" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#iterating-through-datasets"><i class="fa fa-check"></i><b>3.5</b> Iterating through datasets</a><ul>
<li class="chapter" data-level="3.5.1" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#enumeration"><i class="fa fa-check"></i><b>3.5.1</b> Enumeration</a></li>
<li class="chapter" data-level="3.5.2" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#enumerate-and-iterate"><i class="fa fa-check"></i><b>3.5.2</b> <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="3.5.3" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#for-loop-for-iteration"><i class="fa fa-check"></i><b>3.5.3</b> <code>for-loop</code> for iteration</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#zero-gradient"><i class="fa fa-check"></i><b>3.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="3.6.1" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#code-version-in-python"><i class="fa fa-check"></i><b>3.6.1</b> Code version in Python</a></li>
<li class="chapter" data-level="3.6.2" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#code-version-in-r"><i class="fa fa-check"></i><b>3.6.2</b> Code version in R</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="rtorch-vs-pytorch.html"><a href="rtorch-vs-pytorch.html#r-generic-functions"><i class="fa fa-check"></i><b>3.7</b> R generic functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="converting-tensors.html"><a href="converting-tensors.html"><i class="fa fa-check"></i><b>4</b> Converting tensors</a><ul>
<li class="chapter" data-level="4.1" data-path="converting-tensors.html"><a href="converting-tensors.html#tensor-to-numpy-array"><i class="fa fa-check"></i><b>4.1</b> Tensor to <code>numpy</code> array</a></li>
<li class="chapter" data-level="4.2" data-path="converting-tensors.html"><a href="converting-tensors.html#numpy-array-to-tensor"><i class="fa fa-check"></i><b>4.2</b> <code>numpy</code> array to tensor</a><ul>
<li class="chapter" data-level="4.2.1" data-path="converting-tensors.html"><a href="converting-tensors.html#numpy-array-to-r"><i class="fa fa-check"></i><b>4.2.1</b> <code>numpy</code> array to <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="converting-tensors.html"><a href="converting-tensors.html#r-objects-to-numpy-objects"><i class="fa fa-check"></i><b>4.3</b> R objects to <code>numpy</code> objects</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="5" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>5</b> Tensors</a><ul>
<li class="chapter" data-level="5.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>5.1</b> Tensor data types</a><ul>
<li class="chapter" data-level="5.1.1" data-path="tensors.html"><a href="tensors.html#major-tensor-types"><i class="fa fa-check"></i><b>5.1.1</b> Major tensor types</a></li>
<li class="chapter" data-level="5.1.2" data-path="tensors.html"><a href="tensors.html#example-a-4d-tensor"><i class="fa fa-check"></i><b>5.1.2</b> Example: A 4D tensor</a></li>
<li class="chapter" data-level="5.1.3" data-path="tensors.html"><a href="tensors.html#example-a-3d-tensor"><i class="fa fa-check"></i><b>5.1.3</b> Example: A 3D tensor</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>5.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="5.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>5.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="5.2.2" data-path="tensors.html"><a href="tensors.html#add-tensor-elements"><i class="fa fa-check"></i><b>5.2.2</b> Add tensor elements</a></li>
<li class="chapter" data-level="5.2.3" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>5.2.3</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>5.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="5.3.1" data-path="tensors.html"><a href="tensors.html#python-tuples-and-r-vectors"><i class="fa fa-check"></i><b>5.3.1</b> Python Tuples and R vectors</a></li>
<li class="chapter" data-level="5.3.2" data-path="tensors.html"><a href="tensors.html#a-numpy-array-from-r-vectors"><i class="fa fa-check"></i><b>5.3.2</b> A numpy array from R vectors</a></li>
<li class="chapter" data-level="5.3.3" data-path="tensors.html"><a href="tensors.html#numpy-arrays-to-tensors"><i class="fa fa-check"></i><b>5.3.3</b> numpy arrays to tensors</a></li>
<li class="chapter" data-level="5.3.4" data-path="tensors.html"><a href="tensors.html#create-and-fill-a-tensor"><i class="fa fa-check"></i><b>5.3.4</b> Create and fill a tensor</a></li>
<li class="chapter" data-level="5.3.5" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>5.3.5</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>5.4</b> Create tensors</a><ul>
<li class="chapter" data-level="5.4.1" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>5.4.1</b> Tensor fill</a></li>
<li class="chapter" data-level="5.4.2" data-path="tensors.html"><a href="tensors.html#tensor-with-a-range-of-values"><i class="fa fa-check"></i><b>5.4.2</b> Tensor with a range of values</a></li>
<li class="chapter" data-level="5.4.3" data-path="tensors.html"><a href="tensors.html#linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>5.4.3</b> Linear or log scale Tensor</a></li>
<li class="chapter" data-level="5.4.4" data-path="tensors.html"><a href="tensors.html#in-place-out-of-place-fill"><i class="fa fa-check"></i><b>5.4.4</b> In-place / Out-of-place fill</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>5.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="5.5.1" data-path="tensors.html"><a href="tensors.html#exercise"><i class="fa fa-check"></i><b>5.5.1</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>5.6</b> Concatenate tensors</a><ul>
<li class="chapter" data-level="5.6.1" data-path="tensors.html"><a href="tensors.html#concatenate-by-rows"><i class="fa fa-check"></i><b>5.6.1</b> Concatenate by rows</a></li>
<li class="chapter" data-level="5.6.2" data-path="tensors.html"><a href="tensors.html#concatenate-by-columns"><i class="fa fa-check"></i><b>5.6.2</b> Concatenate by columns</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>5.7</b> Reshape tensors</a><ul>
<li class="chapter" data-level="5.7.1" data-path="tensors.html"><a href="tensors.html#with-chunk"><i class="fa fa-check"></i><b>5.7.1</b> With <code>chunk()</code>:</a></li>
<li class="chapter" data-level="5.7.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>5.7.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>5.8</b> Special tensors</a><ul>
<li class="chapter" data-level="5.8.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>5.8.1</b> Identity matrix</a></li>
<li class="chapter" data-level="5.8.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>5.8.2</b> Ones</a></li>
<li class="chapter" data-level="5.8.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>5.8.3</b> Zeros</a></li>
<li class="chapter" data-level="5.8.4" data-path="tensors.html"><a href="tensors.html#diagonal-operations"><i class="fa fa-check"></i><b>5.8.4</b> Diagonal operations</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>5.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="5.9.1" data-path="tensors.html"><a href="tensors.html#indices-to-tensor-elements"><i class="fa fa-check"></i><b>5.9.1</b> Indices to tensor elements</a></li>
<li class="chapter" data-level="5.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>5.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>5.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="5.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>5.10.1</b> Cross product</a></li>
<li class="chapter" data-level="5.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>5.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>5.11</b> Logical operations</a><ul>
<li class="chapter" data-level="5.11.1" data-path="tensors.html"><a href="tensors.html#extract-a-unique-logical-result"><i class="fa fa-check"></i><b>5.11.1</b> Extract a unique logical result</a></li>
<li class="chapter" data-level="5.11.2" data-path="tensors.html"><a href="tensors.html#greater-than-gt"><i class="fa fa-check"></i><b>5.11.2</b> Greater than (<code>gt</code>)</a></li>
<li class="chapter" data-level="5.11.3" data-path="tensors.html"><a href="tensors.html#less-than-or-equal-le"><i class="fa fa-check"></i><b>5.11.3</b> Less than or equal (<code>le</code>)</a></li>
<li class="chapter" data-level="5.11.4" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>5.11.4</b> Logical NOT (<code>!</code>)</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>5.12</b> Distributions</a><ul>
<li class="chapter" data-level="5.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>5.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="5.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>5.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="5.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>5.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>5.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>6</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="6.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>6.1</b> Scalars</a></li>
<li class="chapter" data-level="6.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>6.2</b> Vectors</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linearalgebra.html"><a href="linearalgebra.html#vector-to-matrix"><i class="fa fa-check"></i><b>6.2.1</b> Vector to matrix</a></li>
<li class="chapter" data-level="6.2.2" data-path="linearalgebra.html"><a href="linearalgebra.html#matrix-to-tensor"><i class="fa fa-check"></i><b>6.2.2</b> Matrix to tensor</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>6.3</b> Matrices</a></li>
<li class="chapter" data-level="6.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>6.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="6.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>6.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="6.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>6.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="6.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>6.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="6.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>6.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="6.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>6.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="6.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>6.10</b> Dot product</a><ul>
<li class="chapter" data-level="6.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#d-array-using-python"><i class="fa fa-check"></i><b>6.10.1</b> 2D array using Python</a></li>
<li class="chapter" data-level="6.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#d-array-using-r"><i class="fa fa-check"></i><b>6.10.2</b> 2D array using R</a></li>
<li class="chapter" data-level="6.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#mm-and-matmul-functions"><i class="fa fa-check"></i><b>6.10.3</b> <code>mm</code> and <code>matmul</code> functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html"><i class="fa fa-check"></i><b>7</b> Creating PyTorch classes</a><ul>
<li class="chapter" data-level="7.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#build-a-pytorch-model-class"><i class="fa fa-check"></i><b>7.1</b> Build a PyTorch model class</a><ul>
<li class="chapter" data-level="7.1.1" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-1-one-layer-nn"><i class="fa fa-check"></i><b>7.1.1</b> Example 1: One layer NN</a></li>
<li class="chapter" data-level="7.1.2" data-path="creating-pytorch-classes.html"><a href="creating-pytorch-classes.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>7.1.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="8" data-path="example-1-a-classification-problem.html"><a href="example-1-a-classification-problem.html"><i class="fa fa-check"></i><b>8</b> Example 1: A classification problem</a><ul>
<li class="chapter" data-level="8.1" data-path="example-1-a-classification-problem.html"><a href="example-1-a-classification-problem.html#code-in-python"><i class="fa fa-check"></i><b>8.1</b> Code in Python</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>9</b> Example 2: MNIST handwritten digits</a><ul>
<li class="chapter" data-level="9.1" data-path="mnistdigits.html"><a href="mnistdigits.html#code-in-r"><i class="fa fa-check"></i><b>9.1</b> Code in R</a><ul>
<li class="chapter" data-level="9.1.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>9.1.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="9.1.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>9.1.2</b> Read datasets</a></li>
<li class="chapter" data-level="9.1.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>9.1.3</b> Define the model</a></li>
<li class="chapter" data-level="9.1.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>9.1.4</b> Training</a></li>
<li class="chapter" data-level="9.1.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>9.1.5</b> Prediction</a></li>
<li class="chapter" data-level="9.1.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>9.1.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="mnistdigits.html"><a href="mnistdigits.html#code-in-python-1"><i class="fa fa-check"></i><b>9.2</b> Code in Python</a></li>
</ul></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="10" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>10</b> Linear Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="linear-regression.html"><a href="linear-regression.html#introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="linear-regression.html"><a href="linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>10.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="10.3" data-path="linear-regression.html"><a href="linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>10.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="10.4" data-path="linear-regression.html"><a href="linear-regression.html#numpy-array-to-tensor-1"><i class="fa fa-check"></i><b>10.4</b> <code>numpy</code> array to tensor</a></li>
<li class="chapter" data-level="10.5" data-path="linear-regression.html"><a href="linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>10.5</b> Creating the network model</a></li>
<li class="chapter" data-level="10.6" data-path="linear-regression.html"><a href="linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>10.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="10.7" data-path="linear-regression.html"><a href="linear-regression.html#training-1"><i class="fa fa-check"></i><b>10.7</b> Training</a></li>
<li class="chapter" data-level="10.8" data-path="linear-regression.html"><a href="linear-regression.html#results"><i class="fa fa-check"></i><b>10.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>11</b> Linear Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#rainfall-prediction"><i class="fa fa-check"></i><b>11.1</b> Rainfall prediction</a></li>
<li class="chapter" data-level="11.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#training-data"><i class="fa fa-check"></i><b>11.2</b> Training data</a></li>
<li class="chapter" data-level="11.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>11.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="11.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#build-the-model"><i class="fa fa-check"></i><b>11.4</b> Build the model</a></li>
<li class="chapter" data-level="11.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-predictions"><i class="fa fa-check"></i><b>11.5</b> Generate predictions</a></li>
<li class="chapter" data-level="11.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#loss-function"><i class="fa fa-check"></i><b>11.6</b> Loss Function</a></li>
<li class="chapter" data-level="11.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#step-by-step-process"><i class="fa fa-check"></i><b>11.7</b> Step by step process</a><ul>
<li class="chapter" data-level="11.7.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#compute-the-losses"><i class="fa fa-check"></i><b>11.7.1</b> Compute the losses</a></li>
<li class="chapter" data-level="11.7.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#compute-gradients"><i class="fa fa-check"></i><b>11.7.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="11.7.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#reset-the-gradients"><i class="fa fa-check"></i><b>11.7.3</b> Reset the gradients</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#all-together"><i class="fa fa-check"></i><b>11.8</b> All together</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="12" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>12</b> Neural Networks</a><ul>
<li class="chapter" data-level="12.1" data-path="neural-networks.html"><a href="neural-networks.html#rtorch-and-pytorch"><i class="fa fa-check"></i><b>12.1</b> rTorch and PyTorch</a></li>
<li class="chapter" data-level="12.2" data-path="neural-networks.html"><a href="neural-networks.html#a-neural-network-with-numpy"><i class="fa fa-check"></i><b>12.2</b> A neural network with <code>numpy</code></a></li>
<li class="chapter" data-level="12.3" data-path="neural-networks.html"><a href="neural-networks.html#a-neural-network-with-r-base"><i class="fa fa-check"></i><b>12.3</b> A neural network with <code>r-base</code></a></li>
<li class="chapter" data-level="12.4" data-path="neural-networks.html"><a href="neural-networks.html#a-pytorch-neural-network"><i class="fa fa-check"></i><b>12.4</b> A <code>PyTorch</code> neural network</a></li>
<li class="chapter" data-level="12.5" data-path="neural-networks.html"><a href="neural-networks.html#a-neural-network-in-rtorch"><i class="fa fa-check"></i><b>12.5</b> A neural network in <code>rTorch</code></a><ul>
<li class="chapter" data-level="12.5.1" data-path="neural-networks.html"><a href="neural-networks.html#load-the-libraries"><i class="fa fa-check"></i><b>12.5.1</b> Load the libraries</a></li>
<li class="chapter" data-level="12.5.2" data-path="neural-networks.html"><a href="neural-networks.html#dataset"><i class="fa fa-check"></i><b>12.5.2</b> Dataset</a></li>
<li class="chapter" data-level="12.5.3" data-path="neural-networks.html"><a href="neural-networks.html#initialize-the-weights"><i class="fa fa-check"></i><b>12.5.3</b> Initialize the weights</a></li>
<li class="chapter" data-level="12.5.4" data-path="neural-networks.html"><a href="neural-networks.html#iterate-through-the-dataset"><i class="fa fa-check"></i><b>12.5.4</b> Iterate through the dataset</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="neural-networks.html"><a href="neural-networks.html#full-neural-network-in-rtorch"><i class="fa fa-check"></i><b>12.6</b> Full Neural Network in rTorch</a></li>
<li class="chapter" data-level="12.7" data-path="neural-networks.html"><a href="neural-networks.html#exercise-2"><i class="fa fa-check"></i><b>12.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html"><i class="fa fa-check"></i><b>13</b> A neural network step-by-step</a><ul>
<li class="chapter" data-level="13.1" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#introduction-1"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#select-device"><i class="fa fa-check"></i><b>13.2</b> Select device</a></li>
<li class="chapter" data-level="13.3" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#create-the-dataset"><i class="fa fa-check"></i><b>13.3</b> Create the dataset</a></li>
<li class="chapter" data-level="13.4" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#define-the-model-1"><i class="fa fa-check"></i><b>13.4</b> Define the model</a></li>
<li class="chapter" data-level="13.5" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#the-loss-function"><i class="fa fa-check"></i><b>13.5</b> The Loss function</a></li>
<li class="chapter" data-level="13.6" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#iterate-through-the-dataset-1"><i class="fa fa-check"></i><b>13.6</b> Iterate through the dataset</a></li>
<li class="chapter" data-level="13.7" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#using-r-generics"><i class="fa fa-check"></i><b>13.7</b> Using R generics</a><ul>
<li class="chapter" data-level="13.7.1" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#simplify-tensor-operations"><i class="fa fa-check"></i><b>13.7.1</b> Simplify tensor operations</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#an-elegant-neural-network"><i class="fa fa-check"></i><b>13.8</b> An elegant neural network</a></li>
<li class="chapter" data-level="13.9" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#a-browseable-dataframe"><i class="fa fa-check"></i><b>13.9</b> A browseable dataframe</a></li>
<li class="chapter" data-level="13.10" data-path="a-neural-network-step-by-step.html"><a href="a-neural-network-step-by-step.html#plot-the-loss-at-each-iteration"><i class="fa fa-check"></i><b>13.10</b> Plot the loss at each iteration</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="14" data-path="working-with-a-data-frame.html"><a href="working-with-a-data-frame.html"><i class="fa fa-check"></i><b>14</b> Working with a data.frame</a><ul>
<li class="chapter" data-level="14.1" data-path="working-with-a-data-frame.html"><a href="working-with-a-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>14.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="14.2" data-path="working-with-a-data-frame.html"><a href="working-with-a-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>14.2</b> Load dataset</a></li>
<li class="chapter" data-level="14.3" data-path="working-with-a-data-frame.html"><a href="working-with-a-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>14.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="14.3.1" data-path="working-with-a-data-frame.html"><a href="working-with-a-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>14.3.1</b> Using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>15</b> Working with data.table</a><ul>
<li class="chapter" data-level="15.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>15.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="15.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>15.2</b> Load dataset</a></li>
<li class="chapter" data-level="15.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#datasets-without-normalization"><i class="fa fa-check"></i><b>15.3</b> Datasets without normalization</a></li>
<li class="chapter" data-level="15.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>15.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#sigmoid"><i class="fa fa-check"></i><b>B.1</b> Sigmoid</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#relu"><i class="fa fa-check"></i><b>B.2</b> ReLU</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#tanh"><i class="fa fa-check"></i><b>B.3</b> tanh</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#softmax"><i class="fa fa-check"></i><b>B.4</b> Softmax</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Activation functions in Python</a><ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li><a href="appendixB.html#visualization-with-matplotlib">Visualization with <code>matplotlib</code></a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-code-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax code in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="a-neural-network-step-by-step" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> A neural network step-by-step</h1>
<p><em>Last update: Thu Oct 22 16:46:28 2020 -0500 (54a46ea04)</em></p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">13.1</span> Introduction</h2>
<p>Source: <a href="https://github.com/jcjohnson/pytorch-examples#pytorch-nn" class="uri">https://github.com/jcjohnson/pytorch-examples#pytorch-nn</a></p>
<p>In this example we use the torch <code>nn</code> package to implement our two-layer network:</p>
</div>
<div id="select-device" class="section level2">
<h2><span class="header-section-number">13.2</span> Select device</h2>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="a-neural-network-step-by-step.html#cb537-1"></a><span class="kw">library</span>(rTorch)</span>
<span id="cb537-2"><a href="a-neural-network-step-by-step.html#cb537-2"></a></span>
<span id="cb537-3"><a href="a-neural-network-step-by-step.html#cb537-3"></a>device =<span class="st"> </span>torch<span class="op">$</span><span class="kw">device</span>(<span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb537-4"><a href="a-neural-network-step-by-step.html#cb537-4"></a><span class="co"># device = torch.device(&#39;cuda&#39;) # Uncomment this to run on GPU</span></span></code></pre></div>
<ul>
<li><code>N</code> is batch size;</li>
<li><code>D_in</code> is input dimension;</li>
<li><code>H</code> is hidden dimension;</li>
<li><code>D_out</code> is output dimension.</li>
</ul>
</div>
<div id="create-the-dataset" class="section level2">
<h2><span class="header-section-number">13.3</span> Create the dataset</h2>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="a-neural-network-step-by-step.html#cb538-1"></a><span class="kw">invisible</span>(torch<span class="op">$</span><span class="kw">manual_seed</span>(<span class="dv">0</span>))   <span class="co"># do not show the generator output</span></span>
<span id="cb538-2"><a href="a-neural-network-step-by-step.html#cb538-2"></a>N &lt;-<span class="st"> </span>64L; D_in &lt;-<span class="st"> </span>1000L; H &lt;-<span class="st"> </span>100L; D_out &lt;-<span class="st"> </span>10L</span>
<span id="cb538-3"><a href="a-neural-network-step-by-step.html#cb538-3"></a></span>
<span id="cb538-4"><a href="a-neural-network-step-by-step.html#cb538-4"></a><span class="co"># Create random Tensors to hold inputs and outputs</span></span>
<span id="cb538-5"><a href="a-neural-network-step-by-step.html#cb538-5"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(N, D_in, <span class="dt">device=</span>device)</span>
<span id="cb538-6"><a href="a-neural-network-step-by-step.html#cb538-6"></a>y =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(N, D_out, <span class="dt">device=</span>device)</span></code></pre></div>
</div>
<div id="define-the-model-1" class="section level2">
<h2><span class="header-section-number">13.4</span> Define the model</h2>
<p>We use the <code>nn</code> package to define our model as a sequence of layers. <code>nn.Sequential</code> applies these leayers in sequence to produce an output. Each <em>Linear Module</em> computes the output by using a linear function, and holds also tensors for its weights and biases. After constructing the model we use the <code>.to()</code> method to move it to the desired device, which could be <code>CPU</code> or <code>GPU</code>. Remember that we selected <code>CPU</code> with <code>torch$device('cpu')</code>.</p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="a-neural-network-step-by-step.html#cb539-1"></a>model &lt;-<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Sequential</span>(</span>
<span id="cb539-2"><a href="a-neural-network-step-by-step.html#cb539-2"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(D_in, H),              <span class="co"># first layer</span></span>
<span id="cb539-3"><a href="a-neural-network-step-by-step.html#cb539-3"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">ReLU</span>(),</span>
<span id="cb539-4"><a href="a-neural-network-step-by-step.html#cb539-4"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(H, D_out))<span class="op">$</span><span class="kw">to</span>(device)  <span class="co"># output layer</span></span>
<span id="cb539-5"><a href="a-neural-network-step-by-step.html#cb539-5"></a></span>
<span id="cb539-6"><a href="a-neural-network-step-by-step.html#cb539-6"></a><span class="kw">print</span>(model)</span></code></pre></div>
<pre><code>#&gt; Sequential(
#&gt;   (0): Linear(in_features=1000, out_features=100, bias=True)
#&gt;   (1): ReLU()
#&gt;   (2): Linear(in_features=100, out_features=10, bias=True)
#&gt; )</code></pre>
</div>
<div id="the-loss-function" class="section level2">
<h2><span class="header-section-number">13.5</span> The Loss function</h2>
<p>The <code>nn</code> package also contains definitions of several loss functions; in this case we will use <strong>Mean Squared Error</strong> (<span class="math inline">\(MSE\)</span>) as our loss function. Setting <code>reduction='sum'</code> means that we are computing the <em>sum</em> of squared errors rather than the <strong>mean</strong>; this is for consistency with the examples above where we manually compute the loss, but in practice it is more common to use the mean squared error as a loss by setting <code>reduction='elementwise_mean'</code>.</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="a-neural-network-step-by-step.html#cb541-1"></a>loss_fn =<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">MSELoss</span>(<span class="dt">reduction =</span> <span class="st">&#39;sum&#39;</span>)</span></code></pre></div>
</div>
<div id="iterate-through-the-dataset-1" class="section level2">
<h2><span class="header-section-number">13.6</span> Iterate through the dataset</h2>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="a-neural-network-step-by-step.html#cb542-1"></a>learning_rate =<span class="st"> </span><span class="fl">1e-4</span></span>
<span id="cb542-2"><a href="a-neural-network-step-by-step.html#cb542-2"></a></span>
<span id="cb542-3"><a href="a-neural-network-step-by-step.html#cb542-3"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">500</span>) {</span>
<span id="cb542-4"><a href="a-neural-network-step-by-step.html#cb542-4"></a>  <span class="co"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span>
<span id="cb542-5"><a href="a-neural-network-step-by-step.html#cb542-5"></a>  <span class="co"># override the __call__ operator so you can call them like functions. When</span></span>
<span id="cb542-6"><a href="a-neural-network-step-by-step.html#cb542-6"></a>  <span class="co"># doing so you pass a Tensor of input data to the Module and it produces</span></span>
<span id="cb542-7"><a href="a-neural-network-step-by-step.html#cb542-7"></a>  <span class="co"># a Tensor of output data.</span></span>
<span id="cb542-8"><a href="a-neural-network-step-by-step.html#cb542-8"></a>  y_pred =<span class="st"> </span><span class="kw">model</span>(x)</span>
<span id="cb542-9"><a href="a-neural-network-step-by-step.html#cb542-9"></a></span>
<span id="cb542-10"><a href="a-neural-network-step-by-step.html#cb542-10"></a>  <span class="co"># Compute and print loss. We pass Tensors containing the predicted and true</span></span>
<span id="cb542-11"><a href="a-neural-network-step-by-step.html#cb542-11"></a>  <span class="co"># values of y, and the loss function returns a Tensor containing the loss.</span></span>
<span id="cb542-12"><a href="a-neural-network-step-by-step.html#cb542-12"></a>  loss =<span class="st"> </span><span class="kw">loss_fn</span>(y_pred, y)</span>
<span id="cb542-13"><a href="a-neural-network-step-by-step.html#cb542-13"></a>  <span class="kw">cat</span>(t, <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)</span>
<span id="cb542-14"><a href="a-neural-network-step-by-step.html#cb542-14"></a>  <span class="kw">cat</span>(loss<span class="op">$</span><span class="kw">item</span>(), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb542-15"><a href="a-neural-network-step-by-step.html#cb542-15"></a>  </span>
<span id="cb542-16"><a href="a-neural-network-step-by-step.html#cb542-16"></a>  <span class="co"># Zero the gradients before running the backward pass.</span></span>
<span id="cb542-17"><a href="a-neural-network-step-by-step.html#cb542-17"></a>  model<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb542-18"><a href="a-neural-network-step-by-step.html#cb542-18"></a></span>
<span id="cb542-19"><a href="a-neural-network-step-by-step.html#cb542-19"></a>  <span class="co"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span>
<span id="cb542-20"><a href="a-neural-network-step-by-step.html#cb542-20"></a>  <span class="co"># parameters of the model. Internally, the parameters of each Module are stored</span></span>
<span id="cb542-21"><a href="a-neural-network-step-by-step.html#cb542-21"></a>  <span class="co"># in Tensors with requires_grad=True, so this call will compute gradients for</span></span>
<span id="cb542-22"><a href="a-neural-network-step-by-step.html#cb542-22"></a>  <span class="co"># all learnable parameters in the model.</span></span>
<span id="cb542-23"><a href="a-neural-network-step-by-step.html#cb542-23"></a>  loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb542-24"><a href="a-neural-network-step-by-step.html#cb542-24"></a></span>
<span id="cb542-25"><a href="a-neural-network-step-by-step.html#cb542-25"></a>  <span class="co"># Update the weights using gradient descent. Each parameter is a Tensor, so</span></span>
<span id="cb542-26"><a href="a-neural-network-step-by-step.html#cb542-26"></a>  <span class="co"># we can access its data and gradients like we did before.</span></span>
<span id="cb542-27"><a href="a-neural-network-step-by-step.html#cb542-27"></a>  <span class="kw">with</span>(torch<span class="op">$</span><span class="kw">no_grad</span>(), {</span>
<span id="cb542-28"><a href="a-neural-network-step-by-step.html#cb542-28"></a>      <span class="cf">for</span> (param <span class="cf">in</span> <span class="kw">iterate</span>(model<span class="op">$</span><span class="kw">parameters</span>())) {</span>
<span id="cb542-29"><a href="a-neural-network-step-by-step.html#cb542-29"></a>        <span class="co"># in Python this code is much simpler. In R we have to do some conversions</span></span>
<span id="cb542-30"><a href="a-neural-network-step-by-step.html#cb542-30"></a>        <span class="co"># param$data &lt;- torch$sub(param$data,</span></span>
<span id="cb542-31"><a href="a-neural-network-step-by-step.html#cb542-31"></a>        <span class="co">#                         torch$mul(param$grad$float(),</span></span>
<span id="cb542-32"><a href="a-neural-network-step-by-step.html#cb542-32"></a>        <span class="co">#                           torch$scalar_tensor(learning_rate)))</span></span>
<span id="cb542-33"><a href="a-neural-network-step-by-step.html#cb542-33"></a>        param<span class="op">$</span>data &lt;-<span class="st"> </span>param<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>param<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span>learning_rate</span>
<span id="cb542-34"><a href="a-neural-network-step-by-step.html#cb542-34"></a>      }</span>
<span id="cb542-35"><a href="a-neural-network-step-by-step.html#cb542-35"></a>   })</span>
<span id="cb542-36"><a href="a-neural-network-step-by-step.html#cb542-36"></a>}  </span></code></pre></div>
<pre><code>#&gt; 1    628 
#&gt; 2    585 
#&gt; 3    547 
#&gt; 4    513 
#&gt; 5    482 
#&gt; 6    455 
#&gt; 7    430 
#&gt; 8    406 
#&gt; 9    385 
#&gt; 10   364 
#&gt; 11   345 
#&gt; 12   328 
#&gt; 13   311 
#&gt; 14   295 
#&gt; 15   280 
#&gt; 16   265 
#&gt; 17   252 
#&gt; 18   239 
#&gt; 19   226 
#&gt; 20   214 
#&gt; 21   203 
#&gt; 22   192 
#&gt; 23   181 
#&gt; 24   172 
#&gt; 25   162 
#&gt; 26   153 
#&gt; 27   145 
#&gt; 28   137 
#&gt; 29   129 
#&gt; 30   122 
#&gt; 31   115 
#&gt; 32   109 
#&gt; 33   103 
#&gt; 34   96.9 
#&gt; 35   91.5 
#&gt; 36   86.3 
#&gt; 37   81.5 
#&gt; 38   76.9 
#&gt; 39   72.6 
#&gt; 40   68.5 
#&gt; 41   64.6 
#&gt; 42   61 
#&gt; 43   57.6 
#&gt; 44   54.3 
#&gt; 45   51.3 
#&gt; 46   48.5 
#&gt; 47   45.8 
#&gt; 48   43.2 
#&gt; 49   40.9 
#&gt; 50   38.6 
#&gt; 51   36.5 
#&gt; 52   34.5 
#&gt; 53   32.7 
#&gt; 54   30.9 
#&gt; 55   29.3 
#&gt; 56   27.8 
#&gt; 57   26.3 
#&gt; 58   24.9 
#&gt; 59   23.7 
#&gt; 60   22.4 
#&gt; 61   21.3 
#&gt; 62   20.2 
#&gt; 63   19.2 
#&gt; 64   18.2 
#&gt; 65   17.3 
#&gt; 66   16.5 
#&gt; 67   15.7 
#&gt; 68   14.9 
#&gt; 69   14.2 
#&gt; 70   13.5 
#&gt; 71   12.9 
#&gt; 72   12.3 
#&gt; 73   11.7 
#&gt; 74   11.1 
#&gt; 75   10.6 
#&gt; 76   10.1 
#&gt; 77   9.67 
#&gt; 78   9.24 
#&gt; 79   8.82 
#&gt; 80   8.42 
#&gt; 81   8.05 
#&gt; 82   7.69 
#&gt; 83   7.35 
#&gt; 84   7.03 
#&gt; 85   6.72 
#&gt; 86   6.43 
#&gt; 87   6.16 
#&gt; 88   5.9 
#&gt; 89   5.65 
#&gt; 90   5.41 
#&gt; 91   5.18 
#&gt; 92   4.97 
#&gt; 93   4.76 
#&gt; 94   4.57 
#&gt; 95   4.38 
#&gt; 96   4.2 
#&gt; 97   4.03 
#&gt; 98   3.87 
#&gt; 99   3.72 
#&gt; 100  3.57 
#&gt; 101  3.43 
#&gt; 102  3.29 
#&gt; 103  3.17 
#&gt; 104  3.04 
#&gt; 105  2.92 
#&gt; 106  2.81 
#&gt; 107  2.7 
#&gt; 108  2.6 
#&gt; 109  2.5 
#&gt; 110  2.41 
#&gt; 111  2.31 
#&gt; 112  2.23 
#&gt; 113  2.14 
#&gt; 114  2.06 
#&gt; 115  1.99 
#&gt; 116  1.91 
#&gt; 117  1.84 
#&gt; 118  1.77 
#&gt; 119  1.71 
#&gt; 120  1.65 
#&gt; 121  1.59 
#&gt; 122  1.53 
#&gt; 123  1.47 
#&gt; 124  1.42 
#&gt; 125  1.37 
#&gt; 126  1.32 
#&gt; 127  1.27 
#&gt; 128  1.23 
#&gt; 129  1.18 
#&gt; 130  1.14 
#&gt; 131  1.1 
#&gt; 132  1.06 
#&gt; 133  1.02 
#&gt; 134  0.989 
#&gt; 135  0.954 
#&gt; 136  0.921 
#&gt; 137  0.889 
#&gt; 138  0.858 
#&gt; 139  0.828 
#&gt; 140  0.799 
#&gt; 141  0.772 
#&gt; 142  0.745 
#&gt; 143  0.719 
#&gt; 144  0.695 
#&gt; 145  0.671 
#&gt; 146  0.648 
#&gt; 147  0.626 
#&gt; 148  0.605 
#&gt; 149  0.584 
#&gt; 150  0.564 
#&gt; 151  0.545 
#&gt; 152  0.527 
#&gt; 153  0.509 
#&gt; 154  0.492 
#&gt; 155  0.476 
#&gt; 156  0.46 
#&gt; 157  0.444 
#&gt; 158  0.43 
#&gt; 159  0.415 
#&gt; 160  0.402 
#&gt; 161  0.388 
#&gt; 162  0.375 
#&gt; 163  0.363 
#&gt; 164  0.351 
#&gt; 165  0.339 
#&gt; 166  0.328 
#&gt; 167  0.318 
#&gt; 168  0.307 
#&gt; 169  0.297 
#&gt; 170  0.287 
#&gt; 171  0.278 
#&gt; 172  0.269 
#&gt; 173  0.26 
#&gt; 174  0.252 
#&gt; 175  0.244 
#&gt; 176  0.236 
#&gt; 177  0.228 
#&gt; 178  0.221 
#&gt; 179  0.214 
#&gt; 180  0.207 
#&gt; 181  0.2 
#&gt; 182  0.194 
#&gt; 183  0.187 
#&gt; 184  0.181 
#&gt; 185  0.176 
#&gt; 186  0.17 
#&gt; 187  0.165 
#&gt; 188  0.159 
#&gt; 189  0.154 
#&gt; 190  0.149 
#&gt; 191  0.145 
#&gt; 192  0.14 
#&gt; 193  0.136 
#&gt; 194  0.131 
#&gt; 195  0.127 
#&gt; 196  0.123 
#&gt; 197  0.119 
#&gt; 198  0.115 
#&gt; 199  0.112 
#&gt; 200  0.108 
#&gt; 201  0.105 
#&gt; 202  0.102 
#&gt; 203  0.0983 
#&gt; 204  0.0952 
#&gt; 205  0.0923 
#&gt; 206  0.0894 
#&gt; 207  0.0866 
#&gt; 208  0.0838 
#&gt; 209  0.0812 
#&gt; 210  0.0787 
#&gt; 211  0.0762 
#&gt; 212  0.0739 
#&gt; 213  0.0716 
#&gt; 214  0.0693 
#&gt; 215  0.0672 
#&gt; 216  0.0651 
#&gt; 217  0.0631 
#&gt; 218  0.0611 
#&gt; 219  0.0592 
#&gt; 220  0.0574 
#&gt; 221  0.0556 
#&gt; 222  0.0539 
#&gt; 223  0.0522 
#&gt; 224  0.0506 
#&gt; 225  0.0491 
#&gt; 226  0.0476 
#&gt; 227  0.0461 
#&gt; 228  0.0447 
#&gt; 229  0.0433 
#&gt; 230  0.042 
#&gt; 231  0.0407 
#&gt; 232  0.0394 
#&gt; 233  0.0382 
#&gt; 234  0.0371 
#&gt; 235  0.0359 
#&gt; 236  0.0348 
#&gt; 237  0.0338 
#&gt; 238  0.0327 
#&gt; 239  0.0317 
#&gt; 240  0.0308 
#&gt; 241  0.0298 
#&gt; 242  0.0289 
#&gt; 243  0.028 
#&gt; 244  0.0272 
#&gt; 245  0.0263 
#&gt; 246  0.0255 
#&gt; 247  0.0248 
#&gt; 248  0.024 
#&gt; 249  0.0233 
#&gt; 250  0.0226 
#&gt; 251  0.0219 
#&gt; 252  0.0212 
#&gt; 253  0.0206 
#&gt; 254  0.02 
#&gt; 255  0.0194 
#&gt; 256  0.0188 
#&gt; 257  0.0182 
#&gt; 258  0.0177 
#&gt; 259  0.0171 
#&gt; 260  0.0166 
#&gt; 261  0.0161 
#&gt; 262  0.0156 
#&gt; 263  0.0151 
#&gt; 264  0.0147 
#&gt; 265  0.0142 
#&gt; 266  0.0138 
#&gt; 267  0.0134 
#&gt; 268  0.013 
#&gt; 269  0.0126 
#&gt; 270  0.0122 
#&gt; 271  0.0119 
#&gt; 272  0.0115 
#&gt; 273  0.0112 
#&gt; 274  0.0108 
#&gt; 275  0.0105 
#&gt; 276  0.0102 
#&gt; 277  0.00988 
#&gt; 278  0.00959 
#&gt; 279  0.0093 
#&gt; 280  0.00902 
#&gt; 281  0.00875 
#&gt; 282  0.00849 
#&gt; 283  0.00824 
#&gt; 284  0.00799 
#&gt; 285  0.00775 
#&gt; 286  0.00752 
#&gt; 287  0.0073 
#&gt; 288  0.00708 
#&gt; 289  0.00687 
#&gt; 290  0.00666 
#&gt; 291  0.00647 
#&gt; 292  0.00627 
#&gt; 293  0.00609 
#&gt; 294  0.00591 
#&gt; 295  0.00573 
#&gt; 296  0.00556 
#&gt; 297  0.0054 
#&gt; 298  0.00524 
#&gt; 299  0.00508 
#&gt; 300  0.00493 
#&gt; 301  0.00478 
#&gt; 302  0.00464 
#&gt; 303  0.0045 
#&gt; 304  0.00437 
#&gt; 305  0.00424 
#&gt; 306  0.00412 
#&gt; 307  0.00399 
#&gt; 308  0.00388 
#&gt; 309  0.00376 
#&gt; 310  0.00365 
#&gt; 311  0.00354 
#&gt; 312  0.00344 
#&gt; 313  0.00334 
#&gt; 314  0.00324 
#&gt; 315  0.00314 
#&gt; 316  0.00305 
#&gt; 317  0.00296 
#&gt; 318  0.00287 
#&gt; 319  0.00279 
#&gt; 320  0.00271 
#&gt; 321  0.00263 
#&gt; 322  0.00255 
#&gt; 323  0.00248 
#&gt; 324  0.0024 
#&gt; 325  0.00233 
#&gt; 326  0.00226 
#&gt; 327  0.0022 
#&gt; 328  0.00213 
#&gt; 329  0.00207 
#&gt; 330  0.00201 
#&gt; 331  0.00195 
#&gt; 332  0.00189 
#&gt; 333  0.00184 
#&gt; 334  0.00178 
#&gt; 335  0.00173 
#&gt; 336  0.00168 
#&gt; 337  0.00163 
#&gt; 338  0.00158 
#&gt; 339  0.00154 
#&gt; 340  0.00149 
#&gt; 341  0.00145 
#&gt; 342  0.00141 
#&gt; 343  0.00137 
#&gt; 344  0.00133 
#&gt; 345  0.00129 
#&gt; 346  0.00125 
#&gt; 347  0.00121 
#&gt; 348  0.00118 
#&gt; 349  0.00114 
#&gt; 350  0.00111 
#&gt; 351  0.00108 
#&gt; 352  0.00105 
#&gt; 353  0.00102 
#&gt; 354  0.000987 
#&gt; 355  0.000958 
#&gt; 356  0.000931 
#&gt; 357  0.000904 
#&gt; 358  0.000877 
#&gt; 359  0.000852 
#&gt; 360  0.000827 
#&gt; 361  0.000803 
#&gt; 362  0.00078 
#&gt; 363  0.000757 
#&gt; 364  0.000735 
#&gt; 365  0.000714 
#&gt; 366  0.000693 
#&gt; 367  0.000673 
#&gt; 368  0.000654 
#&gt; 369  0.000635 
#&gt; 370  0.000617 
#&gt; 371  0.000599 
#&gt; 372  0.000581 
#&gt; 373  0.000565 
#&gt; 374  0.000548 
#&gt; 375  0.000532 
#&gt; 376  0.000517 
#&gt; 377  0.000502 
#&gt; 378  0.000488 
#&gt; 379  0.000474 
#&gt; 380  0.00046 
#&gt; 381  0.000447 
#&gt; 382  0.000434 
#&gt; 383  0.000421 
#&gt; 384  0.000409 
#&gt; 385  0.000397 
#&gt; 386  0.000386 
#&gt; 387  0.000375 
#&gt; 388  0.000364 
#&gt; 389  0.000354 
#&gt; 390  0.000343 
#&gt; 391  0.000334 
#&gt; 392  0.000324 
#&gt; 393  0.000315 
#&gt; 394  0.000306 
#&gt; 395  0.000297 
#&gt; 396  0.000288 
#&gt; 397  0.00028 
#&gt; 398  0.000272 
#&gt; 399  0.000264 
#&gt; 400  0.000257 
#&gt; 401  0.000249 
#&gt; 402  0.000242 
#&gt; 403  0.000235 
#&gt; 404  0.000228 
#&gt; 405  0.000222 
#&gt; 406  0.000216 
#&gt; 407  0.000209 
#&gt; 408  0.000203 
#&gt; 409  0.000198 
#&gt; 410  0.000192 
#&gt; 411  0.000186 
#&gt; 412  0.000181 
#&gt; 413  0.000176 
#&gt; 414  0.000171 
#&gt; 415  0.000166 
#&gt; 416  0.000161 
#&gt; 417  0.000157 
#&gt; 418  0.000152 
#&gt; 419  0.000148 
#&gt; 420  0.000144 
#&gt; 421  0.00014 
#&gt; 422  0.000136 
#&gt; 423  0.000132 
#&gt; 424  0.000128 
#&gt; 425  0.000124 
#&gt; 426  0.000121 
#&gt; 427  0.000117 
#&gt; 428  0.000114 
#&gt; 429  0.000111 
#&gt; 430  0.000108 
#&gt; 431  0.000105 
#&gt; 432  0.000102 
#&gt; 433  9.87e-05 
#&gt; 434  9.59e-05 
#&gt; 435  9.32e-05 
#&gt; 436  9.06e-05 
#&gt; 437  8.8e-05 
#&gt; 438  8.55e-05 
#&gt; 439  8.31e-05 
#&gt; 440  8.07e-05 
#&gt; 441  7.84e-05 
#&gt; 442  7.62e-05 
#&gt; 443  7.4e-05 
#&gt; 444  7.2e-05 
#&gt; 445  6.99e-05 
#&gt; 446  6.79e-05 
#&gt; 447  6.6e-05 
#&gt; 448  6.41e-05 
#&gt; 449  6.23e-05 
#&gt; 450  6.06e-05 
#&gt; 451  5.89e-05 
#&gt; 452  5.72e-05 
#&gt; 453  5.56e-05 
#&gt; 454  5.4e-05 
#&gt; 455  5.25e-05 
#&gt; 456  5.1e-05 
#&gt; 457  4.96e-05 
#&gt; 458  4.82e-05 
#&gt; 459  4.68e-05 
#&gt; 460  4.55e-05 
#&gt; 461  4.42e-05 
#&gt; 462  4.3e-05 
#&gt; 463  4.18e-05 
#&gt; 464  4.06e-05 
#&gt; 465  3.94e-05 
#&gt; 466  3.83e-05 
#&gt; 467  3.72e-05 
#&gt; 468  3.62e-05 
#&gt; 469  3.52e-05 
#&gt; 470  3.42e-05 
#&gt; 471  3.32e-05 
#&gt; 472  3.23e-05 
#&gt; 473  3.14e-05 
#&gt; 474  3.05e-05 
#&gt; 475  2.96e-05 
#&gt; 476  2.88e-05 
#&gt; 477  2.8e-05 
#&gt; 478  2.72e-05 
#&gt; 479  2.65e-05 
#&gt; 480  2.57e-05 
#&gt; 481  2.5e-05 
#&gt; 482  2.43e-05 
#&gt; 483  2.36e-05 
#&gt; 484  2.29e-05 
#&gt; 485  2.23e-05 
#&gt; 486  2.17e-05 
#&gt; 487  2.11e-05 
#&gt; 488  2.05e-05 
#&gt; 489  1.99e-05 
#&gt; 490  1.94e-05 
#&gt; 491  1.88e-05 
#&gt; 492  1.83e-05 
#&gt; 493  1.78e-05 
#&gt; 494  1.73e-05 
#&gt; 495  1.68e-05 
#&gt; 496  1.63e-05 
#&gt; 497  1.59e-05 
#&gt; 498  1.54e-05 
#&gt; 499  1.5e-05 
#&gt; 500  1.46e-05</code></pre>
</div>
<div id="using-r-generics" class="section level2">
<h2><span class="header-section-number">13.7</span> Using R generics</h2>
<div id="simplify-tensor-operations" class="section level3">
<h3><span class="header-section-number">13.7.1</span> Simplify tensor operations</h3>
<p>The following two expressions are equivalent, with the first being the long version natural way of doing it in <strong>PyTorch</strong>. The second is using the generics in R for subtraction, multiplication and scalar conversion.</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="a-neural-network-step-by-step.html#cb544-1"></a>param<span class="op">$</span>data &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">sub</span>(param<span class="op">$</span>data,</span>
<span id="cb544-2"><a href="a-neural-network-step-by-step.html#cb544-2"></a>                        torch<span class="op">$</span><span class="kw">mul</span>(param<span class="op">$</span>grad<span class="op">$</span><span class="kw">float</span>(),</span>
<span id="cb544-3"><a href="a-neural-network-step-by-step.html#cb544-3"></a>                          torch<span class="op">$</span><span class="kw">scalar_tensor</span>(learning_rate)))</span></code></pre></div>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="a-neural-network-step-by-step.html#cb545-1"></a>param<span class="op">$</span>data &lt;-<span class="st"> </span>param<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>param<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span>learning_rate</span></code></pre></div>
</div>
</div>
<div id="an-elegant-neural-network" class="section level2">
<h2><span class="header-section-number">13.8</span> An elegant neural network</h2>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="a-neural-network-step-by-step.html#cb546-1"></a><span class="kw">invisible</span>(torch<span class="op">$</span><span class="kw">manual_seed</span>(<span class="dv">0</span>))   <span class="co"># do not show the generator output</span></span>
<span id="cb546-2"><a href="a-neural-network-step-by-step.html#cb546-2"></a><span class="co"># layer properties</span></span>
<span id="cb546-3"><a href="a-neural-network-step-by-step.html#cb546-3"></a>N &lt;-<span class="st"> </span>64L; D_in &lt;-<span class="st"> </span>1000L; H &lt;-<span class="st"> </span>100L; D_out &lt;-<span class="st"> </span>10L</span>
<span id="cb546-4"><a href="a-neural-network-step-by-step.html#cb546-4"></a></span>
<span id="cb546-5"><a href="a-neural-network-step-by-step.html#cb546-5"></a><span class="co"># Create random Tensors to hold inputs and outputs</span></span>
<span id="cb546-6"><a href="a-neural-network-step-by-step.html#cb546-6"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(N, D_in, <span class="dt">device=</span>device)</span>
<span id="cb546-7"><a href="a-neural-network-step-by-step.html#cb546-7"></a>y =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(N, D_out, <span class="dt">device=</span>device)</span>
<span id="cb546-8"><a href="a-neural-network-step-by-step.html#cb546-8"></a></span>
<span id="cb546-9"><a href="a-neural-network-step-by-step.html#cb546-9"></a><span class="co"># set up the neural network</span></span>
<span id="cb546-10"><a href="a-neural-network-step-by-step.html#cb546-10"></a>model &lt;-<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Sequential</span>(</span>
<span id="cb546-11"><a href="a-neural-network-step-by-step.html#cb546-11"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(D_in, H),              <span class="co"># first layer</span></span>
<span id="cb546-12"><a href="a-neural-network-step-by-step.html#cb546-12"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">ReLU</span>(),                       <span class="co"># activation</span></span>
<span id="cb546-13"><a href="a-neural-network-step-by-step.html#cb546-13"></a>  torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(H, D_out))<span class="op">$</span><span class="kw">to</span>(device)  <span class="co"># output layer</span></span>
<span id="cb546-14"><a href="a-neural-network-step-by-step.html#cb546-14"></a></span>
<span id="cb546-15"><a href="a-neural-network-step-by-step.html#cb546-15"></a><span class="co"># specify how we will be computing the loss</span></span>
<span id="cb546-16"><a href="a-neural-network-step-by-step.html#cb546-16"></a>loss_fn =<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">MSELoss</span>(<span class="dt">reduction =</span> <span class="st">&#39;sum&#39;</span>)</span>
<span id="cb546-17"><a href="a-neural-network-step-by-step.html#cb546-17"></a></span>
<span id="cb546-18"><a href="a-neural-network-step-by-step.html#cb546-18"></a>learning_rate =<span class="st"> </span><span class="fl">1e-4</span></span>
<span id="cb546-19"><a href="a-neural-network-step-by-step.html#cb546-19"></a>loss_row &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">vector</span>())     <span class="co"># collect a list for the final dataframe</span></span>
<span id="cb546-20"><a href="a-neural-network-step-by-step.html#cb546-20"></a></span>
<span id="cb546-21"><a href="a-neural-network-step-by-step.html#cb546-21"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">500</span>) {</span>
<span id="cb546-22"><a href="a-neural-network-step-by-step.html#cb546-22"></a>  <span class="co"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span>
<span id="cb546-23"><a href="a-neural-network-step-by-step.html#cb546-23"></a>  <span class="co"># override the __call__ operator so you can call them like functions. When</span></span>
<span id="cb546-24"><a href="a-neural-network-step-by-step.html#cb546-24"></a>  <span class="co"># doing so you pass a Tensor of input data to the Module and it produces</span></span>
<span id="cb546-25"><a href="a-neural-network-step-by-step.html#cb546-25"></a>  <span class="co"># a Tensor of output data.</span></span>
<span id="cb546-26"><a href="a-neural-network-step-by-step.html#cb546-26"></a>  y_pred =<span class="st"> </span><span class="kw">model</span>(x)</span>
<span id="cb546-27"><a href="a-neural-network-step-by-step.html#cb546-27"></a></span>
<span id="cb546-28"><a href="a-neural-network-step-by-step.html#cb546-28"></a>  <span class="co"># Compute and print loss. We pass Tensors containing the predicted and true</span></span>
<span id="cb546-29"><a href="a-neural-network-step-by-step.html#cb546-29"></a>  <span class="co"># values of y, and the loss function returns a Tensor containing the loss.</span></span>
<span id="cb546-30"><a href="a-neural-network-step-by-step.html#cb546-30"></a>  loss =<span class="st"> </span><span class="kw">loss_fn</span>(y_pred, y)  <span class="co"># (y_pred - y) is a tensor; loss_fn output is a scalar</span></span>
<span id="cb546-31"><a href="a-neural-network-step-by-step.html#cb546-31"></a>  loss_row[[t]] &lt;-<span class="st"> </span><span class="kw">c</span>(t, loss<span class="op">$</span><span class="kw">item</span>())</span>
<span id="cb546-32"><a href="a-neural-network-step-by-step.html#cb546-32"></a>  </span>
<span id="cb546-33"><a href="a-neural-network-step-by-step.html#cb546-33"></a>  <span class="co"># Zero the gradients before running the backward pass.</span></span>
<span id="cb546-34"><a href="a-neural-network-step-by-step.html#cb546-34"></a>  model<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb546-35"><a href="a-neural-network-step-by-step.html#cb546-35"></a></span>
<span id="cb546-36"><a href="a-neural-network-step-by-step.html#cb546-36"></a>  <span class="co"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span>
<span id="cb546-37"><a href="a-neural-network-step-by-step.html#cb546-37"></a>  <span class="co"># parameters of the model. Internally, the parameters of each module are stored</span></span>
<span id="cb546-38"><a href="a-neural-network-step-by-step.html#cb546-38"></a>  <span class="co"># in tensors with `requires_grad=True`, so this call will compute gradients for</span></span>
<span id="cb546-39"><a href="a-neural-network-step-by-step.html#cb546-39"></a>  <span class="co"># all learnable parameters in the model.</span></span>
<span id="cb546-40"><a href="a-neural-network-step-by-step.html#cb546-40"></a>  loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb546-41"><a href="a-neural-network-step-by-step.html#cb546-41"></a></span>
<span id="cb546-42"><a href="a-neural-network-step-by-step.html#cb546-42"></a>  <span class="co"># Update the weights using gradient descent. Each parameter is a tensor, so</span></span>
<span id="cb546-43"><a href="a-neural-network-step-by-step.html#cb546-43"></a>  <span class="co"># we can access its data and gradients like we did before.</span></span>
<span id="cb546-44"><a href="a-neural-network-step-by-step.html#cb546-44"></a>  <span class="kw">with</span>(torch<span class="op">$</span><span class="kw">no_grad</span>(), {</span>
<span id="cb546-45"><a href="a-neural-network-step-by-step.html#cb546-45"></a>      <span class="cf">for</span> (param <span class="cf">in</span> <span class="kw">iterate</span>(model<span class="op">$</span><span class="kw">parameters</span>())) {</span>
<span id="cb546-46"><a href="a-neural-network-step-by-step.html#cb546-46"></a>        <span class="co"># using R generics</span></span>
<span id="cb546-47"><a href="a-neural-network-step-by-step.html#cb546-47"></a>        param<span class="op">$</span>data &lt;-<span class="st"> </span>param<span class="op">$</span>data <span class="op">-</span><span class="st"> </span>param<span class="op">$</span>grad <span class="op">*</span><span class="st"> </span>learning_rate</span>
<span id="cb546-48"><a href="a-neural-network-step-by-step.html#cb546-48"></a>      }</span>
<span id="cb546-49"><a href="a-neural-network-step-by-step.html#cb546-49"></a>   })</span>
<span id="cb546-50"><a href="a-neural-network-step-by-step.html#cb546-50"></a>}  </span></code></pre></div>
</div>
<div id="a-browseable-dataframe" class="section level2">
<h2><span class="header-section-number">13.9</span> A browseable dataframe</h2>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="a-neural-network-step-by-step.html#cb547-1"></a><span class="kw">library</span>(DT)</span>
<span id="cb547-2"><a href="a-neural-network-step-by-step.html#cb547-2"></a>loss_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">Reduce</span>(rbind, loss_row), <span class="dt">row.names =</span> <span class="ot">NULL</span>)</span>
<span id="cb547-3"><a href="a-neural-network-step-by-step.html#cb547-3"></a><span class="kw">names</span>(loss_df)[<span class="dv">1</span>] &lt;-<span class="st"> &quot;iter&quot;</span></span>
<span id="cb547-4"><a href="a-neural-network-step-by-step.html#cb547-4"></a><span class="kw">names</span>(loss_df)[<span class="dv">2</span>] &lt;-<span class="st"> &quot;loss&quot;</span></span>
<span id="cb547-5"><a href="a-neural-network-step-by-step.html#cb547-5"></a>DT<span class="op">::</span><span class="kw">datatable</span>(loss_df)</span></code></pre></div>
<div id="htmlwidget-1b4ff99564eb6e8884a5" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1b4ff99564eb6e8884a5">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301","302","303","304","305","306","307","308","309","310","311","312","313","314","315","316","317","318","319","320","321","322","323","324","325","326","327","328","329","330","331","332","333","334","335","336","337","338","339","340","341","342","343","344","345","346","347","348","349","350","351","352","353","354","355","356","357","358","359","360","361","362","363","364","365","366","367","368","369","370","371","372","373","374","375","376","377","378","379","380","381","382","383","384","385","386","387","388","389","390","391","392","393","394","395","396","397","398","399","400","401","402","403","404","405","406","407","408","409","410","411","412","413","414","415","416","417","418","419","420","421","422","423","424","425","426","427","428","429","430","431","432","433","434","435","436","437","438","439","440","441","442","443","444","445","446","447","448","449","450","451","452","453","454","455","456","457","458","459","460","461","462","463","464","465","466","467","468","469","470","471","472","473","474","475","476","477","478","479","480","481","482","483","484","485","486","487","488","489","490","491","492","493","494","495","496","497","498","499","500"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],[628.283874511719,584.959289550781,546.727966308594,512.688537597656,482.130554199219,454.626525878906,429.55517578125,406.398956298828,384.64404296875,364.312469482422,345.386596679688,327.625793457031,310.800231933594,294.837890625,279.732452392578,265.307952880859,251.623046875,238.536041259766,226.023147583008,214.102508544922,202.700271606445,191.805923461914,181.447341918945,171.594848632812,162.211395263672,153.292221069336,144.852615356445,136.859939575195,129.278610229492,122.084869384766,115.273597717285,108.814483642578,102.702018737793,96.928092956543,91.4746704101562,86.3277969360352,81.4750137329102,76.8914489746094,72.5689468383789,68.4777374267578,64.6260833740234,60.9971504211426,57.569149017334,54.3426971435547,51.3091125488281,48.4516296386719,45.7645149230957,43.2405242919922,40.8660736083984,38.6300811767578,36.5252914428711,34.5491638183594,32.6934509277344,30.9498176574707,29.3073463439941,27.7627716064453,26.310905456543,24.94309425354,23.65380859375,22.4388256072998,21.2925815582275,20.2127914428711,19.1928825378418,18.2330322265625,17.32932472229,16.4769058227539,15.6711559295654,14.9095163345337,14.1905403137207,13.51087474823,12.8681945800781,12.2604608535767,11.685152053833,11.1410474777222,10.6257915496826,10.1372718811035,9.67442607879639,9.23574733734131,8.81936073303223,8.423415184021,8.0479793548584,7.69129371643066,7.3524055480957,7.03039932250977,6.72467756271362,6.43443441390991,6.15827894210815,5.89544296264648,5.64577484130859,5.4085898399353,5.18278884887695,4.96778297424316,4.76282262802124,4.56794261932373,4.38167667388916,4.20395755767822,4.034255027771,3.87236881256104,3.7176661491394,3.56985235214233,3.42879033088684,3.29393482208252,3.1650059223175,3.04172992706299,2.92383289337158,2.8109929561615,2.70296669006348,2.5995466709137,2.50053334236145,2.40561032295227,2.31467843055725,2.22756838798523,2.14398527145386,2.06382441520691,1.98689556121826,1.91316115856171,1.84239768981934,1.77456092834473,1.70933353900909,1.64674973487854,1.58666336536407,1.52893197536469,1.47349846363068,1.42019391059875,1.36904418468475,1.31993734836578,1.27271342277527,1.22735118865967,1.18371605873108,1.14171314239502,1.10128891468048,1.06237864494324,1.02497482299805,0.9889817237854,0.95431661605835,0.920958697795868,0.888810038566589,0.857857048511505,0.828074038028717,0.799380540847778,0.771741092205048,0.745122790336609,0.719462692737579,0.694717228412628,0.670871675014496,0.647948026657104,0.625913023948669,0.604666292667389,0.584196388721466,0.564445912837982,0.545387148857117,0.527021527290344,0.509311974048615,0.4922194480896,0.47573059797287,0.459827750921249,0.444491237401962,0.429690569639206,0.415387392044067,0.40159210562706,0.388279020786285,0.375434100627899,0.363029330968857,0.35105288028717,0.339493781328201,0.328329622745514,0.317552447319031,0.307137221097946,0.297078490257263,0.287366539239883,0.277984440326691,0.268914103507996,0.260156899690628,0.251694798469543,0.243515461683273,0.235606402158737,0.227970317006111,0.220615655183792,0.213502466678619,0.206627368927002,0.19998787343502,0.193573549389839,0.187366172671318,0.181365713477135,0.175562530755997,0.169950991868973,0.16452294588089,0.159277930855751,0.154206499457359,0.149300888180733,0.144553974270821,0.139964535832405,0.135524183511734,0.131227552890778,0.127071633934975,0.123050883412361,0.119162112474442,0.115398794412613,0.111758626997471,0.108234480023384,0.104825533926487,0.101525321602821,0.0983332097530365,0.0952441319823265,0.092253103852272,0.0893576741218567,0.0865568742156029,0.0838496387004852,0.0812318399548531,0.0786957666277885,0.0762432739138603,0.0738693326711655,0.0715707764029503,0.0693463534116745,0.0671909749507904,0.0651053339242935,0.0630877539515495,0.0611334443092346,0.0592397749423981,0.0574058853089809,0.0556300282478333,0.0539103336632252,0.0522454231977463,0.0506339073181152,0.0490731671452522,0.0475621670484543,0.0460991337895393,0.0446819961071014,0.0433073565363884,0.0419757328927517,0.0406862944364548,0.0394376255571842,0.0382279492914677,0.0370563454926014,0.0359213463962078,0.0348213985562325,0.0337561704218388,0.0327244810760021,0.0317247584462166,0.030755840241909,0.0298167951405048,0.0289072245359421,0.0280260629951954,0.0271728727966547,0.0263454802334309,0.0255436822772026,0.0247666668146849,0.024014201015234,0.0232851449400187,0.0225782487541437,0.0218929927796125,0.021229138597846,0.0205857437103987,0.0199623163789511,0.0193577408790588,0.0187720693647861,0.0182042922824621,0.0176538955420256,0.0171204283833504,0.0166035108268261,0.0161023829132318,0.0156170753762126,0.0151462182402611,0.0146900489926338,0.0142474789172411,0.0138185834512115,0.0134028671309352,0.0129999183118343,0.0126090021803975,0.0122300619259477,0.0118627417832613,0.0115067670121789,0.0111616086214781,0.0108267990872264,0.0105021754279733,0.0101879462599754,0.00988284964114428,0.00958701968193054,0.00930015556514263,0.00902190059423447,0.00875221751630306,0.00849072355777025,0.00823704525828362,0.00799110066145658,0.00775274494662881,0.00752145890146494,0.00729728769510984,0.00707977823913097,0.00686886580660939,0.00666445214301348,0.00646621733903885,0.00627401378005743,0.00608737720176578,0.00590644683688879,0.00573085807263851,0.0055606896057725,0.00539560476318002,0.00523549551144242,0.00508022122085094,0.00492965802550316,0.00478361127898097,0.00464196549728513,0.00450445152819157,0.00437118066474795,0.00424178829416633,0.00411629024893045,0.00399459106847644,0.00387655268423259,0.00376211386173964,0.00365100242197514,0.00354327633976936,0.00343872653320432,0.00333727174438536,0.00323886075057089,0.00314340041950345,0.00305079785175622,0.00296098948456347,0.0028738162945956,0.00278921681456268,0.00270719011314213,0.00262756505981088,0.00255030859261751,0.00247536064125597,0.00240262248553336,0.00233207480050623,0.00226361863315105,0.00219722441397607,0.00213277456350625,0.00207025348208845,0.00200955709442496,0.00195070076733828,0.00189359067007899,0.00183812959585339,0.00178428704384714,0.00173210655339062,0.00168142572510988,0.00163229065947235,0.00158459157682955,0.00153828307520598,0.00149334024172276,0.00144973606802523,0.00140743353404105,0.00136640947312117,0.00132654793560505,0.00128783995751292,0.00125031580682844,0.0012138836318627,0.00117850385140628,0.00114419125020504,0.00111087993718684,0.00107855198439211,0.00104718515649438,0.00101672357413918,0.000987160135991871,0.000958467135205865,0.000930605630856007,0.000903585867490619,0.000877335842233151,0.000851894845254719,0.000827192387077957,0.000803192786406726,0.000779891153797507,0.000757286907173693,0.000735332549083978,0.000714045600034297,0.000693372450768948,0.000673287024255842,0.000653798750136048,0.000634883297607303,0.000616518955212086,0.000598690297920257,0.000581372412852943,0.000564583344385028,0.000548257492482662,0.000532434321939945,0.000517066335305572,0.000502136303111911,0.000487654033349827,0.000473582389531657,0.000459915958344936,0.000446654710685834,0.000433788838563487,0.000421288190409541,0.000409158878028393,0.0003973804123234,0.000385941122658551,0.000374841445591301,0.000364052131772041,0.000353573705069721,0.000343408260960132,0.00033354019979015,0.000323963875416666,0.000314654054818675,0.000305617926642299,0.00029684163746424,0.000288320414256305,0.000280042469967157,0.000272016652161255,0.000264211179455742,0.000256636907579377,0.000249282165896147,0.000242136855376884,0.000235196464927867,0.000228469507419504,0.000221923721255735,0.000215571082662791,0.00020940754620824,0.000203419767785817,0.000197598259546794,0.000191947096027434,0.000186454359209165,0.000181138180778362,0.000175959954503924,0.000170937855727971,0.000166058729519136,0.000161318763275631,0.000156715832417831,0.000152243199408986,0.000147900223964825,0.000143682380439714,0.000139584793942049,0.000135608483105898,0.000131745633552782,0.00012799448450096,0.000124349695397541,0.000120808712381404,0.000117372692329809,0.00011403467215132,0.000110786000732332,0.000107634958112612,0.000104573773569427,0.000101601093774661,9.8721677204594e-05,9.59186290856451e-05,9.32002149056643e-05,9.05551132746041e-05,8.79877770785242e-05,8.54965037433431e-05,8.3069535321556e-05,8.07150354376063e-05,7.84298099461012e-05,7.62071722419932e-05,7.40465184208006e-05,7.19509407645091e-05,6.99149532010779e-05,6.7937231506221e-05,6.60145524307154e-05,6.41479637124576e-05,6.23342202743515e-05,6.05726090725511e-05,5.88608891121112e-05,5.71999989915639e-05,5.55833394173533e-05,5.40162291144952e-05,5.24887218489312e-05,5.10077697981615e-05,4.95671047247015e-05,4.81654424220324e-05,4.68105063191615e-05,4.54920227639377e-05,4.42101554654073e-05,4.29607389378361e-05,4.17523551732302e-05,4.05779937864281e-05,3.94342314393725e-05,3.83241822419222e-05,3.72479225916322e-05,3.61980746674817e-05,3.51797971234191e-05,3.41916129400488e-05,3.32262679876294e-05,3.22919986501802e-05,3.13873752020299e-05,3.05041248793714e-05,2.96475081995595e-05,2.88136052404298e-05,2.80066851701122e-05,2.7218211471336e-05,2.64570189756341e-05,2.57146512012696e-05,2.49926233664155e-05,2.42910955421394e-05,2.36112318816595e-05,2.29497436521342e-05,2.23050792556023e-05,2.1680687495973e-05,2.10733996937051e-05,2.04816551558906e-05,1.99101468751905e-05,1.93514588318067e-05,1.88111043826211e-05,1.82838848559186e-05,1.7774073057808e-05,1.72761829162482e-05,1.67938087543007e-05,1.6324356693076e-05,1.58670663950033e-05,1.54242698044982e-05,1.49925199366407e-05,1.45731628435897e-05]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>iter<\/th>\n      <th>loss<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="plot-the-loss-at-each-iteration" class="section level2">
<h2><span class="header-section-number">13.10</span> Plot the loss at each iteration</h2>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="a-neural-network-step-by-step.html#cb548-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb548-2"><a href="a-neural-network-step-by-step.html#cb548-2"></a><span class="co"># plot</span></span>
<span id="cb548-3"><a href="a-neural-network-step-by-step.html#cb548-3"></a><span class="kw">ggplot</span>(loss_df, <span class="kw">aes</span>(<span class="dt">x =</span> iter, <span class="dt">y =</span> loss)) <span class="op">+</span></span>
<span id="cb548-4"><a href="a-neural-network-step-by-step.html#cb548-4"></a><span class="st">    </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="0502-neural_networks-steps_files/figure-html/plot-loss-1.png" width="70%" style="display: block; margin: auto;" /></p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="neural-networks.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="working-with-a-data-frame.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/f0nzie/rtorch-minimal-book/edit/main/0502-neural_networks-steps.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

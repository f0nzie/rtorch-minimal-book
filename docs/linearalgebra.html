<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Linear Algebra with Torch | A Minimal rTorch Book</title>
  <meta name="description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Linear Algebra with Torch | A Minimal rTorch Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Linear Algebra with Torch | A Minimal rTorch Book" />
  
  <meta name="twitter:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2020-10-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tensors.html"/>
<link rel="next" href="mnistdigits.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
      // R show code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('show');
      });
      // Python show code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('show');
      });    
  });
  $("#rmd-hide-all-code").click(function() {
      // close the dropdown menu when an option is clicked
      $("#allCodeButton").dropdown("toggle");
      // Hide R code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Python code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('hide');
      });
  });

  // index for unique code element ids
  var r_currentIndex  = 1;   // for R code
  var py_currentIndex = 1;   // for Python code

  // select Python chunks
  var pyCodeBlocks = $('pre.python');
  pyCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse py-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'pycode-643E0F36' + py_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#ebfaeb');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Python code' : 'Python code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#009900');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Python code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Python code');
    });  
   });
  

  // select all R code blocks
  // var rCodeBlocks = $('pre.sourceCode, pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  // adding pre.sourceCode confuses the Python button
  var rCodeBlocks = $('pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + r_currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#e6faff'); // change color of chunk background

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide R code' : 'R code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);
    
    // change the background color of the button        
    showCodeButton.css('background-color','#0000ff');
    
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('R code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide R code');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  // show code by default. Use "show" === "hide" to hide
  window.initializeCodeFolding("show" === "show");
});
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biomarker atopo analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#callable-pytorch-modules"><i class="fa fa-check"></i><b>1.4</b> Callable PyTorch modules</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.4.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.4.2</b> <code>np</code>: the <code>numpy</code> module</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#create-an-array"><i class="fa fa-check"></i>Create an array</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#reshape-an-array"><i class="fa fa-check"></i>Reshape an array</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#generate-a-random-array"><i class="fa fa-check"></i>Generate a random array</a></li>
<li><a href="intro.html#convert-a-numpy-array-to-a-pytorch-tensor">Convert a <code>numpy</code> array to a PyTorch tensor</a></li>
</ul></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.4.3</b> Python built-in functions</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#length-of-a-dataset"><i class="fa fa-check"></i>Length of a dataset</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#iterators"><i class="fa fa-check"></i>Iterators</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#types-and-instances"><i class="fa fa-check"></i>Types and instances</a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>2</b> rTorch vs PyTorch: Whatâ€™s different</a><ul>
<li class="chapter" data-level="2.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>2.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="2.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-a-module-from-pytorch"><i class="fa fa-check"></i><b>2.2</b> Call a module from PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>2.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="2.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>2.4</b> Enumeration</a></li>
<li class="chapter" data-level="2.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate"><i class="fa fa-check"></i><b>2.5</b> How to iterate</a><ul>
<li class="chapter" data-level="2.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>2.5.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>2.5.2</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>2.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="2.6.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>2.6.1</b> Version in Python</a></li>
<li class="chapter" data-level="2.6.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#transform-a-tensor"><i class="fa fa-check"></i><b>2.7</b> Transform a tensor</a></li>
<li class="chapter" data-level="2.8" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#build-a-model-class"><i class="fa fa-check"></i><b>2.8</b> Build a model class</a><ul>
<li class="chapter" data-level="2.8.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-1"><i class="fa fa-check"></i><b>2.8.1</b> Example 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>2.8.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>2.9</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="2.10" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>2.10</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="3" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>3</b> Tensors</a><ul>
<li class="chapter" data-level="3.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>3.1</b> Tensor data types</a></li>
<li class="chapter" data-level="3.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>3.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>3.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>3.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>3.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="3.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>3.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>3.4</b> Create tensors</a></li>
<li class="chapter" data-level="3.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>3.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>3.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>3.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="3.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>3.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="3.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>3.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>3.7</b> Special tensors</a><ul>
<li class="chapter" data-level="3.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>3.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="3.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>3.7.2</b> Ones</a></li>
<li class="chapter" data-level="3.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>3.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>3.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="3.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>3.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="3.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>3.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>3.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="3.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>3.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="3.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>3.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>3.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="3.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>3.10.1</b> Cross product</a></li>
<li class="chapter" data-level="3.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>3.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>3.11</b> Logical operations</a><ul>
<li class="chapter" data-level="3.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>3.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>3.12</b> Distributions</a><ul>
<li class="chapter" data-level="3.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>3.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="3.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>3.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>3.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="4.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>4.1</b> Scalars</a></li>
<li class="chapter" data-level="4.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>4.2</b> Vectors</a></li>
<li class="chapter" data-level="4.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>4.3</b> Matrices</a></li>
<li class="chapter" data-level="4.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>4.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="4.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>4.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="4.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>4.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="4.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>4.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="4.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>4.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="4.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>4.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="4.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>4.10</b> Dot product</a><ul>
<li class="chapter" data-level="4.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-python"><i class="fa fa-check"></i><b>4.10.1</b> Dot product of 2D array using Python</a></li>
<li class="chapter" data-level="4.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-r"><i class="fa fa-check"></i><b>4.10.2</b> Dot product of 2D array using R</a></li>
<li class="chapter" data-level="4.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-with-mm-and-matmul-functions"><i class="fa fa-check"></i><b>4.10.3</b> Dot product with <code>mm</code> and <code>matmul</code> functions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="5" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>5</b> Example 1 (R): MNIST handwritten digits</a><ul>
<li class="chapter" data-level="5.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>5.2</b> Read datasets</a></li>
<li class="chapter" data-level="5.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>5.3</b> Define the model</a></li>
<li class="chapter" data-level="5.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>5.4</b> Training</a></li>
<li class="chapter" data-level="5.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
<li class="chapter" data-level="5.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>5.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-1-python-mnist-handwritten-digits.html"><a href="example-1-python-mnist-handwritten-digits.html"><i class="fa fa-check"></i><b>6</b> Example 1 (Python): MNIST handwritten digits</a></li>
<li class="chapter" data-level="7" data-path="a-classic-classification-problem.html"><a href="a-classic-classification-problem.html"><i class="fa fa-check"></i><b>7</b> A classic classification problem</a></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Simple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>8.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="8.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>8.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="8.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>8.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="8.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>8.5</b> Creating the network model</a></li>
<li class="chapter" data-level="8.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>8.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="8.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>8.7</b> Training</a></li>
<li class="chapter" data-level="8.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>8.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Rainfall. Linear Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#training-data"><i class="fa fa-check"></i><b>9.1</b> Training data</a></li>
<li class="chapter" data-level="9.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>9.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="9.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>9.3</b> Build the model</a></li>
<li class="chapter" data-level="9.4" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>9.4</b> Generate predictions</a></li>
<li class="chapter" data-level="9.5" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>9.5</b> Loss Function</a></li>
<li class="chapter" data-level="9.6" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>9.6</b> Step by step process</a><ul>
<li class="chapter" data-level="9.6.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>9.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="9.6.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>9.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="9.6.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>9.6.3</b> Reset the gradients</a><ul>
<li class="chapter" data-level="9.6.3.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#adjust-weights-and-biases-using-gradient-descent"><i class="fa fa-check"></i><b>9.6.3.1</b> Adjust weights and biases using gradient descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>9.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="10" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html"><i class="fa fa-check"></i><b>10</b> A two-layer neural network</a><ul>
<li class="chapter" data-level="10.1" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#load-the-libraries"><i class="fa fa-check"></i><b>10.1</b> Load the libraries</a></li>
<li class="chapter" data-level="10.2" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#dataset"><i class="fa fa-check"></i><b>10.2</b> Dataset</a></li>
<li class="chapter" data-level="10.3" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-the-model-for-50-iterations"><i class="fa fa-check"></i><b>10.3</b> Run the model for 50 iterations</a></li>
<li class="chapter" data-level="10.4" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>10.4</b> Run it at 100 iterations</a></li>
<li class="chapter" data-level="10.5" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#original-pytorch-code"><i class="fa fa-check"></i><b>10.5</b> Original PyTorch code</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>11</b> A very simple neural network</a><ul>
<li class="chapter" data-level="11.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>11.2</b> Select device</a></li>
<li class="chapter" data-level="11.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>11.3</b> Create the dataset</a></li>
<li class="chapter" data-level="11.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>11.4</b> Define the model</a></li>
<li class="chapter" data-level="11.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>11.5</b> Loss function</a></li>
<li class="chapter" data-level="11.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>11.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neural-networks-2.html"><a href="neural-networks-2.html"><i class="fa fa-check"></i><b>12</b> Neural Networks 2</a><ul>
<li class="chapter" data-level="12.1" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-1"><i class="fa fa-check"></i><b>12.1</b> nn2 1</a></li>
<li class="chapter" data-level="12.2" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-2"><i class="fa fa-check"></i><b>12.2</b> nn2 2</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="13" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>13</b> Working with data.frame</a><ul>
<li class="chapter" data-level="13.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>13.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="13.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>13.2</b> Load dataset</a></li>
<li class="chapter" data-level="13.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>13.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="13.3.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>13.3.1</b> using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>14</b> Working with data.table</a><ul>
<li class="chapter" data-level="14.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>14.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="14.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>14.2</b> Load dataset</a></li>
<li class="chapter" data-level="14.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#read-the-datasets-without-normalization"><i class="fa fa-check"></i><b>14.3</b> Read the datasets without normalization</a></li>
<li class="chapter" data-level="14.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>14.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#the-sigmoid-function"><i class="fa fa-check"></i><b>B.1</b> The Sigmoid function</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#the-relu-function"><i class="fa fa-check"></i><b>B.2</b> The ReLU function</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#the-tanh-function"><i class="fa fa-check"></i><b>B.3</b> The tanh function</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#the-softmax-activation-function"><i class="fa fa-check"></i><b>B.4</b> The Softmax Activation function</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#coding-your-own-activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Coding your own activation functions in Python</a><ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li><a href="appendixB.html#visualization-with-matplotlib">Visualization with <code>matplotlib</code></a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linearalgebra" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Linear Algebra with Torch</h1>
<p>The following are basic operations of Linear Algebra using PyTorch.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="linearalgebra.html#cb136-1"></a><span class="kw">library</span>(rTorch)</span></code></pre></div>
<div id="scalars" class="section level2">
<h2><span class="header-section-number">4.1</span> Scalars</h2>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="linearalgebra.html#cb137-1"></a>torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="fl">2.78654</span>)</span>
<span id="cb137-2"><a href="linearalgebra.html#cb137-2"></a><span class="co">#&gt; tensor(2.7865)</span></span>
<span id="cb137-3"><a href="linearalgebra.html#cb137-3"></a></span>
<span id="cb137-4"><a href="linearalgebra.html#cb137-4"></a>torch<span class="op">$</span><span class="kw">scalar_tensor</span>(0L)</span>
<span id="cb137-5"><a href="linearalgebra.html#cb137-5"></a><span class="co">#&gt; tensor(0.)</span></span>
<span id="cb137-6"><a href="linearalgebra.html#cb137-6"></a></span>
<span id="cb137-7"><a href="linearalgebra.html#cb137-7"></a>torch<span class="op">$</span><span class="kw">scalar_tensor</span>(1L)</span>
<span id="cb137-8"><a href="linearalgebra.html#cb137-8"></a><span class="co">#&gt; tensor(1.)</span></span>
<span id="cb137-9"><a href="linearalgebra.html#cb137-9"></a></span>
<span id="cb137-10"><a href="linearalgebra.html#cb137-10"></a>torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="ot">TRUE</span>)</span>
<span id="cb137-11"><a href="linearalgebra.html#cb137-11"></a><span class="co">#&gt; tensor(1.)</span></span>
<span id="cb137-12"><a href="linearalgebra.html#cb137-12"></a></span>
<span id="cb137-13"><a href="linearalgebra.html#cb137-13"></a>torch<span class="op">$</span><span class="kw">scalar_tensor</span>(<span class="ot">FALSE</span>)</span>
<span id="cb137-14"><a href="linearalgebra.html#cb137-14"></a><span class="co">#&gt; tensor(0.)</span></span></code></pre></div>
</div>
<div id="vectors" class="section level2">
<h2><span class="header-section-number">4.2</span> Vectors</h2>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="linearalgebra.html#cb138-1"></a>v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb138-2"><a href="linearalgebra.html#cb138-2"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(v)</span>
<span id="cb138-3"><a href="linearalgebra.html#cb138-3"></a><span class="co">#&gt; tensor([0., 1., 2., 3., 4., 5.])</span></span></code></pre></div>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="linearalgebra.html#cb139-1"></a><span class="co"># row-vector</span></span>
<span id="cb139-2"><a href="linearalgebra.html#cb139-2"></a><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</span>
<span id="cb139-3"><a href="linearalgebra.html#cb139-3"></a><span class="co">#&gt; R matrix</span></span>
<span id="cb139-4"><a href="linearalgebra.html#cb139-4"></a>(mr &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">nrow=</span><span class="dv">1</span>))</span>
<span id="cb139-5"><a href="linearalgebra.html#cb139-5"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></span>
<span id="cb139-6"><a href="linearalgebra.html#cb139-6"></a><span class="co">#&gt; [1,]    1    2    3    4    5    6    7    8    9    10</span></span>
<span id="cb139-7"><a href="linearalgebra.html#cb139-7"></a><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</span>
<span id="cb139-8"><a href="linearalgebra.html#cb139-8"></a><span class="co">#&gt; as_tensor</span></span>
<span id="cb139-9"><a href="linearalgebra.html#cb139-9"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(mr)</span>
<span id="cb139-10"><a href="linearalgebra.html#cb139-10"></a><span class="co">#&gt; tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]], dtype=torch.int32)</span></span>
<span id="cb139-11"><a href="linearalgebra.html#cb139-11"></a><span class="kw">message</span>(<span class="st">&quot;shape_of_tensor&quot;</span>)</span>
<span id="cb139-12"><a href="linearalgebra.html#cb139-12"></a><span class="co">#&gt; shape_of_tensor</span></span>
<span id="cb139-13"><a href="linearalgebra.html#cb139-13"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(mr)<span class="op">$</span>shape</span>
<span id="cb139-14"><a href="linearalgebra.html#cb139-14"></a><span class="co">#&gt; torch.Size([1, 10])</span></span></code></pre></div>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="linearalgebra.html#cb140-1"></a><span class="co"># column-vector</span></span>
<span id="cb140-2"><a href="linearalgebra.html#cb140-2"></a><span class="kw">message</span>(<span class="st">&quot;R matrix, one column&quot;</span>)</span>
<span id="cb140-3"><a href="linearalgebra.html#cb140-3"></a><span class="co">#&gt; R matrix, one column</span></span>
<span id="cb140-4"><a href="linearalgebra.html#cb140-4"></a>(mc &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">ncol=</span><span class="dv">1</span>))</span>
<span id="cb140-5"><a href="linearalgebra.html#cb140-5"></a><span class="co">#&gt;       [,1]</span></span>
<span id="cb140-6"><a href="linearalgebra.html#cb140-6"></a><span class="co">#&gt;  [1,]    1</span></span>
<span id="cb140-7"><a href="linearalgebra.html#cb140-7"></a><span class="co">#&gt;  [2,]    2</span></span>
<span id="cb140-8"><a href="linearalgebra.html#cb140-8"></a><span class="co">#&gt;  [3,]    3</span></span>
<span id="cb140-9"><a href="linearalgebra.html#cb140-9"></a><span class="co">#&gt;  [4,]    4</span></span>
<span id="cb140-10"><a href="linearalgebra.html#cb140-10"></a><span class="co">#&gt;  [5,]    5</span></span>
<span id="cb140-11"><a href="linearalgebra.html#cb140-11"></a><span class="co">#&gt;  [6,]    6</span></span>
<span id="cb140-12"><a href="linearalgebra.html#cb140-12"></a><span class="co">#&gt;  [7,]    7</span></span>
<span id="cb140-13"><a href="linearalgebra.html#cb140-13"></a><span class="co">#&gt;  [8,]    8</span></span>
<span id="cb140-14"><a href="linearalgebra.html#cb140-14"></a><span class="co">#&gt;  [9,]    9</span></span>
<span id="cb140-15"><a href="linearalgebra.html#cb140-15"></a><span class="co">#&gt; [10,]   10</span></span>
<span id="cb140-16"><a href="linearalgebra.html#cb140-16"></a><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</span>
<span id="cb140-17"><a href="linearalgebra.html#cb140-17"></a><span class="co">#&gt; as_tensor</span></span>
<span id="cb140-18"><a href="linearalgebra.html#cb140-18"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(mc)</span>
<span id="cb140-19"><a href="linearalgebra.html#cb140-19"></a><span class="co">#&gt; tensor([[ 1],</span></span>
<span id="cb140-20"><a href="linearalgebra.html#cb140-20"></a><span class="co">#&gt;         [ 2],</span></span>
<span id="cb140-21"><a href="linearalgebra.html#cb140-21"></a><span class="co">#&gt;         [ 3],</span></span>
<span id="cb140-22"><a href="linearalgebra.html#cb140-22"></a><span class="co">#&gt;         [ 4],</span></span>
<span id="cb140-23"><a href="linearalgebra.html#cb140-23"></a><span class="co">#&gt;         [ 5],</span></span>
<span id="cb140-24"><a href="linearalgebra.html#cb140-24"></a><span class="co">#&gt;         [ 6],</span></span>
<span id="cb140-25"><a href="linearalgebra.html#cb140-25"></a><span class="co">#&gt;         [ 7],</span></span>
<span id="cb140-26"><a href="linearalgebra.html#cb140-26"></a><span class="co">#&gt;         [ 8],</span></span>
<span id="cb140-27"><a href="linearalgebra.html#cb140-27"></a><span class="co">#&gt;         [ 9],</span></span>
<span id="cb140-28"><a href="linearalgebra.html#cb140-28"></a><span class="co">#&gt;         [10]], dtype=torch.int32)</span></span>
<span id="cb140-29"><a href="linearalgebra.html#cb140-29"></a><span class="kw">message</span>(<span class="st">&quot;size of tensor&quot;</span>)</span>
<span id="cb140-30"><a href="linearalgebra.html#cb140-30"></a><span class="co">#&gt; size of tensor</span></span>
<span id="cb140-31"><a href="linearalgebra.html#cb140-31"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(mc)<span class="op">$</span>shape</span>
<span id="cb140-32"><a href="linearalgebra.html#cb140-32"></a><span class="co">#&gt; torch.Size([10, 1])</span></span></code></pre></div>
</div>
<div id="matrices" class="section level2">
<h2><span class="header-section-number">4.3</span> Matrices</h2>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="linearalgebra.html#cb141-1"></a><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</span>
<span id="cb141-2"><a href="linearalgebra.html#cb141-2"></a><span class="co">#&gt; R matrix</span></span>
<span id="cb141-3"><a href="linearalgebra.html#cb141-3"></a>(m1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">24</span>, <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))</span>
<span id="cb141-4"><a href="linearalgebra.html#cb141-4"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]</span></span>
<span id="cb141-5"><a href="linearalgebra.html#cb141-5"></a><span class="co">#&gt; [1,]    1    2    3    4    5    6    7    8</span></span>
<span id="cb141-6"><a href="linearalgebra.html#cb141-6"></a><span class="co">#&gt; [2,]    9   10   11   12   13   14   15   16</span></span>
<span id="cb141-7"><a href="linearalgebra.html#cb141-7"></a><span class="co">#&gt; [3,]   17   18   19   20   21   22   23   24</span></span>
<span id="cb141-8"><a href="linearalgebra.html#cb141-8"></a><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</span>
<span id="cb141-9"><a href="linearalgebra.html#cb141-9"></a><span class="co">#&gt; as_tensor</span></span>
<span id="cb141-10"><a href="linearalgebra.html#cb141-10"></a>(t1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</span>
<span id="cb141-11"><a href="linearalgebra.html#cb141-11"></a><span class="co">#&gt; tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],</span></span>
<span id="cb141-12"><a href="linearalgebra.html#cb141-12"></a><span class="co">#&gt;         [ 9, 10, 11, 12, 13, 14, 15, 16],</span></span>
<span id="cb141-13"><a href="linearalgebra.html#cb141-13"></a><span class="co">#&gt;         [17, 18, 19, 20, 21, 22, 23, 24]], dtype=torch.int32)</span></span>
<span id="cb141-14"><a href="linearalgebra.html#cb141-14"></a><span class="kw">message</span>(<span class="st">&quot;shape&quot;</span>)</span>
<span id="cb141-15"><a href="linearalgebra.html#cb141-15"></a><span class="co">#&gt; shape</span></span>
<span id="cb141-16"><a href="linearalgebra.html#cb141-16"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(m1)<span class="op">$</span>shape</span>
<span id="cb141-17"><a href="linearalgebra.html#cb141-17"></a><span class="co">#&gt; torch.Size([3, 8])</span></span>
<span id="cb141-18"><a href="linearalgebra.html#cb141-18"></a><span class="kw">message</span>(<span class="st">&quot;size&quot;</span>)</span>
<span id="cb141-19"><a href="linearalgebra.html#cb141-19"></a><span class="co">#&gt; size</span></span>
<span id="cb141-20"><a href="linearalgebra.html#cb141-20"></a>torch<span class="op">$</span><span class="kw">as_tensor</span>(m1)<span class="op">$</span><span class="kw">size</span>()</span>
<span id="cb141-21"><a href="linearalgebra.html#cb141-21"></a><span class="co">#&gt; torch.Size([3, 8])</span></span>
<span id="cb141-22"><a href="linearalgebra.html#cb141-22"></a><span class="kw">message</span>(<span class="st">&quot;dim&quot;</span>)</span>
<span id="cb141-23"><a href="linearalgebra.html#cb141-23"></a><span class="co">#&gt; dim</span></span>
<span id="cb141-24"><a href="linearalgebra.html#cb141-24"></a><span class="kw">dim</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</span>
<span id="cb141-25"><a href="linearalgebra.html#cb141-25"></a><span class="co">#&gt; [1] 3 8</span></span>
<span id="cb141-26"><a href="linearalgebra.html#cb141-26"></a><span class="kw">message</span>(<span class="st">&quot;length&quot;</span>)</span>
<span id="cb141-27"><a href="linearalgebra.html#cb141-27"></a><span class="co">#&gt; length</span></span>
<span id="cb141-28"><a href="linearalgebra.html#cb141-28"></a><span class="kw">length</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m1))</span>
<span id="cb141-29"><a href="linearalgebra.html#cb141-29"></a><span class="co">#&gt; [1] 24</span></span></code></pre></div>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="linearalgebra.html#cb142-1"></a><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</span>
<span id="cb142-2"><a href="linearalgebra.html#cb142-2"></a><span class="co">#&gt; R matrix</span></span>
<span id="cb142-3"><a href="linearalgebra.html#cb142-3"></a>(m2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">99</span>, <span class="dt">ncol =</span> <span class="dv">10</span>))</span>
<span id="cb142-4"><a href="linearalgebra.html#cb142-4"></a><span class="co">#&gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></span>
<span id="cb142-5"><a href="linearalgebra.html#cb142-5"></a><span class="co">#&gt;  [1,]    0   10   20   30   40   50   60   70   80    90</span></span>
<span id="cb142-6"><a href="linearalgebra.html#cb142-6"></a><span class="co">#&gt;  [2,]    1   11   21   31   41   51   61   71   81    91</span></span>
<span id="cb142-7"><a href="linearalgebra.html#cb142-7"></a><span class="co">#&gt;  [3,]    2   12   22   32   42   52   62   72   82    92</span></span>
<span id="cb142-8"><a href="linearalgebra.html#cb142-8"></a><span class="co">#&gt;  [4,]    3   13   23   33   43   53   63   73   83    93</span></span>
<span id="cb142-9"><a href="linearalgebra.html#cb142-9"></a><span class="co">#&gt;  [5,]    4   14   24   34   44   54   64   74   84    94</span></span>
<span id="cb142-10"><a href="linearalgebra.html#cb142-10"></a><span class="co">#&gt;  [6,]    5   15   25   35   45   55   65   75   85    95</span></span>
<span id="cb142-11"><a href="linearalgebra.html#cb142-11"></a><span class="co">#&gt;  [7,]    6   16   26   36   46   56   66   76   86    96</span></span>
<span id="cb142-12"><a href="linearalgebra.html#cb142-12"></a><span class="co">#&gt;  [8,]    7   17   27   37   47   57   67   77   87    97</span></span>
<span id="cb142-13"><a href="linearalgebra.html#cb142-13"></a><span class="co">#&gt;  [9,]    8   18   28   38   48   58   68   78   88    98</span></span>
<span id="cb142-14"><a href="linearalgebra.html#cb142-14"></a><span class="co">#&gt; [10,]    9   19   29   39   49   59   69   79   89    99</span></span>
<span id="cb142-15"><a href="linearalgebra.html#cb142-15"></a><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</span>
<span id="cb142-16"><a href="linearalgebra.html#cb142-16"></a><span class="co">#&gt; as_tensor</span></span>
<span id="cb142-17"><a href="linearalgebra.html#cb142-17"></a>(t2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</span>
<span id="cb142-18"><a href="linearalgebra.html#cb142-18"></a><span class="co">#&gt; tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],</span></span>
<span id="cb142-19"><a href="linearalgebra.html#cb142-19"></a><span class="co">#&gt;         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],</span></span>
<span id="cb142-20"><a href="linearalgebra.html#cb142-20"></a><span class="co">#&gt;         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],</span></span>
<span id="cb142-21"><a href="linearalgebra.html#cb142-21"></a><span class="co">#&gt;         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],</span></span>
<span id="cb142-22"><a href="linearalgebra.html#cb142-22"></a><span class="co">#&gt;         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],</span></span>
<span id="cb142-23"><a href="linearalgebra.html#cb142-23"></a><span class="co">#&gt;         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],</span></span>
<span id="cb142-24"><a href="linearalgebra.html#cb142-24"></a><span class="co">#&gt;         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],</span></span>
<span id="cb142-25"><a href="linearalgebra.html#cb142-25"></a><span class="co">#&gt;         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],</span></span>
<span id="cb142-26"><a href="linearalgebra.html#cb142-26"></a><span class="co">#&gt;         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],</span></span>
<span id="cb142-27"><a href="linearalgebra.html#cb142-27"></a><span class="co">#&gt;         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)</span></span>
<span id="cb142-28"><a href="linearalgebra.html#cb142-28"></a><span class="kw">message</span>(<span class="st">&quot;shape&quot;</span>)</span>
<span id="cb142-29"><a href="linearalgebra.html#cb142-29"></a><span class="co">#&gt; shape</span></span>
<span id="cb142-30"><a href="linearalgebra.html#cb142-30"></a>t2<span class="op">$</span>shape</span>
<span id="cb142-31"><a href="linearalgebra.html#cb142-31"></a><span class="co">#&gt; torch.Size([10, 10])</span></span>
<span id="cb142-32"><a href="linearalgebra.html#cb142-32"></a><span class="kw">message</span>(<span class="st">&quot;dim&quot;</span>)</span>
<span id="cb142-33"><a href="linearalgebra.html#cb142-33"></a><span class="co">#&gt; dim</span></span>
<span id="cb142-34"><a href="linearalgebra.html#cb142-34"></a><span class="kw">dim</span>(torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</span>
<span id="cb142-35"><a href="linearalgebra.html#cb142-35"></a><span class="co">#&gt; [1] 10 10</span></span></code></pre></div>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="linearalgebra.html#cb143-1"></a>m1[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb143-2"><a href="linearalgebra.html#cb143-2"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb143-3"><a href="linearalgebra.html#cb143-3"></a>m2[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb143-4"><a href="linearalgebra.html#cb143-4"></a><span class="co">#&gt; [1] 0</span></span></code></pre></div>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="linearalgebra.html#cb144-1"></a>t1[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb144-2"><a href="linearalgebra.html#cb144-2"></a><span class="co">#&gt; tensor(1, dtype=torch.int32)</span></span>
<span id="cb144-3"><a href="linearalgebra.html#cb144-3"></a>t2[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb144-4"><a href="linearalgebra.html#cb144-4"></a><span class="co">#&gt; tensor(0, dtype=torch.int32)</span></span></code></pre></div>
</div>
<div id="d-tensors" class="section level2">
<h2><span class="header-section-number">4.4</span> 3D+ tensors</h2>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="linearalgebra.html#cb145-1"></a><span class="co"># RGB color image has three axes </span></span>
<span id="cb145-2"><a href="linearalgebra.html#cb145-2"></a>(img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(3L, 28L, 28L))</span>
<span id="cb145-3"><a href="linearalgebra.html#cb145-3"></a><span class="co">#&gt; tensor([[[0.0851, 0.1065, 0.7608,  ..., 0.5812, 0.4252, 0.6177],</span></span>
<span id="cb145-4"><a href="linearalgebra.html#cb145-4"></a><span class="co">#&gt;          [0.6279, 0.7656, 0.2918,  ..., 0.4205, 0.1213, 0.1802],</span></span>
<span id="cb145-5"><a href="linearalgebra.html#cb145-5"></a><span class="co">#&gt;          [0.9089, 0.9708, 0.3665,  ..., 0.6661, 0.1234, 0.2903],</span></span>
<span id="cb145-6"><a href="linearalgebra.html#cb145-6"></a><span class="co">#&gt;          ...,</span></span>
<span id="cb145-7"><a href="linearalgebra.html#cb145-7"></a><span class="co">#&gt;          [0.8555, 0.9334, 0.0868,  ..., 0.4547, 0.8523, 0.6185],</span></span>
<span id="cb145-8"><a href="linearalgebra.html#cb145-8"></a><span class="co">#&gt;          [0.1225, 0.0929, 0.0193,  ..., 0.6175, 0.4618, 0.9052],</span></span>
<span id="cb145-9"><a href="linearalgebra.html#cb145-9"></a><span class="co">#&gt;          [0.8532, 0.7185, 0.0273,  ..., 0.7122, 0.3092, 0.0446]],</span></span>
<span id="cb145-10"><a href="linearalgebra.html#cb145-10"></a><span class="co">#&gt; </span></span>
<span id="cb145-11"><a href="linearalgebra.html#cb145-11"></a><span class="co">#&gt;         [[0.7361, 0.0667, 0.2758,  ..., 0.0776, 0.2094, 0.4039],</span></span>
<span id="cb145-12"><a href="linearalgebra.html#cb145-12"></a><span class="co">#&gt;          [0.9845, 0.8521, 0.8883,  ..., 0.1236, 0.1726, 0.1094],</span></span>
<span id="cb145-13"><a href="linearalgebra.html#cb145-13"></a><span class="co">#&gt;          [0.8255, 0.9892, 0.9171,  ..., 0.7832, 0.7564, 0.2947],</span></span>
<span id="cb145-14"><a href="linearalgebra.html#cb145-14"></a><span class="co">#&gt;          ...,</span></span>
<span id="cb145-15"><a href="linearalgebra.html#cb145-15"></a><span class="co">#&gt;          [0.2095, 0.7633, 0.4461,  ..., 0.1478, 0.5026, 0.4553],</span></span>
<span id="cb145-16"><a href="linearalgebra.html#cb145-16"></a><span class="co">#&gt;          [0.0127, 0.9428, 0.1243,  ..., 0.8608, 0.4925, 0.9474],</span></span>
<span id="cb145-17"><a href="linearalgebra.html#cb145-17"></a><span class="co">#&gt;          [0.7745, 0.7443, 0.0320,  ..., 0.2150, 0.3772, 0.2980]],</span></span>
<span id="cb145-18"><a href="linearalgebra.html#cb145-18"></a><span class="co">#&gt; </span></span>
<span id="cb145-19"><a href="linearalgebra.html#cb145-19"></a><span class="co">#&gt;         [[0.5760, 0.8096, 0.0732,  ..., 0.8406, 0.0692, 0.3474],</span></span>
<span id="cb145-20"><a href="linearalgebra.html#cb145-20"></a><span class="co">#&gt;          [0.0712, 0.7110, 0.1372,  ..., 0.4755, 0.9103, 0.4137],</span></span>
<span id="cb145-21"><a href="linearalgebra.html#cb145-21"></a><span class="co">#&gt;          [0.8007, 0.8131, 0.2237,  ..., 0.7018, 0.8058, 0.2310],</span></span>
<span id="cb145-22"><a href="linearalgebra.html#cb145-22"></a><span class="co">#&gt;          ...,</span></span>
<span id="cb145-23"><a href="linearalgebra.html#cb145-23"></a><span class="co">#&gt;          [0.6682, 0.0209, 0.9269,  ..., 0.7134, 0.3020, 0.9877],</span></span>
<span id="cb145-24"><a href="linearalgebra.html#cb145-24"></a><span class="co">#&gt;          [0.2029, 0.6861, 0.2617,  ..., 0.8970, 0.5193, 0.4956],</span></span>
<span id="cb145-25"><a href="linearalgebra.html#cb145-25"></a><span class="co">#&gt;          [0.1251, 0.4621, 0.4737,  ..., 0.1029, 0.0390, 0.9338]]])</span></span>
<span id="cb145-26"><a href="linearalgebra.html#cb145-26"></a>img<span class="op">$</span>shape</span>
<span id="cb145-27"><a href="linearalgebra.html#cb145-27"></a><span class="co">#&gt; torch.Size([3, 28, 28])</span></span></code></pre></div>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="linearalgebra.html#cb146-1"></a>img[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb146-2"><a href="linearalgebra.html#cb146-2"></a><span class="co">#&gt; tensor(0.0851)</span></span>
<span id="cb146-3"><a href="linearalgebra.html#cb146-3"></a>img[<span class="dv">3</span>, <span class="dv">28</span>, <span class="dv">28</span>]</span>
<span id="cb146-4"><a href="linearalgebra.html#cb146-4"></a><span class="co">#&gt; tensor(0.9338)</span></span></code></pre></div>
</div>
<div id="transpose-of-a-matrix" class="section level2">
<h2><span class="header-section-number">4.5</span> Transpose of a matrix</h2>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="linearalgebra.html#cb147-1"></a>(m3 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>, <span class="dt">ncol =</span> <span class="dv">5</span>))</span>
<span id="cb147-2"><a href="linearalgebra.html#cb147-2"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></span>
<span id="cb147-3"><a href="linearalgebra.html#cb147-3"></a><span class="co">#&gt; [1,]    1    6   11   16   21</span></span>
<span id="cb147-4"><a href="linearalgebra.html#cb147-4"></a><span class="co">#&gt; [2,]    2    7   12   17   22</span></span>
<span id="cb147-5"><a href="linearalgebra.html#cb147-5"></a><span class="co">#&gt; [3,]    3    8   13   18   23</span></span>
<span id="cb147-6"><a href="linearalgebra.html#cb147-6"></a><span class="co">#&gt; [4,]    4    9   14   19   24</span></span>
<span id="cb147-7"><a href="linearalgebra.html#cb147-7"></a><span class="co">#&gt; [5,]    5   10   15   20   25</span></span>
<span id="cb147-8"><a href="linearalgebra.html#cb147-8"></a></span>
<span id="cb147-9"><a href="linearalgebra.html#cb147-9"></a><span class="co"># transpose</span></span>
<span id="cb147-10"><a href="linearalgebra.html#cb147-10"></a><span class="kw">message</span>(<span class="st">&quot;transpose&quot;</span>)</span>
<span id="cb147-11"><a href="linearalgebra.html#cb147-11"></a><span class="co">#&gt; transpose</span></span>
<span id="cb147-12"><a href="linearalgebra.html#cb147-12"></a>tm3 &lt;-<span class="st"> </span><span class="kw">t</span>(m3)</span>
<span id="cb147-13"><a href="linearalgebra.html#cb147-13"></a>tm3</span>
<span id="cb147-14"><a href="linearalgebra.html#cb147-14"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></span>
<span id="cb147-15"><a href="linearalgebra.html#cb147-15"></a><span class="co">#&gt; [1,]    1    2    3    4    5</span></span>
<span id="cb147-16"><a href="linearalgebra.html#cb147-16"></a><span class="co">#&gt; [2,]    6    7    8    9   10</span></span>
<span id="cb147-17"><a href="linearalgebra.html#cb147-17"></a><span class="co">#&gt; [3,]   11   12   13   14   15</span></span>
<span id="cb147-18"><a href="linearalgebra.html#cb147-18"></a><span class="co">#&gt; [4,]   16   17   18   19   20</span></span>
<span id="cb147-19"><a href="linearalgebra.html#cb147-19"></a><span class="co">#&gt; [5,]   21   22   23   24   25</span></span></code></pre></div>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="linearalgebra.html#cb148-1"></a><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</span>
<span id="cb148-2"><a href="linearalgebra.html#cb148-2"></a><span class="co">#&gt; as_tensor</span></span>
<span id="cb148-3"><a href="linearalgebra.html#cb148-3"></a>(t3 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m3))</span>
<span id="cb148-4"><a href="linearalgebra.html#cb148-4"></a><span class="co">#&gt; tensor([[ 1,  6, 11, 16, 21],</span></span>
<span id="cb148-5"><a href="linearalgebra.html#cb148-5"></a><span class="co">#&gt;         [ 2,  7, 12, 17, 22],</span></span>
<span id="cb148-6"><a href="linearalgebra.html#cb148-6"></a><span class="co">#&gt;         [ 3,  8, 13, 18, 23],</span></span>
<span id="cb148-7"><a href="linearalgebra.html#cb148-7"></a><span class="co">#&gt;         [ 4,  9, 14, 19, 24],</span></span>
<span id="cb148-8"><a href="linearalgebra.html#cb148-8"></a><span class="co">#&gt;         [ 5, 10, 15, 20, 25]], dtype=torch.int32)</span></span>
<span id="cb148-9"><a href="linearalgebra.html#cb148-9"></a><span class="kw">message</span>(<span class="st">&quot;transpose&quot;</span>)</span>
<span id="cb148-10"><a href="linearalgebra.html#cb148-10"></a><span class="co">#&gt; transpose</span></span>
<span id="cb148-11"><a href="linearalgebra.html#cb148-11"></a>tt3 &lt;-<span class="st"> </span>t3<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0 =</span> 0L, <span class="dt">dim1 =</span> 1L)</span>
<span id="cb148-12"><a href="linearalgebra.html#cb148-12"></a>tt3</span>
<span id="cb148-13"><a href="linearalgebra.html#cb148-13"></a><span class="co">#&gt; tensor([[ 1,  2,  3,  4,  5],</span></span>
<span id="cb148-14"><a href="linearalgebra.html#cb148-14"></a><span class="co">#&gt;         [ 6,  7,  8,  9, 10],</span></span>
<span id="cb148-15"><a href="linearalgebra.html#cb148-15"></a><span class="co">#&gt;         [11, 12, 13, 14, 15],</span></span>
<span id="cb148-16"><a href="linearalgebra.html#cb148-16"></a><span class="co">#&gt;         [16, 17, 18, 19, 20],</span></span>
<span id="cb148-17"><a href="linearalgebra.html#cb148-17"></a><span class="co">#&gt;         [21, 22, 23, 24, 25]], dtype=torch.int32)</span></span></code></pre></div>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="linearalgebra.html#cb149-1"></a>tm3 <span class="op">==</span><span class="st"> </span>tt3<span class="op">$</span><span class="kw">numpy</span>()   <span class="co"># convert first the tensor to numpy</span></span>
<span id="cb149-2"><a href="linearalgebra.html#cb149-2"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></span>
<span id="cb149-3"><a href="linearalgebra.html#cb149-3"></a><span class="co">#&gt; [1,] TRUE TRUE TRUE TRUE TRUE</span></span>
<span id="cb149-4"><a href="linearalgebra.html#cb149-4"></a><span class="co">#&gt; [2,] TRUE TRUE TRUE TRUE TRUE</span></span>
<span id="cb149-5"><a href="linearalgebra.html#cb149-5"></a><span class="co">#&gt; [3,] TRUE TRUE TRUE TRUE TRUE</span></span>
<span id="cb149-6"><a href="linearalgebra.html#cb149-6"></a><span class="co">#&gt; [4,] TRUE TRUE TRUE TRUE TRUE</span></span>
<span id="cb149-7"><a href="linearalgebra.html#cb149-7"></a><span class="co">#&gt; [5,] TRUE TRUE TRUE TRUE TRUE</span></span></code></pre></div>
</div>
<div id="vectors-special-case-of-a-matrix" class="section level2">
<h2><span class="header-section-number">4.6</span> Vectors, special case of a matrix</h2>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="linearalgebra.html#cb150-1"></a><span class="kw">message</span>(<span class="st">&quot;R matrix&quot;</span>)</span>
<span id="cb150-2"><a href="linearalgebra.html#cb150-2"></a><span class="co">#&gt; R matrix</span></span>
<span id="cb150-3"><a href="linearalgebra.html#cb150-3"></a>m2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">99</span>, <span class="dt">ncol =</span> <span class="dv">10</span>)</span>
<span id="cb150-4"><a href="linearalgebra.html#cb150-4"></a><span class="kw">message</span>(<span class="st">&quot;as_tensor&quot;</span>)</span>
<span id="cb150-5"><a href="linearalgebra.html#cb150-5"></a><span class="co">#&gt; as_tensor</span></span>
<span id="cb150-6"><a href="linearalgebra.html#cb150-6"></a>(t2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(m2))</span>
<span id="cb150-7"><a href="linearalgebra.html#cb150-7"></a><span class="co">#&gt; tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],</span></span>
<span id="cb150-8"><a href="linearalgebra.html#cb150-8"></a><span class="co">#&gt;         [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],</span></span>
<span id="cb150-9"><a href="linearalgebra.html#cb150-9"></a><span class="co">#&gt;         [ 2, 12, 22, 32, 42, 52, 62, 72, 82, 92],</span></span>
<span id="cb150-10"><a href="linearalgebra.html#cb150-10"></a><span class="co">#&gt;         [ 3, 13, 23, 33, 43, 53, 63, 73, 83, 93],</span></span>
<span id="cb150-11"><a href="linearalgebra.html#cb150-11"></a><span class="co">#&gt;         [ 4, 14, 24, 34, 44, 54, 64, 74, 84, 94],</span></span>
<span id="cb150-12"><a href="linearalgebra.html#cb150-12"></a><span class="co">#&gt;         [ 5, 15, 25, 35, 45, 55, 65, 75, 85, 95],</span></span>
<span id="cb150-13"><a href="linearalgebra.html#cb150-13"></a><span class="co">#&gt;         [ 6, 16, 26, 36, 46, 56, 66, 76, 86, 96],</span></span>
<span id="cb150-14"><a href="linearalgebra.html#cb150-14"></a><span class="co">#&gt;         [ 7, 17, 27, 37, 47, 57, 67, 77, 87, 97],</span></span>
<span id="cb150-15"><a href="linearalgebra.html#cb150-15"></a><span class="co">#&gt;         [ 8, 18, 28, 38, 48, 58, 68, 78, 88, 98],</span></span>
<span id="cb150-16"><a href="linearalgebra.html#cb150-16"></a><span class="co">#&gt;         [ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]], dtype=torch.int32)</span></span>
<span id="cb150-17"><a href="linearalgebra.html#cb150-17"></a></span>
<span id="cb150-18"><a href="linearalgebra.html#cb150-18"></a><span class="co"># in R</span></span>
<span id="cb150-19"><a href="linearalgebra.html#cb150-19"></a><span class="kw">message</span>(<span class="st">&quot;select column of matrix&quot;</span>)</span>
<span id="cb150-20"><a href="linearalgebra.html#cb150-20"></a><span class="co">#&gt; select column of matrix</span></span>
<span id="cb150-21"><a href="linearalgebra.html#cb150-21"></a>(v1 &lt;-<span class="st"> </span>m2[, <span class="dv">1</span>])</span>
<span id="cb150-22"><a href="linearalgebra.html#cb150-22"></a><span class="co">#&gt;  [1] 0 1 2 3 4 5 6 7 8 9</span></span>
<span id="cb150-23"><a href="linearalgebra.html#cb150-23"></a><span class="kw">message</span>(<span class="st">&quot;select row of matrix&quot;</span>)</span>
<span id="cb150-24"><a href="linearalgebra.html#cb150-24"></a><span class="co">#&gt; select row of matrix</span></span>
<span id="cb150-25"><a href="linearalgebra.html#cb150-25"></a>(v2 &lt;-<span class="st"> </span>m2[<span class="dv">10</span>, ])</span>
<span id="cb150-26"><a href="linearalgebra.html#cb150-26"></a><span class="co">#&gt;  [1]  9 19 29 39 49 59 69 79 89 99</span></span></code></pre></div>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="linearalgebra.html#cb151-1"></a><span class="co"># PyTorch</span></span>
<span id="cb151-2"><a href="linearalgebra.html#cb151-2"></a><span class="kw">message</span>()</span>
<span id="cb151-3"><a href="linearalgebra.html#cb151-3"></a><span class="co">#&gt; </span></span>
<span id="cb151-4"><a href="linearalgebra.html#cb151-4"></a>t2c &lt;-<span class="st"> </span>t2[, <span class="dv">1</span>]</span>
<span id="cb151-5"><a href="linearalgebra.html#cb151-5"></a>t2r &lt;-<span class="st"> </span>t2[<span class="dv">10</span>, ]</span>
<span id="cb151-6"><a href="linearalgebra.html#cb151-6"></a></span>
<span id="cb151-7"><a href="linearalgebra.html#cb151-7"></a>t2c</span>
<span id="cb151-8"><a href="linearalgebra.html#cb151-8"></a><span class="co">#&gt; tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)</span></span>
<span id="cb151-9"><a href="linearalgebra.html#cb151-9"></a>t2r</span>
<span id="cb151-10"><a href="linearalgebra.html#cb151-10"></a><span class="co">#&gt; tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)</span></span></code></pre></div>
<p>In vectors, the vector and its transpose are equal.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="linearalgebra.html#cb152-1"></a>tt2r &lt;-<span class="st"> </span>t2r<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0 =</span> 0L, <span class="dt">dim1 =</span> 0L)</span>
<span id="cb152-2"><a href="linearalgebra.html#cb152-2"></a>tt2r</span>
<span id="cb152-3"><a href="linearalgebra.html#cb152-3"></a><span class="co">#&gt; tensor([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99], dtype=torch.int32)</span></span></code></pre></div>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="linearalgebra.html#cb153-1"></a><span class="co"># a tensor of booleans. is vector equal to its transposed?</span></span>
<span id="cb153-2"><a href="linearalgebra.html#cb153-2"></a>t2r <span class="op">==</span><span class="st"> </span>tt2r</span>
<span id="cb153-3"><a href="linearalgebra.html#cb153-3"></a><span class="co">#&gt; tensor([True, True, True, True, True, True, True, True, True, True])</span></span></code></pre></div>
</div>
<div id="tensor-arithmetic" class="section level2">
<h2><span class="header-section-number">4.7</span> Tensor arithmetic</h2>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="linearalgebra.html#cb154-1"></a><span class="kw">message</span>(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb154-2"><a href="linearalgebra.html#cb154-2"></a><span class="co">#&gt; x</span></span>
<span id="cb154-3"><a href="linearalgebra.html#cb154-3"></a>(<span class="dt">x =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</span>
<span id="cb154-4"><a href="linearalgebra.html#cb154-4"></a><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></span>
<span id="cb154-5"><a href="linearalgebra.html#cb154-5"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb154-6"><a href="linearalgebra.html#cb154-6"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb154-7"><a href="linearalgebra.html#cb154-7"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb154-8"><a href="linearalgebra.html#cb154-8"></a><span class="co">#&gt;         [1., 1., 1., 1.]])</span></span>
<span id="cb154-9"><a href="linearalgebra.html#cb154-9"></a><span class="kw">message</span>(<span class="st">&quot;y&quot;</span>)</span>
<span id="cb154-10"><a href="linearalgebra.html#cb154-10"></a><span class="co">#&gt; y</span></span>
<span id="cb154-11"><a href="linearalgebra.html#cb154-11"></a>(<span class="dt">y =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</span>
<span id="cb154-12"><a href="linearalgebra.html#cb154-12"></a><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></span>
<span id="cb154-13"><a href="linearalgebra.html#cb154-13"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb154-14"><a href="linearalgebra.html#cb154-14"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb154-15"><a href="linearalgebra.html#cb154-15"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb154-16"><a href="linearalgebra.html#cb154-16"></a><span class="co">#&gt;         [1., 1., 1., 1.]])</span></span>
<span id="cb154-17"><a href="linearalgebra.html#cb154-17"></a><span class="kw">message</span>(<span class="st">&quot;x+y&quot;</span>)</span>
<span id="cb154-18"><a href="linearalgebra.html#cb154-18"></a><span class="co">#&gt; x+y</span></span>
<span id="cb154-19"><a href="linearalgebra.html#cb154-19"></a>x <span class="op">+</span><span class="st"> </span>y</span>
<span id="cb154-20"><a href="linearalgebra.html#cb154-20"></a><span class="co">#&gt; tensor([[2., 2., 2., 2.],</span></span>
<span id="cb154-21"><a href="linearalgebra.html#cb154-21"></a><span class="co">#&gt;         [2., 2., 2., 2.],</span></span>
<span id="cb154-22"><a href="linearalgebra.html#cb154-22"></a><span class="co">#&gt;         [2., 2., 2., 2.],</span></span>
<span id="cb154-23"><a href="linearalgebra.html#cb154-23"></a><span class="co">#&gt;         [2., 2., 2., 2.],</span></span>
<span id="cb154-24"><a href="linearalgebra.html#cb154-24"></a><span class="co">#&gt;         [2., 2., 2., 2.]])</span></span></code></pre></div>
<p><span class="math display">\[A + B = B + A\]</span></p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="linearalgebra.html#cb155-1"></a>x <span class="op">+</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span>y <span class="op">+</span><span class="st"> </span>x</span>
<span id="cb155-2"><a href="linearalgebra.html#cb155-2"></a><span class="co">#&gt; tensor([[True, True, True, True],</span></span>
<span id="cb155-3"><a href="linearalgebra.html#cb155-3"></a><span class="co">#&gt;         [True, True, True, True],</span></span>
<span id="cb155-4"><a href="linearalgebra.html#cb155-4"></a><span class="co">#&gt;         [True, True, True, True],</span></span>
<span id="cb155-5"><a href="linearalgebra.html#cb155-5"></a><span class="co">#&gt;         [True, True, True, True],</span></span>
<span id="cb155-6"><a href="linearalgebra.html#cb155-6"></a><span class="co">#&gt;         [True, True, True, True]])</span></span></code></pre></div>
</div>
<div id="add-a-scalar-to-a-tensor" class="section level2">
<h2><span class="header-section-number">4.8</span> Add a scalar to a tensor</h2>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="linearalgebra.html#cb156-1"></a>s &lt;-<span class="st"> </span><span class="fl">0.5</span>    <span class="co"># scalar</span></span>
<span id="cb156-2"><a href="linearalgebra.html#cb156-2"></a>x <span class="op">+</span><span class="st"> </span>s</span>
<span id="cb156-3"><a href="linearalgebra.html#cb156-3"></a><span class="co">#&gt; tensor([[1.5000, 1.5000, 1.5000, 1.5000],</span></span>
<span id="cb156-4"><a href="linearalgebra.html#cb156-4"></a><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000],</span></span>
<span id="cb156-5"><a href="linearalgebra.html#cb156-5"></a><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000],</span></span>
<span id="cb156-6"><a href="linearalgebra.html#cb156-6"></a><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000],</span></span>
<span id="cb156-7"><a href="linearalgebra.html#cb156-7"></a><span class="co">#&gt;         [1.5000, 1.5000, 1.5000, 1.5000]])</span></span></code></pre></div>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="linearalgebra.html#cb157-1"></a><span class="co"># scalar multiplying two tensors</span></span>
<span id="cb157-2"><a href="linearalgebra.html#cb157-2"></a>s <span class="op">*</span><span class="st"> </span>(x <span class="op">+</span><span class="st"> </span>y)</span>
<span id="cb157-3"><a href="linearalgebra.html#cb157-3"></a><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></span>
<span id="cb157-4"><a href="linearalgebra.html#cb157-4"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb157-5"><a href="linearalgebra.html#cb157-5"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb157-6"><a href="linearalgebra.html#cb157-6"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb157-7"><a href="linearalgebra.html#cb157-7"></a><span class="co">#&gt;         [1., 1., 1., 1.]])</span></span></code></pre></div>
</div>
<div id="multiplying-tensors" class="section level2">
<h2><span class="header-section-number">4.9</span> Multiplying tensors</h2>
<p><span class="math display">\[A * B = B * A\]</span></p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="linearalgebra.html#cb158-1"></a><span class="kw">message</span>(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb158-2"><a href="linearalgebra.html#cb158-2"></a><span class="co">#&gt; x</span></span>
<span id="cb158-3"><a href="linearalgebra.html#cb158-3"></a>(<span class="dt">x =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</span>
<span id="cb158-4"><a href="linearalgebra.html#cb158-4"></a><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></span>
<span id="cb158-5"><a href="linearalgebra.html#cb158-5"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb158-6"><a href="linearalgebra.html#cb158-6"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb158-7"><a href="linearalgebra.html#cb158-7"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb158-8"><a href="linearalgebra.html#cb158-8"></a><span class="co">#&gt;         [1., 1., 1., 1.]])</span></span>
<span id="cb158-9"><a href="linearalgebra.html#cb158-9"></a><span class="kw">message</span>(<span class="st">&quot;y&quot;</span>)</span>
<span id="cb158-10"><a href="linearalgebra.html#cb158-10"></a><span class="co">#&gt; y</span></span>
<span id="cb158-11"><a href="linearalgebra.html#cb158-11"></a>(<span class="dt">y =</span> torch<span class="op">$</span><span class="kw">ones</span>(5L, 4L))</span>
<span id="cb158-12"><a href="linearalgebra.html#cb158-12"></a><span class="co">#&gt; tensor([[1., 1., 1., 1.],</span></span>
<span id="cb158-13"><a href="linearalgebra.html#cb158-13"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb158-14"><a href="linearalgebra.html#cb158-14"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb158-15"><a href="linearalgebra.html#cb158-15"></a><span class="co">#&gt;         [1., 1., 1., 1.],</span></span>
<span id="cb158-16"><a href="linearalgebra.html#cb158-16"></a><span class="co">#&gt;         [1., 1., 1., 1.]])</span></span>
<span id="cb158-17"><a href="linearalgebra.html#cb158-17"></a><span class="kw">message</span>(<span class="st">&quot;2x+4y&quot;</span>)</span>
<span id="cb158-18"><a href="linearalgebra.html#cb158-18"></a><span class="co">#&gt; 2x+4y</span></span>
<span id="cb158-19"><a href="linearalgebra.html#cb158-19"></a>(<span class="dt">z =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>y)</span>
<span id="cb158-20"><a href="linearalgebra.html#cb158-20"></a><span class="co">#&gt; tensor([[6., 6., 6., 6.],</span></span>
<span id="cb158-21"><a href="linearalgebra.html#cb158-21"></a><span class="co">#&gt;         [6., 6., 6., 6.],</span></span>
<span id="cb158-22"><a href="linearalgebra.html#cb158-22"></a><span class="co">#&gt;         [6., 6., 6., 6.],</span></span>
<span id="cb158-23"><a href="linearalgebra.html#cb158-23"></a><span class="co">#&gt;         [6., 6., 6., 6.],</span></span>
<span id="cb158-24"><a href="linearalgebra.html#cb158-24"></a><span class="co">#&gt;         [6., 6., 6., 6.]])</span></span></code></pre></div>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="linearalgebra.html#cb159-1"></a>x <span class="op">*</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span>y <span class="op">*</span><span class="st"> </span>x</span>
<span id="cb159-2"><a href="linearalgebra.html#cb159-2"></a><span class="co">#&gt; tensor([[True, True, True, True],</span></span>
<span id="cb159-3"><a href="linearalgebra.html#cb159-3"></a><span class="co">#&gt;         [True, True, True, True],</span></span>
<span id="cb159-4"><a href="linearalgebra.html#cb159-4"></a><span class="co">#&gt;         [True, True, True, True],</span></span>
<span id="cb159-5"><a href="linearalgebra.html#cb159-5"></a><span class="co">#&gt;         [True, True, True, True],</span></span>
<span id="cb159-6"><a href="linearalgebra.html#cb159-6"></a><span class="co">#&gt;         [True, True, True, True]])</span></span></code></pre></div>
</div>
<div id="dot-product-1" class="section level2">
<h2><span class="header-section-number">4.10</span> Dot product</h2>
<p><span class="math display">\[dot(a,b)_{i,j,k,a,b,c} = \sum_m a_{i,j,k,m}b_{a,b,m,c}\]</span></p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="linearalgebra.html#cb160-1"></a>torch<span class="op">$</span><span class="kw">dot</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)), torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>)))</span>
<span id="cb160-2"><a href="linearalgebra.html#cb160-2"></a><span class="co">#&gt; tensor(7.)</span></span></code></pre></div>
<div id="dot-product-of-2d-array-using-python" class="section level3">
<h3><span class="header-section-number">4.10.1</span> Dot product of 2D array using Python</h3>
<div class="sourceCode" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="linearalgebra.html#cb161-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb161-2"><a href="linearalgebra.html#cb161-2"></a></span>
<span id="cb161-3"><a href="linearalgebra.html#cb161-3"></a>a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</span>
<span id="cb161-4"><a href="linearalgebra.html#cb161-4"></a>b <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</span>
<span id="cb161-5"><a href="linearalgebra.html#cb161-5"></a><span class="bu">print</span>(a)</span>
<span id="cb161-6"><a href="linearalgebra.html#cb161-6"></a><span class="co">#&gt; [[1 2]</span></span>
<span id="cb161-7"><a href="linearalgebra.html#cb161-7"></a><span class="co">#&gt;  [3 4]]</span></span>
<span id="cb161-8"><a href="linearalgebra.html#cb161-8"></a><span class="bu">print</span>(b)</span>
<span id="cb161-9"><a href="linearalgebra.html#cb161-9"></a><span class="co">#&gt; [[1 2]</span></span>
<span id="cb161-10"><a href="linearalgebra.html#cb161-10"></a><span class="co">#&gt;  [3 4]]</span></span>
<span id="cb161-11"><a href="linearalgebra.html#cb161-11"></a>np.dot(a, b)</span>
<span id="cb161-12"><a href="linearalgebra.html#cb161-12"></a><span class="co">#&gt; array([[ 7, 10],</span></span>
<span id="cb161-13"><a href="linearalgebra.html#cb161-13"></a><span class="co">#&gt;        [15, 22]])</span></span></code></pre></div>
</div>
<div id="dot-product-of-2d-array-using-r" class="section level3">
<h3><span class="header-section-number">4.10.2</span> Dot product of 2D array using R</h3>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="linearalgebra.html#cb162-1"></a>a &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</span>
<span id="cb162-2"><a href="linearalgebra.html#cb162-2"></a>a</span>
<span id="cb162-3"><a href="linearalgebra.html#cb162-3"></a><span class="co">#&gt;      [,1] [,2]</span></span>
<span id="cb162-4"><a href="linearalgebra.html#cb162-4"></a><span class="co">#&gt; [1,]    1    2</span></span>
<span id="cb162-5"><a href="linearalgebra.html#cb162-5"></a><span class="co">#&gt; [2,]    3    4</span></span>
<span id="cb162-6"><a href="linearalgebra.html#cb162-6"></a>b &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</span>
<span id="cb162-7"><a href="linearalgebra.html#cb162-7"></a>b</span>
<span id="cb162-8"><a href="linearalgebra.html#cb162-8"></a><span class="co">#&gt;      [,1] [,2]</span></span>
<span id="cb162-9"><a href="linearalgebra.html#cb162-9"></a><span class="co">#&gt; [1,]    1    2</span></span>
<span id="cb162-10"><a href="linearalgebra.html#cb162-10"></a><span class="co">#&gt; [2,]    3    4</span></span>
<span id="cb162-11"><a href="linearalgebra.html#cb162-11"></a></span>
<span id="cb162-12"><a href="linearalgebra.html#cb162-12"></a>np<span class="op">$</span><span class="kw">dot</span>(a, b)</span>
<span id="cb162-13"><a href="linearalgebra.html#cb162-13"></a><span class="co">#&gt;      [,1] [,2]</span></span>
<span id="cb162-14"><a href="linearalgebra.html#cb162-14"></a><span class="co">#&gt; [1,]    7   10</span></span>
<span id="cb162-15"><a href="linearalgebra.html#cb162-15"></a><span class="co">#&gt; [2,]   15   22</span></span></code></pre></div>
<p><code>torch.dot()</code> treats both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> as <strong>1D</strong> vectors (irrespective of their original shape) and computes their inner product.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="linearalgebra.html#cb163-1"></a>at &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(a)</span>
<span id="cb163-2"><a href="linearalgebra.html#cb163-2"></a>bt &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(b)</span>
<span id="cb163-3"><a href="linearalgebra.html#cb163-3"></a></span>
<span id="cb163-4"><a href="linearalgebra.html#cb163-4"></a><span class="co"># torch$dot(at, bt)  &lt;- RuntimeError: dot: Expected 1-D argument self, but got 2-D</span></span>
<span id="cb163-5"><a href="linearalgebra.html#cb163-5"></a><span class="co"># at %.*% bt</span></span></code></pre></div>
<p>If we perform the same dot product operation in Python, we get the same error:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="linearalgebra.html#cb164-1"></a><span class="im">import</span> torch</span>
<span id="cb164-2"><a href="linearalgebra.html#cb164-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb164-3"><a href="linearalgebra.html#cb164-3"></a></span>
<span id="cb164-4"><a href="linearalgebra.html#cb164-4"></a>a <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</span>
<span id="cb164-5"><a href="linearalgebra.html#cb164-5"></a>a</span>
<span id="cb164-6"><a href="linearalgebra.html#cb164-6"></a><span class="co">#&gt; array([[1, 2],</span></span>
<span id="cb164-7"><a href="linearalgebra.html#cb164-7"></a><span class="co">#&gt;        [3, 4]])</span></span>
<span id="cb164-8"><a href="linearalgebra.html#cb164-8"></a>b <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</span>
<span id="cb164-9"><a href="linearalgebra.html#cb164-9"></a>b</span>
<span id="cb164-10"><a href="linearalgebra.html#cb164-10"></a><span class="co">#&gt; array([[1, 2],</span></span>
<span id="cb164-11"><a href="linearalgebra.html#cb164-11"></a><span class="co">#&gt;        [3, 4]])</span></span>
<span id="cb164-12"><a href="linearalgebra.html#cb164-12"></a>np.dot(a, b)</span>
<span id="cb164-13"><a href="linearalgebra.html#cb164-13"></a><span class="co">#&gt; array([[ 7, 10],</span></span>
<span id="cb164-14"><a href="linearalgebra.html#cb164-14"></a><span class="co">#&gt;        [15, 22]])</span></span>
<span id="cb164-15"><a href="linearalgebra.html#cb164-15"></a>at <span class="op">=</span> torch.as_tensor(a)</span>
<span id="cb164-16"><a href="linearalgebra.html#cb164-16"></a>bt <span class="op">=</span> torch.as_tensor(b)</span>
<span id="cb164-17"><a href="linearalgebra.html#cb164-17"></a></span>
<span id="cb164-18"><a href="linearalgebra.html#cb164-18"></a>at</span>
<span id="cb164-19"><a href="linearalgebra.html#cb164-19"></a><span class="co">#&gt; tensor([[1, 2],</span></span>
<span id="cb164-20"><a href="linearalgebra.html#cb164-20"></a><span class="co">#&gt;         [3, 4]])</span></span>
<span id="cb164-21"><a href="linearalgebra.html#cb164-21"></a>bt</span>
<span id="cb164-22"><a href="linearalgebra.html#cb164-22"></a><span class="co">#&gt; tensor([[1, 2],</span></span>
<span id="cb164-23"><a href="linearalgebra.html#cb164-23"></a><span class="co">#&gt;         [3, 4]])</span></span>
<span id="cb164-24"><a href="linearalgebra.html#cb164-24"></a>torch.dot(at, bt)</span>
<span id="cb164-25"><a href="linearalgebra.html#cb164-25"></a><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83</span></span>
<span id="cb164-26"><a href="linearalgebra.html#cb164-26"></a><span class="co">#&gt; </span></span>
<span id="cb164-27"><a href="linearalgebra.html#cb164-27"></a><span class="co">#&gt; Detailed traceback: </span></span>
<span id="cb164-28"><a href="linearalgebra.html#cb164-28"></a><span class="co">#&gt;   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</span></span></code></pre></div>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="linearalgebra.html#cb165-1"></a>a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</span>
<span id="cb165-2"><a href="linearalgebra.html#cb165-2"></a>b &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>)))</span>
<span id="cb165-3"><a href="linearalgebra.html#cb165-3"></a>c &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">11</span>, <span class="dv">12</span>), <span class="kw">list</span>(<span class="dv">13</span>, <span class="dv">14</span>)))</span>
<span id="cb165-4"><a href="linearalgebra.html#cb165-4"></a></span>
<span id="cb165-5"><a href="linearalgebra.html#cb165-5"></a>a</span>
<span id="cb165-6"><a href="linearalgebra.html#cb165-6"></a><span class="co">#&gt; tensor([[1., 2.],</span></span>
<span id="cb165-7"><a href="linearalgebra.html#cb165-7"></a><span class="co">#&gt;         [3., 4.]])</span></span>
<span id="cb165-8"><a href="linearalgebra.html#cb165-8"></a>b</span>
<span id="cb165-9"><a href="linearalgebra.html#cb165-9"></a><span class="co">#&gt; tensor([1., 2., 3., 4.])</span></span>
<span id="cb165-10"><a href="linearalgebra.html#cb165-10"></a>torch<span class="op">$</span><span class="kw">dot</span>(a, b)</span>
<span id="cb165-11"><a href="linearalgebra.html#cb165-11"></a><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 1D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83</span></span>
<span id="cb165-12"><a href="linearalgebra.html#cb165-12"></a></span>
<span id="cb165-13"><a href="linearalgebra.html#cb165-13"></a><span class="co"># this is another way of performing dot product in PyTorch</span></span>
<span id="cb165-14"><a href="linearalgebra.html#cb165-14"></a><span class="co"># a$dot(a)</span></span></code></pre></div>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="linearalgebra.html#cb166-1"></a>o1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(2L, 2L)</span>
<span id="cb166-2"><a href="linearalgebra.html#cb166-2"></a>o2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(2L, 2L)</span>
<span id="cb166-3"><a href="linearalgebra.html#cb166-3"></a></span>
<span id="cb166-4"><a href="linearalgebra.html#cb166-4"></a>o1</span>
<span id="cb166-5"><a href="linearalgebra.html#cb166-5"></a><span class="co">#&gt; tensor([[1., 1.],</span></span>
<span id="cb166-6"><a href="linearalgebra.html#cb166-6"></a><span class="co">#&gt;         [1., 1.]])</span></span>
<span id="cb166-7"><a href="linearalgebra.html#cb166-7"></a>o2</span>
<span id="cb166-8"><a href="linearalgebra.html#cb166-8"></a><span class="co">#&gt; tensor([[1., 1.],</span></span>
<span id="cb166-9"><a href="linearalgebra.html#cb166-9"></a><span class="co">#&gt;         [1., 1.]])</span></span>
<span id="cb166-10"><a href="linearalgebra.html#cb166-10"></a></span>
<span id="cb166-11"><a href="linearalgebra.html#cb166-11"></a>torch<span class="op">$</span><span class="kw">dot</span>(o1, o2)</span>
<span id="cb166-12"><a href="linearalgebra.html#cb166-12"></a><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83</span></span>
<span id="cb166-13"><a href="linearalgebra.html#cb166-13"></a>o1<span class="op">$</span><span class="kw">dot</span>(o2)</span>
<span id="cb166-14"><a href="linearalgebra.html#cb166-14"></a><span class="co">#&gt; Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1595629401553/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:83</span></span></code></pre></div>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="linearalgebra.html#cb167-1"></a><span class="co"># 1D tensors work fine</span></span>
<span id="cb167-2"><a href="linearalgebra.html#cb167-2"></a>r =<span class="st"> </span>torch<span class="op">$</span><span class="kw">dot</span>(torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(4L, 2L, 4L)), torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(3L, 4L, 1L)))</span>
<span id="cb167-3"><a href="linearalgebra.html#cb167-3"></a>r</span>
<span id="cb167-4"><a href="linearalgebra.html#cb167-4"></a><span class="co">#&gt; tensor(24.)</span></span></code></pre></div>
</div>
<div id="dot-product-with-mm-and-matmul-functions" class="section level3">
<h3><span class="header-section-number">4.10.3</span> Dot product with <code>mm</code> and <code>matmul</code> functions</h3>
<p>So, if we cannor perform 2D tensor operations with the <code>dot</code> product, how do we manage then?</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="linearalgebra.html#cb168-1"></a><span class="co">## mm and matmul seem to address the dot product we are looking for in tensors</span></span>
<span id="cb168-2"><a href="linearalgebra.html#cb168-2"></a>a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)</span>
<span id="cb168-3"><a href="linearalgebra.html#cb168-3"></a>b =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(3L, 4L)</span>
<span id="cb168-4"><a href="linearalgebra.html#cb168-4"></a></span>
<span id="cb168-5"><a href="linearalgebra.html#cb168-5"></a>a<span class="op">$</span><span class="kw">mm</span>(b)</span>
<span id="cb168-6"><a href="linearalgebra.html#cb168-6"></a><span class="co">#&gt; tensor([[ 0.3896,  0.3526, -0.4799,  1.4460],</span></span>
<span id="cb168-7"><a href="linearalgebra.html#cb168-7"></a><span class="co">#&gt;         [-0.5764, -0.2071,  2.1255,  2.6443]])</span></span>
<span id="cb168-8"><a href="linearalgebra.html#cb168-8"></a>a<span class="op">$</span><span class="kw">matmul</span>(b)</span>
<span id="cb168-9"><a href="linearalgebra.html#cb168-9"></a><span class="co">#&gt; tensor([[ 0.3896,  0.3526, -0.4799,  1.4460],</span></span>
<span id="cb168-10"><a href="linearalgebra.html#cb168-10"></a><span class="co">#&gt;         [-0.5764, -0.2071,  2.1255,  2.6443]])</span></span></code></pre></div>
<p>Here is a good explanation: <a href="https://stackoverflow.com/a/44525687/5270873" class="uri">https://stackoverflow.com/a/44525687/5270873</a></p>
<p>Letâ€™s now prove the associative property of tensors:</p>
<p><span class="math display">\[(A B)^T = B^T A^T\]</span></p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="linearalgebra.html#cb169-1"></a>abt &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">mm</span>(a, b)<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</span>
<span id="cb169-2"><a href="linearalgebra.html#cb169-2"></a>abt</span>
<span id="cb169-3"><a href="linearalgebra.html#cb169-3"></a><span class="co">#&gt; tensor([[ 0.3896, -0.5764],</span></span>
<span id="cb169-4"><a href="linearalgebra.html#cb169-4"></a><span class="co">#&gt;         [ 0.3526, -0.2071],</span></span>
<span id="cb169-5"><a href="linearalgebra.html#cb169-5"></a><span class="co">#&gt;         [-0.4799,  2.1255],</span></span>
<span id="cb169-6"><a href="linearalgebra.html#cb169-6"></a><span class="co">#&gt;         [ 1.4460,  2.6443]])</span></span></code></pre></div>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="linearalgebra.html#cb170-1"></a>at &lt;-<span class="st"> </span>a<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</span>
<span id="cb170-2"><a href="linearalgebra.html#cb170-2"></a>bt &lt;-<span class="st"> </span>b<span class="op">$</span><span class="kw">transpose</span>(<span class="dt">dim0=</span>0L, <span class="dt">dim1=</span>1L)</span>
<span id="cb170-3"><a href="linearalgebra.html#cb170-3"></a></span>
<span id="cb170-4"><a href="linearalgebra.html#cb170-4"></a>btat &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">matmul</span>(bt, at)</span>
<span id="cb170-5"><a href="linearalgebra.html#cb170-5"></a>btat</span>
<span id="cb170-6"><a href="linearalgebra.html#cb170-6"></a><span class="co">#&gt; tensor([[ 0.3896, -0.5764],</span></span>
<span id="cb170-7"><a href="linearalgebra.html#cb170-7"></a><span class="co">#&gt;         [ 0.3526, -0.2071],</span></span>
<span id="cb170-8"><a href="linearalgebra.html#cb170-8"></a><span class="co">#&gt;         [-0.4799,  2.1255],</span></span>
<span id="cb170-9"><a href="linearalgebra.html#cb170-9"></a><span class="co">#&gt;         [ 1.4460,  2.6443]])</span></span></code></pre></div>
<p>And we could unit test if the results are nearly the same with <code>allclose()</code>:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="linearalgebra.html#cb171-1"></a><span class="co"># tolerance</span></span>
<span id="cb171-2"><a href="linearalgebra.html#cb171-2"></a>torch<span class="op">$</span><span class="kw">allclose</span>(abt, btat, <span class="dt">rtol=</span><span class="fl">0.0001</span>)</span>
<span id="cb171-3"><a href="linearalgebra.html#cb171-3"></a><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="tensors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mnistdigits.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
